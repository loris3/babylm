{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mrequest to http://localhost:8081/api/kernels/1daa13aa-63a6-48ba-8612-b3bc4465c2a3/restart?1730973496728 failed, reason: read ECONNRESET. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"dataset_folder\": \"./train_10M\",\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mrequest to http://localhost:8081/api/kernels/1daa13aa-63a6-48ba-8612-b3bc4465c2a3/restart?1730973496728 failed, reason: read ECONNRESET. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os\n",
    "os.environ['HF_HOME'] = '/data/loriss21dm/cache'\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘curricula’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir curricula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curriculum 2023 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact data from Thoma et al 2023. Note that the model does not see all examples in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mrequest to http://localhost:8081/api/kernels/1daa13aa-63a6-48ba-8612-b3bc4465c2a3/restart?1730973496728 failed, reason: read ECONNRESET. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ['HF_HOME'] = '/data/loriss21dm/cache'\n",
    "# dev = load_dataset(\"babylm-anon/dev-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b93a6c66cb4d678ef0d99c4d6e02b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1058753 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAST_GEN_DIR = \"last_gen\"\n",
    "EPOCHS_PER_STAGE = 10\n",
    "datasets_stages = []\n",
    "orders_stages = []\n",
    "\n",
    "torch.manual_seed(0)\n",
    "for folder in (sorted(os.listdir(LAST_GEN_DIR))):\n",
    "    d = load_dataset(\"text\", data_dir =os.path.join(LAST_GEN_DIR, folder), cache_dir='/data/loriss21dm/cache')[\"train\"] \n",
    "    d = d.shuffle() # we shuffle within the stage\n",
    "    d = datasets.Dataset.from_dict(d[0:len(d)//10]) # TODO\n",
    "    datasets_stages.append(d)\n",
    "    offset = orders_stages[-1][-1]+1 if len(orders_stages) else 0\n",
    "    for _ in range(0,EPOCHS_PER_STAGE):\n",
    "        orders_stages.append(torch.arange(offset,len(d)+offset))\n",
    "    \n",
    "\n",
    "\n",
    "dataset = datasets.concatenate_datasets(datasets_stages)\n",
    "\n",
    "dataset.save_to_disk(\"./curricula/datasets/curriculum_100M_2023\")\n",
    "#assert torch.equal(torch.cat([o.flatten() for o in orders_stages]),torch.arange(0,len(dataset)))\n",
    "\n",
    "torch.save(orders_stages, \"./curricula/curriculum_100M_2023\")\n",
    "len(orders_stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curriculum with 10M 2024 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training with the strategy in Thoma et al 2023. Note that the model does not see all examples in each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This config is not designed to extract influence estimates from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"raw_dataset_folder_babylm\"] = \"./train_10M\"\n",
    "args[\"raw_eval_dataset_folder_babylm\"] = \"./train_100M\"\n",
    "args[\"dataset_folder\"] = \"./curricula/datasets/curriculum_10M_2024\"\n",
    "args[\"curriculum_path\"] = \"./curricula/curriculum_10M_2024\"\n",
    "args[\"eval_dataset_folder\"] = \"./curricula/datasets/curriculum_10M_2024_eval\"\n",
    "args[\"epochs_per_stage\"] = 2\n",
    "\n",
    "args[\"curriculum\"] = {\n",
    "    \"C1\": [\"childes.train\"],\n",
    "    \"C2\": [\"open_subtitles.train\", \"bnc_spoken.train\"],\n",
    "    \"C3\": [\"switchboard.train\"],\n",
    "    \"C4\": [\"gutenberg.train\"],\n",
    "    \"C5\": [ \"simple_wiki.train\"]\n",
    "} # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c701f84ca7744d8a371411e92bdb5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1179014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32640299a98d4fd6aea130f87e9ddcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/6487961 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7eb1a20139e474a88bf7365b9c8acb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/58950 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914b8c960f554763825571ff79cfacc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/58950 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'dataset_folder': './curricula/datasets/curriculum_10M_2024',\n",
       " 'raw_dataset_folder_babylm': './train_10M',\n",
       " 'raw_eval_dataset_folder_babylm': './train_100M',\n",
       " 'curriculum_path': './curricula/curriculum_10M_2024',\n",
       " 'eval_dataset_folder': './curricula/datasets/curriculum_10M_2024_eval',\n",
       " 'epochs_per_stage': 2,\n",
       " 'curriculum': {'C1': ['childes.train'],\n",
       "  'C2': ['open_subtitles.train', 'bnc_spoken.train'],\n",
       "  'C3': ['switchboard.train'],\n",
       "  'C4': ['gutenberg.train'],\n",
       "  'C5': ['simple_wiki.train']},\n",
       " 'epoch_equivalents': 2.0,\n",
       " 'epochs': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def add_source(entry, source):\n",
    "    entry[\"source\"] = source\n",
    "    return entry\n",
    "def create_dataset(curriculum, raw_dataset_folder):\n",
    "    datasets_stages = []\n",
    "    orders_stages = []\n",
    "    for _, files in curriculum.items():\n",
    "        d = datasets.concatenate_datasets(\n",
    "                [\n",
    "                    load_dataset(\"text\", data_files =os.path.join(raw_dataset_folder, file))[\"train\"] \n",
    "                    .map(lambda entry: add_source(entry, file))\n",
    "                    for file in files\n",
    "                ]\n",
    "            )\n",
    "        d = d.shuffle() # we shuffle with the stage\n",
    "        datasets_stages.append(d)\n",
    "        offset = orders_stages[-1][-1]+1 if len(orders_stages) else 0\n",
    "        for i in range(0,args[\"epochs_per_stage\"]):\n",
    "            indices = torch.arange(offset,len(d)+offset) # and then shuffle again (across epochs within stages)\n",
    "            orders_stages.append(indices[torch.randperm(len(indices))])\n",
    "    return datasets_stages, orders_stages\n",
    "        \n",
    "# pretraining data\n",
    "torch.manual_seed(0)\n",
    "datasets_stages, orders_stages = create_dataset(args[\"curriculum\"], args[\"raw_dataset_folder_babylm\"])\n",
    "dataset = datasets.concatenate_datasets(datasets_stages)\n",
    "dataset = dataset.shuffle()\n",
    "dataset.save_to_disk(args[\"dataset_folder\"])\n",
    "torch.save(orders_stages, args[\"curriculum_path\"])\n",
    "\n",
    "# eval data is a split of (100M dataset - 10M dataset)\n",
    "# of size 0.05*len(10M dataset)\n",
    "torch.manual_seed(0)\n",
    "eval_datasets_stages, _ = create_dataset(args[\"curriculum\"], args[\"raw_eval_dataset_folder_babylm\"])\n",
    "\n",
    "\n",
    "\n",
    "# remove all strings that are in the eval dataset \n",
    "## basically (100M dataset - 10M dataset) but one source at a time as that is faster\n",
    "datasets_eval = []\n",
    "lookup = {d[0][\"source\"]: d for d in datasets_stages}\n",
    "# print(lookup)\n",
    "for e in eval_datasets_stages:\n",
    "    if e[0][\"source\"] in lookup.keys():\n",
    "        l = list(set(e[\"text\"]) - set(lookup[e[0][\"source\"]][\"text\"]))\n",
    "        datasets_eval.append(datasets.Dataset.from_dict({\"text\": l, \"source\": [e[0][\"source\"]]*len(l)}))\n",
    "    else:\n",
    "        print(\"warning: adding all of \",  e[0][\"source\"] )\n",
    "        datasets_eval.append(e)\n",
    "dataset_eval = datasets.concatenate_datasets(datasets_eval)\n",
    "\n",
    "# do a stratified split, requires casting to class  \n",
    "dataset_eval = dataset_eval.class_encode_column(\"source\")\n",
    "dataset_eval = dataset_eval.train_test_split(test_size=int(len(dataset)*0.05), shuffle=True, seed=42, stratify_by_column=\"source\")[\"test\"]\n",
    "# undo casting\n",
    "def undo_casting(x):\n",
    "    x[\"source\"] = dataset_eval.features[\"source\"].int2str(x[\"source\"])\n",
    "    return x\n",
    "dataset_eval = dataset_eval.map(undo_casting)\n",
    "# dataset_eval = dataset_eval.filter(lambda x: x[\"text\"] not in l)\n",
    "# dataset_eval = dataset_eval.shuffle()\n",
    "dataset_eval.save_to_disk(args[\"eval_dataset_folder\"])\n",
    "\n",
    "\n",
    "\n",
    "# assert torch.equal(torch.cat([o.flatten() for o in orders_stages]),torch.arange(0,len(dataset)))\n",
    "\n",
    "\n",
    "\n",
    "len_full_dataset = len(dataset)\n",
    "args[\"epoch_equivalents\"] = sum([len(o) for o in orders_stages]) / len_full_dataset\n",
    "args[\"epochs\"] = len(orders_stages)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"./configs/curriculum_10M_2024\", 'w') as f:\n",
    "    json.dump(args, f)\n",
    "args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified 10M Curriculum built from 100M 2024 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates 5 stages of equal size totaling 10M tokens from the 100M data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mrequest to http://localhost:8081/api/kernels/1daa13aa-63a6-48ba-8612-b3bc4465c2a3/restart?1730973496728 failed, reason: read ECONNRESET. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "args[\"raw_dataset_folder_babylm\"] = \"./train_100M\"\n",
    "args[\"raw_eval_dataset_folder_babylm\"] = \"./train_100M\"\n",
    "args[\"dataset_folder\"] = \"./curricula/datasets/curriculum_stratified_10M_2024\"\n",
    "args[\"curriculum_path\"] = \"./curricula/curriculum_stratified_10M_2024\"\n",
    "args[\"eval_dataset_folder\"] = \"./curricula/datasets/curriculum_stratified_10M_2024_eval\"\n",
    "args[\"epochs_per_stage\"] = 2\n",
    "\n",
    "args[\"curriculum\"] = {\n",
    "    \"C1\": [\"childes.train\"],\n",
    "    \"C2\": [\"open_subtitles.train\", \"bnc_spoken.train\"],\n",
    "    \"C3\": [\"switchboard.train\"],\n",
    "    \"C4\": [\"gutenberg.train\"],\n",
    "    \"C5\": [ \"simple_wiki.train\"]\n",
    "} # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mrequest to http://localhost:8081/api/kernels/1daa13aa-63a6-48ba-8612-b3bc4465c2a3/restart?1730973496728 failed, reason: read ECONNRESET. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bbb9e362ed42d2be5f77910c217352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5790000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datasets_stages = []\n",
    "datasets_stages_eval = []\n",
    "orders_stages = []\n",
    "\n",
    "BUDGET_PER_STAGE = 10_000_000 // len(args[\"curriculum\"])\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def get_train_test_splits_for_stage(d):\n",
    "    d = d.shuffle()\n",
    "    word_count = lambda d: len([w for w in tokenizer.tokenize(d) if w.isalnum()])\n",
    "    words_in_split = 0\n",
    "    i = 0\n",
    "    wc = word_count(d[i][\"text\"])\n",
    "    while (BUDGET_PER_STAGE >= (words_in_split + wc)) and (i < len(d)):\n",
    "        words_in_split += wc\n",
    "        i+=1\n",
    "        wc = word_count(d[i][\"text\"])\n",
    "        \n",
    "    print(BUDGET_PER_STAGE-words_in_split, \"tokens left in budget\")\n",
    "    return d[0:i+1], d[i+1:]  # so that train is of size BUDGET_PER_STAGE, and the rest will be further split when generating the eval dataset later\n",
    "\n",
    "torch.manual_seed(0)\n",
    "for _, files in args[\"curriculum\"].items():\n",
    "    d = datasets.concatenate_datasets(\n",
    "            [\n",
    "                load_dataset(\"text\", data_files =os.path.join(args[\"raw_dataset_folder_babylm\"], file))[\"train\"] \n",
    "                .map(lambda entry: add_source(entry, file))\n",
    "                for file in files\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    d, d_eval = get_train_test_splits_for_stage(d)\n",
    "    datasets_stages.append(d)\n",
    "    datasets_stages_eval.append(d_eval)\n",
    "    offset = orders_stages[-1][-1]+1 if len(orders_stages) else 0\n",
    "    for i in range(0,args[\"epochs_per_stage\"]):\n",
    "        indices = torch.arange(offset,len(d)+offset) # and then shuffle again (across epochs within stages)\n",
    "        orders_stages.append(indices[torch.randperm(len(indices))])\n",
    "    \n",
    "\n",
    "        \n",
    "# pretraining data\n",
    "dataset = datasets.concatenate_datasets(datasets_stages)\n",
    "dataset = dataset.shuffle()\n",
    "dataset.save_to_disk(args[\"dataset_folder\"])\n",
    "torch.save(orders_stages, args[\"curriculum_path\"])\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "dataset_eval = datasets.concatenate_datasets(datasets_stages_eval)\n",
    "\n",
    "# do a stratified split, requires casting to class  \n",
    "dataset_eval = dataset_eval.class_encode_column(\"source\")\n",
    "dataset_eval = dataset_eval.train_test_split(test_size=int(len(dataset)*0.05), shuffle=True, seed=42, stratify_by_column=\"source\")[\"test\"]\n",
    "# undo casting\n",
    "def undo_casting(x):\n",
    "    x[\"source\"] = dataset_eval.features[\"source\"].int2str(x[\"source\"])\n",
    "    return x\n",
    "dataset_eval = dataset_eval.map(undo_casting)\n",
    "\n",
    "dataset_eval.save_to_disk(args[\"eval_dataset_folder\"])\n",
    "\n",
    "\n",
    "\n",
    "# assert torch.equal(torch.cat([o.flatten() for o in orders_stages]),torch.arange(0,len(dataset)))\n",
    "\n",
    "\n",
    "\n",
    "len_full_dataset = len(dataset)\n",
    "args[\"epoch_equivalents\"] = sum([len(o) for o in orders_stages]) / len_full_dataset\n",
    "args[\"epochs\"] = len(orders_stages)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"./configs/curriculum_stratified_10M_2024\", 'w') as f:\n",
    "    json.dump(args, f)\n",
    "args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mimicks the default behaviour of Huggingface's `Trainer`: Randomly shuffle dataset after each epoch.\n",
    "All data is shown at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset_folder\": \"./curricula/datasets/curriculum_10M_2024\",# reuse one created above\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"raw_dataset_folder_babylm\"] = \"./train_10M\"\n",
    "args[\"curriculum_path\"] = \"./curricula/random_10M_2024\"\n",
    "args[\"eval_dataset_folder\"] = \"./curricula/datasets/curriculum_10M_2024_eval\"\n",
    "args[\"epochs\"] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets\n",
    "dataset = datasets.load_from_disk(args[\"dataset_folder\"]) # reuse one created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(torch.sort(torch.randperm(len(dataset))).values, torch.arange(0,len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_folder': './curricula/datasets/curriculum_10M_2024',\n",
       " 'raw_dataset_folder_babylm': './train_10M',\n",
       " 'curriculum_path': './curricula/random_10M_2024',\n",
       " 'eval_dataset_folder': './curricula/datasets/curriculum_10M_2024_eval',\n",
       " 'epochs': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args[\"epochs\"] = 10\n",
    "import torch \n",
    "torch.manual_seed(0)\n",
    "random_order = torch.stack([torch.randperm(len(dataset)) for _ in range(0,args[\"epochs\"])])\n",
    "torch.save(random_order, \"./curricula/random_10M_2024\")\n",
    "with open(\"./configs/random_10M_2024\", 'w') as f:\n",
    "    json.dump(args, f)\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Groups     |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
    "|----------------|-------|------|-----:|------|-----:|---|-----:|\n",
    "|blimp_supplement|N/A    |none  |     0|acc   |0.4401|±  |0.0069|\n",
    "|blimp_filtered  |N/A    |none  |     0|acc   |0.4579|±  |0.0019|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Shuffle with a proportion of the documents beeing random tokens as a control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset_folder\": \"./curricula/datasets/curriculum_10M_2024_noisy\",# reuse one created above\n",
    "   \n",
    "}\n",
    "args[\"raw_dataset_folder_babylm\"] = \"./train_10M\"\n",
    "args[\"curriculum_path\"] = \"./curricula/random_10M_2024_noisy\"\n",
    "args[\"eval_dataset_folder\"] = \"./curricula/datasets/curriculum_10M_2024_eval\"\n",
    "args[\"epochs\"] = 10\n",
    "\n",
    "args[\"proportion_noise\"] = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "dataset = datasets.load_from_disk(\"./curricula/datasets/curriculum_10M_2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' Towns Shim achieving Rapid Tight scrollIn Meter daNar lenses',\n",
       " 'source': 'noise'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"FacebookAI/roberta-base\", max_len=512)\n",
    "def replace_with_noise(example):\n",
    "    tokenized = tokenizer(example[\"text\"], return_special_tokens_mask=True, truncation=True, max_length=512)[\"input_ids\"]\n",
    "    example[\"text\"] = tokenizer.decode(torch.randint(0, tokenizer.vocab_size, (len(tokenized),)), skip_special_tokens=True)\n",
    "    example[\"source\"] = \"noise\"\n",
    "    return example\n",
    "replace_with_noise(dataset[1000000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7371b5ba844eda8896fbebc198d9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1179014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'dataset_folder': './curricula/datasets/curriculum_10M_2024_noisy',\n",
       " 'raw_dataset_folder_babylm': './train_10M',\n",
       " 'curriculum_path': './curricula/random_10M_2024_noisy',\n",
       " 'eval_dataset_folder': './curricula/datasets/curriculum_10M_2024_eval',\n",
       " 'epochs': 10,\n",
       " 'proportion_noise': 0.05}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.manual_seed(0)\n",
    "ind_to_replace_with_noise = torch.randperm(int(len(dataset)*args[\"proportion_noise\"]))\n",
    "dl = dataset.to_list()\n",
    "for i in ind_to_replace_with_noise:\n",
    "    dl[i] = replace_with_noise(dl[i])\n",
    "from collections import ChainMap\n",
    "\n",
    "\n",
    "dataset = datasets.Dataset.from_dict({k: [line[k] for line in dl] for k in dl[0]})\n",
    "dataset = dataset.shuffle()\n",
    "dataset.save_to_disk(args[\"dataset_folder\"])\n",
    "random_order = torch.stack([torch.randperm(len(dataset)) for _ in range(0,args[\"epochs\"])])\n",
    "torch.save(random_order, args[\"curriculum_path\"])\n",
    "with open(\"./configs/random_10M_2024_noisy\", 'w') as f:\n",
    "    json.dump(args, f)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20294)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_replace_with_noise[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset_folder\": \"./curricula/datasets/test\",   \n",
    "}\n",
    "args[\"raw_dataset_folder_babylm\"] = \"./train_10M\"\n",
    "args[\"curriculum_path\"] = \"./curricula/test_random_curriculum\"\n",
    "args[\"eval_dataset_folder\"] = \"./curricula/datasets/test_eval\"\n",
    "args[\"epochs\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccea2b76cd74a87a63704052cd5e3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed98723ce1ef476b9a46aa6214b61570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'dataset_folder': './curricula/datasets/test',\n",
       " 'raw_dataset_folder_babylm': './train_10M',\n",
       " 'curriculum_path': './curricula/test_random_curriculum',\n",
       " 'eval_dataset_folder': './curricula/datasets/test_eval',\n",
       " 'epochs': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "import torch \n",
    "torch.manual_seed(0)\n",
    "import json\n",
    "#dataset = load_dataset(\"text\", data_dir =\"/data/loriss21dm/babylm/train_test\", cache_dir='/data/loriss21dm/cache')[\"train\"] \n",
    "dataset = datasets.load_from_disk(\"./curricula/datasets/curriculum_10M_2024\") # reuse one created above\n",
    "dataset = dataset.shuffle()\n",
    "dataset = datasets.Dataset.from_dict(dataset[0:len(dataset)//1000]) # TODO\n",
    "dataset.save_to_disk(args[\"dataset_folder\"])\n",
    "\n",
    "random_order = torch.stack([torch.randperm(len(dataset)) for _ in range(0,args[\"epochs\"])])\n",
    "torch.save(random_order, args[\"curriculum_path\"])\n",
    "\n",
    "\n",
    "dataset = datasets.Dataset.from_dict(dataset[0:len(dataset)//10]) # TODO\n",
    "dataset.save_to_disk(args[\"eval_dataset_folder\"])\n",
    "\n",
    "with open(\"./configs/test\", 'w') as f:\n",
    "    json.dump(args, f)\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Curriculum based on Influence during learning on randomly shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_folder': './curricula/datasets/curriculum_10M_2024', 'raw_dataset_folder_babylm': './train_10M', 'curriculum_path': './curricula/random_10M_2024', 'eval_dataset_folder': './curricula/datasets/curriculum_10M_2024_eval', 'epochs': 10}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9212</th>\n",
       "      <th>18424</th>\n",
       "      <th>27636</th>\n",
       "      <th>36848</th>\n",
       "      <th>46060</th>\n",
       "      <th>55272</th>\n",
       "      <th>64484</th>\n",
       "      <th>73696</th>\n",
       "      <th>82908</th>\n",
       "      <th>92120</th>\n",
       "      <th>total</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>document_lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196915</td>\n",
       "      <td>0.464265</td>\n",
       "      <td>0.168282</td>\n",
       "      <td>0.054872</td>\n",
       "      <td>0.023046</td>\n",
       "      <td>0.051617</td>\n",
       "      <td>0.032035</td>\n",
       "      <td>0.015906</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>1.015337</td>\n",
       "      <td>Now you're putting it on me like I'm gonna aba...</td>\n",
       "      <td>open_subtitles.train</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.215043</td>\n",
       "      <td>0.052703</td>\n",
       "      <td>0.130161</td>\n",
       "      <td>0.045186</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>-0.002933</td>\n",
       "      <td>0.086384</td>\n",
       "      <td>0.044641</td>\n",
       "      <td>0.620429</td>\n",
       "      <td>= = = childes/CHILDES_UK/Edinburgh/hakeem0903....</td>\n",
       "      <td>childes.train</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130555</td>\n",
       "      <td>0.031752</td>\n",
       "      <td>0.398065</td>\n",
       "      <td>0.113166</td>\n",
       "      <td>0.084688</td>\n",
       "      <td>0.072645</td>\n",
       "      <td>0.047322</td>\n",
       "      <td>0.034912</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.930202</td>\n",
       "      <td>*CHI:\\tI don't wear my sweatshirt.</td>\n",
       "      <td>childes.train</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000313</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.029773</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.044175</td>\n",
       "      <td>0.013503</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>0.108195</td>\n",
       "      <td>The program caused different reactions from co...</td>\n",
       "      <td>simple_wiki.train</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.122183</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>0.037030</td>\n",
       "      <td>0.055496</td>\n",
       "      <td>0.016643</td>\n",
       "      <td>0.027887</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>0.119937</td>\n",
       "      <td>0.540355</td>\n",
       "      <td></td>\n",
       "      <td>simple_wiki.train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179009</th>\n",
       "      <td>0.011064</td>\n",
       "      <td>-0.028697</td>\n",
       "      <td>-0.005899</td>\n",
       "      <td>-0.017692</td>\n",
       "      <td>-0.005494</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>-0.001288</td>\n",
       "      <td>-0.000507</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.049523</td>\n",
       "      <td></td>\n",
       "      <td>childes.train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179010</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002727</td>\n",
       "      <td>-0.001382</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>-0.004443</td>\n",
       "      <td>\"Here in London. It is a powerful and wealthy ...</td>\n",
       "      <td>gutenberg.train</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179011</th>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>-0.000568</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.010588</td>\n",
       "      <td>0.031212</td>\n",
       "      <td>*MOT:\\tDada's waiting for you.</td>\n",
       "      <td>childes.train</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179012</th>\n",
       "      <td>-0.001100</td>\n",
       "      <td>0.107309</td>\n",
       "      <td>0.023218</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>-0.000616</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.144407</td>\n",
       "      <td>*MOT:\\there can I fix it?</td>\n",
       "      <td>childes.train</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179013</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>*CHI:\\tum a mouse.</td>\n",
       "      <td>childes.train</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1179014 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             9212     18424     27636     36848     46060     55272     64484  \\\n",
       "0        0.000000  0.196915  0.464265  0.168282  0.054872  0.023046  0.051617   \n",
       "1        0.215043  0.052703  0.130161  0.045186  0.015314  0.025799  0.008130   \n",
       "2        0.130555  0.031752  0.398065  0.113166  0.084688  0.072645  0.047322   \n",
       "3       -0.000313  0.001169  0.000973  0.000264  0.029773  0.007767  0.044175   \n",
       "4        0.002561  0.122183  0.139494  0.037030  0.055496  0.016643  0.027887   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1179009  0.011064 -0.028697 -0.005899 -0.017692 -0.005494 -0.000605 -0.001288   \n",
       "1179010  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1179011  0.000385  0.001423  0.000343 -0.000568  0.000187 -0.000054  0.000143   \n",
       "1179012 -0.001100  0.107309  0.023218  0.009043 -0.000616  0.000789  0.000879   \n",
       "1179013  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            73696     82908     92120     total  \\\n",
       "0        0.032035  0.015906  0.008399  1.015337   \n",
       "1       -0.002933  0.086384  0.044641  0.620429   \n",
       "2        0.034912  0.011752  0.005345  0.930202   \n",
       "3        0.013503  0.004643  0.006240  0.108195   \n",
       "4        0.010327  0.008796  0.119937  0.540355   \n",
       "...           ...       ...       ...       ...   \n",
       "1179009 -0.000507 -0.000258 -0.000148 -0.049523   \n",
       "1179010 -0.002727 -0.001382 -0.000334 -0.004443   \n",
       "1179011  0.010581  0.008184  0.010588  0.031212   \n",
       "1179012  0.000590  0.000725  0.003571  0.144407   \n",
       "1179013  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                                      text  \\\n",
       "0        Now you're putting it on me like I'm gonna aba...   \n",
       "1        = = = childes/CHILDES_UK/Edinburgh/hakeem0903....   \n",
       "2                       *CHI:\\tI don't wear my sweatshirt.   \n",
       "3        The program caused different reactions from co...   \n",
       "4                                                            \n",
       "...                                                    ...   \n",
       "1179009                                                      \n",
       "1179010  \"Here in London. It is a powerful and wealthy ...   \n",
       "1179011                    *MOT:\\tDada's waiting for you.    \n",
       "1179012                          *MOT:\\there can I fix it?   \n",
       "1179013                                *CHI:\\tum a mouse.    \n",
       "\n",
       "                       source  document_lenght  \n",
       "0        open_subtitles.train               14  \n",
       "1               childes.train                8  \n",
       "2               childes.train                7  \n",
       "3           simple_wiki.train               37  \n",
       "4           simple_wiki.train                1  \n",
       "...                       ...              ...  \n",
       "1179009         childes.train                1  \n",
       "1179010       gutenberg.train               27  \n",
       "1179011         childes.train                6  \n",
       "1179012         childes.train                7  \n",
       "1179013         childes.train                5  \n",
       "\n",
       "[1179014 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABA+klEQVR4nO3de3xU9Z3/8ffMJJkQciOETACDAVSQooQFk4bWS2sqtdbWbusiWmGzSltLWmvcPjRtJdW2xqpFupYt6oJ2a12p/VntVovVVHQpUTRIvRSwKHfIzZALAWaSmfP7IzmTBJKQSWbmzOX1fDzmQXLmnJnvcUx48/1+vt+vzTAMQwAAABaxW90AAAAQ3wgjAADAUoQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABLJVjdgOHw+Xw6dOiQ0tLSZLPZrG4OAAAYBsMw1N7erkmTJsluH7z/IyrCyKFDh5SXl2d1MwAAwAjs379fZ5xxxqDPR0UYSUtLk9R9M+np6Ra3BgAADEdbW5vy8vL8f48PJirCiDk0k56eThgBACDKnK7EggJWAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABLEUYAAIClCCMAAMBShBEAAGApwggAALAUYQQAAFiKMAIAACxFGAEAAJYijACwTkeHZLN1Pzo6rG4NAIuMKIysXr1a+fn5Sk5OVlFRkbZs2TLk+atWrdKMGTM0ZswY5eXl6ZZbbtGJEydG1GAAABBbAg4j69evV3l5uSorK7V161bNmTNHCxcuVENDw4DnP/HEE7r99ttVWVmp7du3a+3atVq/fr2+973vjbrxAAAg+gUcRlauXKlly5aptLRUs2bN0po1a5SSkqJ169YNeP7mzZv1iU98Qtdee63y8/N12WWXafHixaftTQEAAPEhoDDi8XhUW1urkpKS3hew21VSUqKampoBr1mwYIFqa2v94ePDDz/U888/r8997nODvo/b7VZbW1u/BwAAiE0JgZzc1NQkr9crl8vV77jL5dKOHTsGvObaa69VU1OTPvnJT8owDHV1dekb3/jGkMM0VVVVuvPOOwNpGgAAiFIhn02zceNG3X333frP//xPbd26VU8//bSee+45/ehHPxr0moqKCrW2tvof+/fvD3UzAQCARQLqGcnOzpbD4VB9fX2/4/X19crNzR3wmjvuuEPXX3+9brzxRknSeeedp46ODn3ta1/T97//fdntp+Yhp9Mpp9MZSNMAAECUCqhnJCkpSfPmzVN1dbX/mM/nU3V1tYqLiwe85tixY6cEDofDIUkyDCPQ9gIAgBgTUM+IJJWXl2vp0qWaP3++CgsLtWrVKnV0dKi0tFSStGTJEk2ePFlVVVWSpCuvvFIrV67U3LlzVVRUpF27dumOO+7QlVde6Q8lAAAgfgUcRhYtWqTGxkatWLFCdXV1Kigo0IYNG/xFrfv27evXE/KDH/xANptNP/jBD3Tw4EFNmDBBV155pX7yk58E7y4AAEDUshlRMFbS1tamjIwMtba2Kj093ermAAiWjg4pNbX766NHpbFjrW0PgKAa7t/f7E0DAAAsRRgBAACWIowAAABLEUYAAIClCCMAAMBShBEAAGApwggAALAUYQQAAFiKMAIAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABLEUYAAIClCCMAAMBShBEAltlV3251EwBEgBGFkdWrVys/P1/JyckqKirSli1bBj33kksukc1mO+VxxRVXjLjRAGLDO4farG4CgAgQcBhZv369ysvLVVlZqa1bt2rOnDlauHChGhoaBjz/6aef1uHDh/2Pd999Vw6HQ1dfffWoGw8gurV0eKxuAoAIEHAYWblypZYtW6bS0lLNmjVLa9asUUpKitatWzfg+VlZWcrNzfU/XnzxRaWkpBBGAKjleG8YOdHptbAlAKwUUBjxeDyqra1VSUlJ7wvY7SopKVFNTc2wXmPt2rW65pprNHbs2MBaCiDmHDnWG0Ya29wWtgSAlRICObmpqUler1cul6vfcZfLpR07dpz2+i1btujdd9/V2rVrhzzP7XbL7e79xdTWxrgyEItajnX5v248ekJ5FrYFgHXCOptm7dq1Ou+881RYWDjkeVVVVcrIyPA/8vL4FQXEor49Iw1t1I8A8SqgMJKdnS2Hw6H6+vp+x+vr65WbmzvktR0dHXryySd1ww03nPZ9Kioq1Nra6n/s378/kGYCiBJ9C1gb2k9Y2BIAVgoojCQlJWnevHmqrq72H/P5fKqurlZxcfGQ1z711FNyu9366le/etr3cTqdSk9P7/cAEHuOHO/0f91wlDACxKuAakYkqby8XEuXLtX8+fNVWFioVatWqaOjQ6WlpZKkJUuWaPLkyaqqqup33dq1a3XVVVdp/PjxwWk5gKhmGIZaj/WGkUaGaYC4FXAYWbRokRobG7VixQrV1dWpoKBAGzZs8Be17tu3T3Z7/w6XnTt3atOmTfrzn/8cnFYDiHrt7i51+Qz/9wzTAPEr4DAiSWVlZSorKxvwuY0bN55ybMaMGTIM49STAcStIycteNbQRhgB4hV70wCwRPNJYaSxnWEaIF4RRgBYoqVPvYjUPWxzzNM1yNkAYhlhBIAlTu4ZkaQGVmEF4hJhBIAl+i54ZqqnbgSIS4QRAJYYMIy00zMCxCPCCABLNHd0nnKMGTVAfCKMALBEC8M0AHoQRgBYYqAC1noKWIG4RBgBYImTp/ZK9IwA8YowAsASzQMM0zRQwArEJcIIgLAzDIOaEQB+hBEAYXfU3aVO76n7VR3zeHXUzSqsQLwhjAAIuyM903qTE3t/BaUld+/bSe8IEH8IIwDCzlzwbFxKov9YTppTEmEEiEeEEQBhZxavZoxJ8h+b0BNG2J8GiD+EEQBhZxavZo3tDSM5acmS6BkB4hFhBEDYmUvBZ4zpHaaZkN4dTFj4DIg/hBEAYXekZ/XVcWP71Iyk9vSMtNMzAsQbwgiAsDMLWDPHnDpMw2Z5QPwhjAAIuwFn0zBMA8QtwgiAsDPXGckcoIC1of2EDOPUBdEAxC7CCICw6x2m6e0Zye6Z2nui06e2E6zCCsQTwgiAsGv2F7D29owkJzqU2TNsQ90IEF8IIwDCqnuTvO5hmnEpSf2e612FlboRIJ4QRgCEVYfHK4/XJ0n+nhCTK52Fz4B4RBgBEFbmGiPOBLvGJDr6PedfhZW1RoC4QhgBEFa903qTZLPZ+j3nSmd/GiAeEUYAhNVAxasmhmmA+EQYARBWZvFq1tjEU54ze0YII0B8IYwACCuzZyQz5dSekZx0c+EzhmmAeEIYARBWLT01I1kDhBFzmKahzc0qrEAcGVEYWb16tfLz85WcnKyioiJt2bJlyPNbWlq0fPlyTZw4UU6nU+ecc46ef/75ETUYQHRrHmBfGtOE1O5hGo/X5x/OARD7Ag4j69evV3l5uSorK7V161bNmTNHCxcuVENDw4DnezwefeYzn9GePXv0u9/9Tjt37tQjjzyiyZMnj7rxAKKPuS/NQAWsSQl2ZfUcZ3ovED8SAr1g5cqVWrZsmUpLSyVJa9as0XPPPad169bp9ttvP+X8devWqbm5WZs3b1ZiYve/hPLz80fXagBRy5zamzVAGJG6V2Ft7vCovs2tmbnhbBkAqwTUM+LxeFRbW6uSkpLeF7DbVVJSopqamgGv+cMf/qDi4mItX75cLpdLs2fP1t133y2v1zvo+7jdbrW1tfV7AIgNQxWwSkzvBeJRQGGkqalJXq9XLper33GXy6W6uroBr/nwww/1u9/9Tl6vV88//7zuuOMO/exnP9OPf/zjQd+nqqpKGRkZ/kdeXl4gzQQQwfxTewcNI+bCZ4QRIF6EfDaNz+dTTk6OHn74Yc2bN0+LFi3S97//fa1Zs2bQayoqKtTa2up/7N+/P9TNBBAGhmH4C1hP3pfG1NszwvReIF4EVDOSnZ0th8Oh+vr6fsfr6+uVmzvw4O7EiROVmJgoh6N3D4pzzz1XdXV18ng8Sko69V9HTqdTTqczkKYBiALHPF55uro3ycsamyR1nRo4chimAeJOQD0jSUlJmjdvnqqrq/3HfD6fqqurVVxcPOA1n/jEJ7Rr1y75fD7/sffff18TJ04cMIgAiF1m8WpSgl0pSY4Bz3Gl9QzTsPAZEDcCHqYpLy/XI488ol/96lfavn27brrpJnV0dPhn1yxZskQVFRX+82+66SY1Nzfr5ptv1vvvv6/nnntOd999t5YvXx68uwAQFfzTelMST9kkz9S78Bk9I0C8CHhq76JFi9TY2KgVK1aorq5OBQUF2rBhg7+odd++fbLbezNOXl6eXnjhBd1yyy06//zzNXnyZN1888267bbbgncXAKJC3x17B5OT3tsz4vMZstsHDi0AYkfAYUSSysrKVFZWNuBzGzduPOVYcXGxXnvttZG8FYAYMpwwkp3qlM0mdfm6i12zU6kfA2Ide9MACJsjHUMveCZJiQ67xo9l914gnhBGAIRNc88aI4NN6zX1rjVCESsQDwgjAMJmOD0jEquwAvGGMAIgbIZTMyL19oyw8BkQHwgjAMLGH0bGDj1Mk5PW0zPCzr1AXCCMAAib3nVGhjdMQ80IEB8IIwDCJtBhmgZ6RoC4QBgBEDbNwyxg9Q/TUMAKxAXCCICwOO7xyt2zSd64086m6e4ZaWx3y+szQt42ANYijAAIi+aeIZpEh01jB9kkzzQ+1Sm7TfIZ0kdHqRsBYh1hBEBYmGuMjEtJGnSTPJPDbtOENKb3AvGCMAIgLIZbvGpi4TMgfhBGAISFWbx6ujVGTKw1AsQPwgiAsGjp2ZfmdDNpTKzCCsQPwgiAsDB7RjIDHKZppGcEiHmEEQBh0dJTM5I17DBCzwgQLwgjAMKiuWeYJjMlwJoRCliBmEcYARAWR4a5+qoph54RIG4QRgCERe+OvYHVjHzU4Van1xeydgGwHmEEQFj0XfRsOLJSkpRgt8kwpCZWYQViGmEEQFgcMaf2DjOM2O025bAKKxAXCCMAQu64x6vjnV5JUuYwFz2TpBxWYQXiAmEEQMiZ9SIJdpvSnAnDvs6c3ttAGAFiGmEEQMj1LV493SZ5ffXuT8MwDRDLCCMAQu5IR3e9yLhhrjFiMsNIA6uwAjGNMAIg5ALdsdc0gQJWIC4QRgCE3EjDiIsCViAuEEYAhJy5Sd5wFzwz+QtY2+kZAWIZYQRAyLWYa4wEMK1Xklw9+9M0d3jk7vIGvV0AIgNhBEDINQe4+qopMyVRSY7uX1ON9I4AMWtEYWT16tXKz89XcnKyioqKtGXLlkHPfeyxx2Sz2fo9kpOTR9xgANFnpDUjNpuNDfOAOBBwGFm/fr3Ky8tVWVmprVu3as6cOVq4cKEaGhoGvSY9PV2HDx/2P/bu3TuqRgOILr3rjAQ2TCP1md5LESsQswIOIytXrtSyZctUWlqqWbNmac2aNUpJSdG6desGvcZmsyk3N9f/cLlco2o0gOjSu85IYD0jUm8RKzNqgNgVUBjxeDyqra1VSUlJ7wvY7SopKVFNTc2g1x09elRnnnmm8vLy9MUvflHvvffekO/jdrvV1tbW7wEgepk9I1kBzqaRpJw0c+EzhmmAWBVQGGlqapLX6z2lZ8Plcqmurm7Aa2bMmKF169bp2Wef1eOPPy6fz6cFCxbowIEDg75PVVWVMjIy/I+8vLxAmgkggpzo9OqYp2eTvBH0jFAzAsS+kM+mKS4u1pIlS1RQUKCLL75YTz/9tCZMmKCHHnpo0GsqKirU2trqf+zfvz/UzQQQIua0XofdpvTk4W+SZ3KlsSQ8EOsC+s2QnZ0th8Oh+vr6fsfr6+uVm5s7rNdITEzU3LlztWvXrkHPcTqdcjqdgTQNQITqndabGNAmeSZWYQViX0A9I0lJSZo3b56qq6v9x3w+n6qrq1VcXDys1/B6vXrnnXc0ceLEwFoKICq1jHBar8nFMA0Q8wLuMy0vL9fSpUs1f/58FRYWatWqVero6FBpaakkacmSJZo8ebKqqqokSXfddZc+/vGP66yzzlJLS4vuu+8+7d27VzfeeGNw7wRARGoeZRjJ6ekZaT3eqROdXiUnOoLWNgCRIeAwsmjRIjU2NmrFihWqq6tTQUGBNmzY4C9q3bdvn+z23g6XI0eOaNmyZaqrq9O4ceM0b948bd68WbNmzQreXQCIWEc6Rr7GiCSlJycoOdGuE50+NbS5NWV8SjCbByACBF5NJqmsrExlZWUDPrdx48Z+3z/wwAN64IEHRvI2AGLAEf++NCPrGbHZbHKlJ2vvR8dU336CMALEIPamARBSZgHrSKb1mswZNRSxArGJMAIgpMwC1qxRhJEJPUWsDRSxAjGJMAIgpJp7hmkyU0ZWMyL16RlhrREgJhFGAISUWcA60poRqXd6Lz0jQGwijAAIqd4de0cTRqgZAWIZYQRASPmn9o6iZiSHnXuBmEYYARAy7i6vOno2yRtNAavZM8IwDRCbCCMAQsbcJM9uk9JGsEmeyQwj7e4udbi7gtI2AJGDMAIgZJr7DNHY7YFvkmdKdSZobFL3MvAN7fSOALGGMAIgZIJRvGqiiBWIXYQRACFzpKN7mGbcKNYYMU1I65neS88IEHMIIwBC5sgod+ztq7eIlZ4RINYQRgCETDCm9ZpcTO8FYhZhBEDINIekZoRhGiDWEEYAhIw5tTdr7OhrRnIoYAViFmEEQMiYU3szgzFMQwErELMIIwBCpqVnmGY0q6+a+k7tNQxj1K8HIHIQRgCETG/NSDCGabp7Ro55vDrKKqxATCGMAAiZFv86I6PvGUlJSvAvKU8RKxBbCCMAQsLT5VN7Tw9GVhBm00hSjr9uhCJWIJYQRgCEhFkvYrdJ6cmjH6aR2L0XiFWEEQAhcaRnWm/mKDfJ64v9aYDYRBgBEBK903qD0ysi9RaxUjMCxBbCCICQCOa0XpMrradnhJoRIKYQRgCERDCXgjexWR4QmwgjAEKid5O84A3TuBimAWISYQRASJgFrKHoGWEVViC2EEYAhERvz0jwwsiEnnVG3F0+tR1nFVYgVhBGAITEkRAUsCYnOpQxpnvYh4XPgNhBGAEQEs0hGKaRqBsBYhFhBEBIhKKAVWLhMyAWjSiMrF69Wvn5+UpOTlZRUZG2bNkyrOuefPJJ2Ww2XXXVVSN5WwBR5EgIpvZKUg5rjQAxJ+Awsn79epWXl6uyslJbt27VnDlztHDhQjU0NAx53Z49e/Tv//7vuvDCC0fcWADRodPrU/uJ7gLTYBawSr3DNOxPA8SOgMPIypUrtWzZMpWWlmrWrFlas2aNUlJStG7dukGv8Xq9uu6663TnnXdq2rRpo2owgMjX0lMvYrPJX3AaLAzTALEnoDDi8XhUW1urkpKS3hew21VSUqKamppBr7vrrruUk5OjG264YVjv43a71dbW1u8BIHqYQzQZYxLlCNImeabeAlbCCBArAgojTU1N8nq9crlc/Y67XC7V1dUNeM2mTZu0du1aPfLII8N+n6qqKmVkZPgfeXl5gTQTgMXMTfKCOa3XlOPvGWGYBogVIZ1N097eruuvv16PPPKIsrOzh31dRUWFWltb/Y/9+/eHsJUAgq0lRMWrUu8wTWO7m1VYgRiREMjJ2dnZcjgcqq+v73e8vr5eubm5p5z/wQcfaM+ePbryyiv9x3w+X/cbJyRo586dmj59+inXOZ1OOZ3OQJoGIII0d/SsMRLkab2SNCG1+3eDx+tTy7HOkAQeAOEVUM9IUlKS5s2bp+rqav8xn8+n6upqFRcXn3L+zJkz9c4772jbtm3+xxe+8AV96lOf0rZt2xh+AWKUf1pvCIZpkhLsyuoJIEzvBWJDQD0jklReXq6lS5dq/vz5Kiws1KpVq9TR0aHS0lJJ0pIlSzR58mRVVVUpOTlZs2fP7nd9ZmamJJ1yHEDs8C94FqJei5w0p5o7PKpvc2vmqZ2yAKJMwGFk0aJFamxs1IoVK1RXV6eCggJt2LDBX9S6b98+2e0s7ArEs+YQ9oxI3XUjO+ramVEDxIiAw4gklZWVqaysbMDnNm7cOOS1jz322EjeEkAUMdcZyRob/JoRqe/CZ4QRIBbQhQEg6MypvZkh7BmRmN4LxArCCICgM6f2ZoWqZoRVWIGYQhgBEHTNIdqx1+RK61mFtZ2eESAWEEYABFWX16e2EG2SZzKHaagZAWIDYQRAULUcD90meaacngLWxna3fD5WYQWiHWEEQFCZa4ykJycqwRGaXzHZqU7ZbFKXz/BPIwYQvQgjAILqiH9ab+iWaU902DV+LLv3ArGCMAIgqHqn9YZmiMbUu9YIRaxAtCOMAAgq/7TeEBWvmlxM7wViBmEEQFD5l4IP8W66Zs8IC58B0Y8wAiCojoR4jRFTTlpPzwg79wJRjzACIKjMAtbQ94yw1ggQKwgjAIKqt2cktGEkJ41hGiBWEEYABNWRY+EJI/6eEYZpgKhHGAEQVOFYZ0TqLWBtbHfLyyqsQFQjjAAIqlBvkmcan+qU3Sb5DOmjowzVANGMMAIgaLo3yQtPAavDbtME6kaAmEAYARA0rcc7ZfSMmGSGaJO8vlj4DIgNhBEAQWPWi6QnJ4Rsk7y+WGsEiA2EEQBBY86kCXXxqolVWIHYQBgBEDS9m+SFK4yw8BkQCwgjAIKmJcw9I70LnxFGgGhGGAEQNM0d3TUjmSGe1mvqXfiMYRogmhFGAASNv2ckTMM0OdSMADGBMAIgaPwLnoWtgLW7Z+SjDrc6vb6wvCeA4COMAAiacO1LY8pKSVKC3SbDkJpYhRWIWoQRAEHTuy9NeGpG7HYbu/cCMYAwAiBojoR5aq8k5bAKKxD1CCMAgibci55JvQufsdYIEL0IIwCCwusz1HI8vFN7pb770zBMA0SrEYWR1atXKz8/X8nJySoqKtKWLVsGPffpp5/W/PnzlZmZqbFjx6qgoEC//vWvR9xgAJGp7yZ54SpglVj4DIgFAYeR9evXq7y8XJWVldq6davmzJmjhQsXqqGhYcDzs7Ky9P3vf181NTV6++23VVpaqtLSUr3wwgujbjyAyGEO0aQlJygxDJvkmXJY+AyIegH/xli5cqWWLVum0tJSzZo1S2vWrFFKSorWrVs34PmXXHKJvvSlL+ncc8/V9OnTdfPNN+v888/Xpk2bRt14AJHDLF4NZ6+I1HeYhp4RIFoFFEY8Ho9qa2tVUlLS+wJ2u0pKSlRTU3Pa6w3DUHV1tXbu3KmLLrpo0PPcbrfa2tr6PQBENnNab7gWPDP5C1jpGQGiVkBhpKmpSV6vVy6Xq99xl8ulurq6Qa9rbW1VamqqkpKSdMUVV+jBBx/UZz7zmUHPr6qqUkZGhv+Rl5cXSDMBWKC3ZyR8xauS5Err7hlp7vDI3eUN63sDCI6wDOympaVp27ZteuONN/STn/xE5eXl2rhx46DnV1RUqLW11f/Yv39/OJoJYBSaw7wvjSkzJVFJPTUqjfSOAFEpIZCTs7Oz5XA4VF9f3+94fX29cnNzB73ObrfrrLPOkiQVFBRo+/btqqqq0iWXXDLg+U6nU06nM5CmAbCYfyn4MA/T2Gw25aQ7deDIcdW3uXXGuJSwvj+A0QuoZyQpKUnz5s1TdXW1/5jP51N1dbWKi4uH/To+n09uN/+CAWKJVcM0Um8RKwufAdEpoJ4RSSovL9fSpUs1f/58FRYWatWqVero6FBpaakkacmSJZo8ebKqqqokddd/zJ8/X9OnT5fb7dbzzz+vX//61/rlL38Z3DsBYCmrClil3iJWZtQA0SngMLJo0SI1NjZqxYoVqqurU0FBgTZs2OAvat23b5/s9t4Ol46ODn3zm9/UgQMHNGbMGM2cOVOPP/64Fi1aFLy7AGA5q6b2SlJOTxFrPTUjQFQKOIxIUllZmcrKygZ87uTC1B//+Mf68Y9/PJK3ARBF/DUjVoQRekaAqMbeNACCwhymCecmeSZzei+zaYDoRBgBMGo+n6GWY9YXsNIzAkQnwgiAUWs70SlfzyZ5mRYM0/QWsNIzAkQjwgiAUWvuKV5NdSYoKSH8v1bMzfJaj3fqRCersALRhjACYNR6p/WGf4hGktKTE5Sc2P3rrIHeESDqEEYAjJo5rTfcS8GbbDZbb91IO3UjQLQhjAAYNXNfGivqRUzmjBqKWIHoQxgBMGrmTBorpvWaJlDECkQtwgiAUWvu6K4ZybRgWq/J7Blhfxog+hBGAIyav2fEymGanp6RBhY+A6IOYQTAqJlTe63YJM/EwmdA9CKMABg1K/elMbE/DRC9CCMARs3qdUak3p4R1hkBog9hBMComeuMWNkzYoaRdneXOtxdlrUDQOAIIwBGxecz1HLcuh17TanOBI1NckiiiBWINoQRAKPSfqJL3p5d8qyc2itRxApEK8IIgFExV18dm+SQM8FhaVsmpFHECkQjwgiAUfHPpLFwiMZEESsQnQgjAEYlEopXTb0Ln9EzAkQTwgiAUemd1hsJYcSsGaFnBIgmhBEAo9LbM2Jt8aok5VDACkQlwgiAUWmOgNVXTa409qcBohFhBMCo+DfJi6hhmhMyDMPi1gAYLsIIgFFpjqhhmu6ekWMer46yCisQNQgjAEYlkgpYU5ISlOZMkEQRKxBNCCMARiWSpvZKvb0jDRSxAlGDMAJgVI5EUAGr1KduhLVGgKhBGAEwYoZh+IdpIqGAVWIVViAaEUYAjFhbBG2SZzKHaagZAaIHYQTAiJnTelOSHEpOtHaTPJMrjWEaINqMKIysXr1a+fn5Sk5OVlFRkbZs2TLouY888oguvPBCjRs3TuPGjVNJScmQ5wOIHs0RVrwq9R2mIYwA0SLgMLJ+/XqVl5ersrJSW7du1Zw5c7Rw4UI1NDQMeP7GjRu1ePFivfzyy6qpqVFeXp4uu+wyHTx4cNSNB2CtFv+03sgYopF6N8tjmAaIHgGHkZUrV2rZsmUqLS3VrFmztGbNGqWkpGjdunUDnv+b3/xG3/zmN1VQUKCZM2fqv/7rv+Tz+VRdXT3qxgOwViT3jLAKKxA9AgojHo9HtbW1Kikp6X0Bu10lJSWqqakZ1mscO3ZMnZ2dysrKCqylACJOpE3rlaQJPfvTuLt8ajvOKqxANAgojDQ1Ncnr9crlcvU77nK5VFdXN6zXuO222zRp0qR+geZkbrdbbW1t/R4AIs+RCNqXxpSc6FDGmO5hI4pYgegQ1tk099xzj5588kn9/ve/V3Jy8qDnVVVVKSMjw//Iy8sLYysBDFdzR3fNSKRM6zX11o0QRoBoEFAYyc7OlsPhUH19fb/j9fX1ys3NHfLa+++/X/fcc4/+/Oc/6/zzzx/y3IqKCrW2tvof+/fvD6SZAMIkknbs7YuFz4DoElAYSUpK0rx58/oVn5rFqMXFxYNed++99+pHP/qRNmzYoPnz55/2fZxOp9LT0/s9AESeSCxglaQc1hoBokpCoBeUl5dr6dKlmj9/vgoLC7Vq1Sp1dHSotLRUkrRkyRJNnjxZVVVVkqSf/vSnWrFihZ544gnl5+f7a0tSU1OVmpoaxFsBEG6RWMAq9Q7T0DMCRIeAw8iiRYvU2NioFStWqK6uTgUFBdqwYYO/qHXfvn2y23s7XH75y1/K4/HoK1/5Sr/Xqays1A9/+MPRtR6ApY5E4DojUv/pvQAiX8BhRJLKyspUVlY24HMbN27s9/2ePXtG8hYAIpxhGDoSocM0FLAC0YW9aQCMyFF3l7p6NsmLtDCS4+8ZYZgGiAaEEQAjcqRnWu+YRIfGJEXGJnmmnJ6FzxraWYUViAaEEQAj0uwvXo2sehGpdxXWTq/hr2sBELkIIwBGxD+TJsLWGJEkZ4LDv/YJdSNA5COMABiRSC1eNZlDNXs/6rC4JQBOhzACYER6p/VGZhhZMD1bkvTY5j3WNgTAaRFGAIyI2TOSFYE1I5K07KKpSnTY9NqHzXpjT7PVzQEwBMIIgBExC1gzI3SYZmLGGH1lXvcmm7/4yy6LWwNgKIQRACMSqZvk9XXTxdPlsNv0yvuNevtAi9XNATAIwgiAETE3ycuM0GEaSZoyPkVfLJgkid4RIJIRRgCMSEtPAWsk94xI0jcvOUs2m/Tnv9drR12b1c0BMADCCIARaY7wqb2ms3JS9bnzJkqSVr/8gcWtATAQwgiAgBmGEdGLnp2s7FNnSZL++PYhfdB41OLWADgZYQRAwDo8XnV6u/d8yYrwnhFJOndiukrOzZFhSL/cSO8IEGkIIwACZq4x4kywR9wmeYNZ3tM78vu3Dmp/8zGLWwOgL8IIgIAdiYJpvSebO2WcLjw7W16foTWv0DsCRBLCCICA9U7rjZ4wIvXWjjz15gE20AMiCGEEQMB6e0Yid42RgRRNG6/C/Cx5vD49/OqHVjcHQA/CCICAHeno2SQvynpGJKns0929I795fa8+Ouq2uDUAJMIIgBHwT+uNwjBy4dnZmnNGhk50+rR2026rmwNAhBEAIxBNa4yczGazqezTZ0uS/rtmr1p7VpIFYB3CCICA9Q7TRFfNiOnSmTmamZumo+4uPbZ5j9XNAeIeYQRAwKJxam9fdrvNXzuy7q+7ddTdZXGLgPhGGAEQsGjZl2Yol8+eqGkTxqr1eKcef22v1c0B4hphBEDAormA1eSw27T8ku7ekf/6vw913OO1uEVA/CKMAAhI9yZ5PTUjUbbOyMm+UDBJZ4wbo6ajHj35xj6rmwPELcIIgIAc83jl6fJJiu6eEUlKdNh10yXTJUkPvfKh3F30jgBWIIwACIg5RJOUYFdKlGySN5SvzDtDrnSn6tpO6P/VHrS6OUBcIowACIg5rTcrJUk2m83i1oyeM8Ghr1/U3Tvynxt3qdPrs7hFQPwhjAAISPMxc5O86K4X6Wtx4RSNH5ukA0eO6w/bDlndHCDuEEYABKQlytcYGciYJIduvHCaJGn1xl3y+gyLWwTElxGFkdWrVys/P1/JyckqKirSli1bBj33vffe05e//GXl5+fLZrNp1apVI20rgAgQC2uMDOSrH5+ijDGJ+rCxQxverbO6OUBcCTiMrF+/XuXl5aqsrNTWrVs1Z84cLVy4UA0NDQOef+zYMU2bNk333HOPcnNzR91gANaKlWm9J0tLTlTpJ/IlSQ/+5R8yDHpHgHAJOIysXLlSy5YtU2lpqWbNmqU1a9YoJSVF69atG/D8Cy64QPfdd5+uueYaOZ3OUTcYgLWO9PSMZMVYz4gk/euCfKU6E7Sjrl3V2wf+BxaA4AsojHg8HtXW1qqkpKT3Bex2lZSUqKamJmiNcrvdamtr6/cAEBl6C1hjL4xkpiTp+uIzJUkPvryL3hEgTAIKI01NTfJ6vXK5XP2Ou1wu1dUFb4y1qqpKGRkZ/kdeXl7QXhvA6MRiAWtfN3xyqpIT7frb/hZt2tVkdXOAuBCRs2kqKirU2trqf+zfv9/qJgHo0dyzzkgsTe3tKzvVqWsLe3pH/rLL4tYA8SGgMJKdnS2Hw6H6+vp+x+vr64NanOp0OpWent7vASAyxHrPiCR97aJpSnLYtWV3s17/8COrmwPEvIDCSFJSkubNm6fq6mr/MZ/Pp+rqahUXFwe9cQAii2EYMTu1t6/cjGR9Zf4ZkqRfvEzvCBBqAQ/TlJeX65FHHtGvfvUrbd++XTfddJM6OjpUWloqSVqyZIkqKir853s8Hm3btk3btm2Tx+PRwYMHtW3bNu3axQ84EG2Od3rlNjfJi+GeEUm66eLpctht+r9/NGnb/harmwPEtIDDyKJFi3T//fdrxYoVKigo0LZt27RhwwZ/Ueu+fft0+PBh//mHDh3S3LlzNXfuXB0+fFj333+/5s6dqxtvvDF4dwEgLMw1RpIcdo2NgU3yhpKXlaKrCiZLkn5B7QgQUgkjuaisrExlZWUDPrdx48Z+3+fn5zM9DogR5hojmSmJMbFJ3ul881PT9fRbB/TS9nr9/VCbZk2ifg0IhYicTQMgMh2Jg+LVvqZPSNUV502U1L1nDYDQIIwAGLZ4KF492fJPnSVJev6dw9rVcNTi1gCxiTACYNjMYZpY25dmKOdOTNdnZrlkGNJ/0jsChARhBMCw+TfJi6OeEUkq6+kdeXbbIe376JjFrQFiD2EEwLCZNSPxFkbm5GXqonMmyOsz9MtXPrC6OUDMIYwAGDZ/z0icFLD29a1Pd/eO/L/aAzrcetzi1gCxhTACYNjMmpGsOKoZMV2Qn6WiqVnyeH16+NUPrW4OEFMIIwCGzRymyYyzYRrTtz59tiTpf7bsU2O72+LWALGDMAJg2Pw9I3EaRj5x1njNycvUiU6ffl79vnw+FnQEgoEwAmDYmuO0gNVks9n07Z7akcdf26drHn6NtUeAICCMABiW4x6vTnSam+TFX82I6dJzXbrzCx9TSpJDW/Y063M//z+teul9ubu8VjcNiFqEEQDDYtaLJNhtSnWOaFurmLF0Qb7+fMtF+tSMCfJ4fVr10j90xX9s0ht7mq1uGhCVCCMAhsW/xsjYpLjYJO90zhiXonX/eoEeXDxX2alJ2tVwVFevqdH3fv+OWo93Wt08IKoQRgAMy5GO7r9g47V4dSA2m01Xzpmkl8ov1qL5eZKkJ17fp8+sfEV/eucwO5YDw0QYATAszf5pvfFbLzKYzJQk/fQr5+t/ln1c07LHqqHdrZt+s1XL/ruWBdKAYSCMABiWlmPmgmf0jAymePp4PX/zhfrWp89Sgt2ml7bX6zMrX9WvNu+Rl2nAwKAIIwCGpbkjvhc8G67kRIduvWyGnvv2hfqnKZk66u5S5R/e01fWbNaOujarmwdEJMIIgGFp6dmXJh6Xgh+JGblp+t03FuhHX/yYUp0Jemtfiz7/H5t03ws7dKKTacBAX4QRAMNi9ozE64JnI2G323R9cb5eKr9Yl81yqctnaPXLH+jyn/+fNn/QZHXzgIhBGAEwLEfifPXV0cjNSNbDS+ZrzVfnKSfNqd1NHbr2kdf13af+5q/FAeIZYQTAsByhgHXUPjs7Vy/derG++vEpkqSnag+oZOUrenbbQaYBI64RRgAMi7nOCFN7Ryc9OVE/vuo8/e4bxTo7J1VNRz26+cltKn3sDe1vPmZ18wBLEEYADAs9I8E1Pz9Lf/z2J1X+mXOU5LBr485GXfbAq3rolQ/U0HbC6uYBYRXfG0wAGJYTnV4d83TPABlHGAkaZ4JD3770bF1x/kRVPP2OtuxuVtWfdqjqTzs0NXusCvOzVDQtS4VTs3TGuBSrmwuEDGEEwGn13SQvLc43yQuF6RNS9eSyj+u3b+7Xr1/bq78fbtPupg7tburQ+jf3S5ImZ45R0dTuYFI4NUtTs8eyRxBiBr9VAJxWb70Im+SFit1u0zWFU3RN4RS1Hu9U7d5mvb67WVt2N+udA6062HJcT791UE+/dVCSNCHNqcKpWf6Ack5Omux2PhtEJ8IIgNPqndZL8Wo4ZIxJ1KdnuvTpmS5JUoe7S2/ta9GW3R/ptd3N2ra/RY3tbj339mE99/ZhSd2FxRfk94aTWRPTleCgLBDRgTAC4LT8YYR6EUuMdSbok2dn65NnZ0vqruH52/4WbdndrC17mvXmniNqOdapF/9erxf/Xi9JSnUmaN6Z41Q4NUsfn5al8yZnKimBcILIRBgBcFpHelZfzWLBs4iQnOhQ0bTxKpo2XpLU6fXp3YOt2rK7e2jnjT3Naj/RpVfeb9Qr7zf2XGPX2Tlpys1IVm56snIzkjWxz9e5GclKSeKvBFiD//MAnFZzT83IOPaliUiJDrvmThmnuVPG6esXT5fXZ2j74bbunpOe3pPmDo/eOdiqdw62Dvo6GWMS+wUVV3pPYMlI1sSMMcpNT1b6mATqhhB0Iwojq1ev1n333ae6ujrNmTNHDz74oAoLCwc9/6mnntIdd9yhPXv26Oyzz9ZPf/pTfe5znxtxowGEF0vBRxeH3abZkzM0e3KG/u2TU2UYhj5oPKo9Tcd0uO2E6lqPq67Vrbq24zrcekJ1rSd0zONV6/FOtR7v1M769kFfe0yi45Sg4uoJKWOTEpSanKA0Z6LGOh3+r5MT7QQYDCngMLJ+/XqVl5drzZo1Kioq0qpVq7Rw4ULt3LlTOTk5p5y/efNmLV68WFVVVfr85z+vJ554QldddZW2bt2q2bNnB+UmAIQWYSS62Ww2nZWTprNy0gZ83jAMtbu7VNcTTOpaT3SHlLbjfb4+oZZjnTre6dWHTR36sKlj2O9vt3XXsKQl94QUZ4JSkxOV5kzo+T5RqckJSh3g6zGJDjkT7Upy2JWUYJczofvPpITuY4Sc2GAzAtwQoaioSBdccIF+8YtfSJJ8Pp/y8vL0rW99S7fffvsp5y9atEgdHR364x//6D/28Y9/XAUFBVqzZs2w3rOtrU0ZGRlqbW1Venp6IM0FEARL1m3Rq+836v6r5+gr884I3gt3dEipqd1fHz0qjR0bvNdG0J3o9PrDSX1bT0hpPa6GdreOurvUfqJLR91d6nB36eiJLh31dCnUW+4kJdjlHCioJNjlTHAMGGKcPUEmwWFXgt2mBIdNDnv31w67rf+fDrsSze8HOS/RYe/3vcNuk93W/ej+unvqtt1mk8Nmk82m3nPs8h/v+/3Jz9lsisrgNdy/vwPqGfF4PKqtrVVFRYX/mN1uV0lJiWpqaga8pqamRuXl5f2OLVy4UM8888yg7+N2u+V2u/3ft7W1BdLMYVu7abcOHGEvCOB0th/u/hnMomYkriUnOpSfPVb52cMLjT6foeOdXn9Q6XB3nfK1/3Fi4K+Pe7zyeH3ydPnk7vKq09s/3Xi6up+Te5BGxBC7rTucmMHEpt7v7T3fm8/Z+/wpmd/3Bh1Jstslm3rPfXDxXM2enGHJvQUURpqamuT1euVyufodd7lc2rFjx4DX1NXVDXh+XV3doO9TVVWlO++8M5Cmjchzbx/S1n0tIX8fIFZMzBgT3BccO1Yh/6czLGO32zTWmaCxzgS5gtSp7fMZ3eHE65O709cvqJjBpPv77sdQz3f5DHl95p9G959ew3+886Tv+53nM9TlHeCYzyev15DPkLyGIcPoPu4zutvuMwx5jf7f+4b5I+AzJJ//5yX4PzedXl/QX3O4InI2TUVFRb/elLa2NuXl5QX9fb487wwVTx8f9NcFYlH++LE6dyLDpLCW3W5Tst2h5ESHlGx1a4LDMAwZPeHFZxjy+eQPLUafr30+Q4a6vzeM3j8NQzLUHWoMf7gxv+9/vnquH+jcs10D1xSFQ0BhJDs7Ww6HQ/X19f2O19fXKzc3d8BrcnNzAzpfkpxOp5xOZyBNG5Hris4M+XsAADAUmznUouirCQmWgJbjS0pK0rx581RdXe0/5vP5VF1dreLi4gGvKS4u7ne+JL344ouDng8AAOJLwMM05eXlWrp0qebPn6/CwkKtWrVKHR0dKi0tlSQtWbJEkydPVlVVlSTp5ptv1sUXX6yf/exnuuKKK/Tkk0/qzTff1MMPPxzcOwEAAFEp4DCyaNEiNTY2asWKFaqrq1NBQYE2bNjgL1Ldt2+f7PbeDpcFCxboiSee0A9+8AN973vf09lnn61nnnmGNUYAAICkEawzYgXWGQEAIPoM9+9vtnAEAACWIowAAABLEUYAAIClCCMAAMBShBEAAGApwggAALAUYQQAAFiKMAIAACxFGAEAAJYKeDl4K5iLxLa1tVncEgAAMFzm39unW+w9KsJIe3u7JCkvL8/ilgAAgEC1t7crIyNj0OejYm8an8+nQ4cOKS0tTTabLWiv29bWpry8PO3fvz9m97yJ9Xvk/qJfrN8j9xf9Yv0eQ3l/hmGovb1dkyZN6reJ7smiomfEbrfrjDPOCNnrp6enx+T/YH3F+j1yf9Ev1u+R+4t+sX6Pobq/oXpETBSwAgAASxFGAACApeI6jDidTlVWVsrpdFrdlJCJ9Xvk/qJfrN8j9xf9Yv0eI+H+oqKAFQAAxK647hkBAADWI4wAAABLEUYAAIClCCMAAMBSMR9GfvKTn2jBggVKSUlRZmbmgOfs27dPV1xxhVJSUpSTk6Pvfve76urqGvJ1m5ubdd111yk9PV2ZmZm64YYbdPTo0RDcwfBt3LhRNpttwMcbb7wx6HWXXHLJKed/4xvfCGPLA5Ofn39Ke++5554hrzlx4oSWL1+u8ePHKzU1VV/+8pdVX18fphYP3549e3TDDTdo6tSpGjNmjKZPn67Kykp5PJ4hr4v0z3D16tXKz89XcnKyioqKtGXLliHPf+qppzRz5kwlJyfrvPPO0/PPPx+mlgamqqpKF1xwgdLS0pSTk6OrrrpKO3fuHPKaxx577JTPKjk5OUwtDtwPf/jDU9o7c+bMIa+Jls9PGvj3ic1m0/Llywc8P9I/v1dffVVXXnmlJk2aJJvNpmeeeabf84ZhaMWKFZo4caLGjBmjkpIS/eMf/zjt6wb6MxyomA8jHo9HV199tW666aYBn/d6vbriiivk8Xi0efNm/epXv9Jjjz2mFStWDPm61113nd577z29+OKL+uMf/6hXX31VX/va10JxC8O2YMECHT58uN/jxhtv1NSpUzV//vwhr122bFm/6+69994wtXpk7rrrrn7t/da3vjXk+bfccov+93//V0899ZReeeUVHTp0SP/8z/8cptYO344dO+Tz+fTQQw/pvffe0wMPPKA1a9boe9/73mmvjdTPcP369SovL1dlZaW2bt2qOXPmaOHChWpoaBjw/M2bN2vx4sW64YYb9NZbb+mqq67SVVddpXfffTfMLT+9V155RcuXL9drr72mF198UZ2dnbrsssvU0dEx5HXp6en9Pqu9e/eGqcUj87GPfaxfezdt2jToudH0+UnSG2+80e/eXnzxRUnS1VdfPeg1kfz5dXR0aM6cOVq9evWAz9977736j//4D61Zs0avv/66xo4dq4ULF+rEiRODvmagP8MjYsSJRx991MjIyDjl+PPPP2/Y7Xajrq7Of+yXv/ylkZ6ebrjd7gFf6+9//7shyXjjjTf8x/70pz8ZNpvNOHjwYNDbPlIej8eYMGGCcddddw153sUXX2zcfPPN4WlUEJx55pnGAw88MOzzW1pajMTEROOpp57yH9u+fbshyaipqQlBC4Pr3nvvNaZOnTrkOZH8GRYWFhrLly/3f+/1eo1JkyYZVVVVA57/L//yL8YVV1zR71hRUZHx9a9/PaTtDIaGhgZDkvHKK68Mes5gv4siVWVlpTFnzpxhnx/Nn59hGMbNN99sTJ8+3fD5fAM+H02fnyTj97//vf97n89n5ObmGvfdd5//WEtLi+F0Oo3/+Z//GfR1Av0ZHomY7xk5nZqaGp133nlyuVz+YwsXLlRbW5vee++9Qa/JzMzs19tQUlIiu92u119/PeRtHq4//OEP+uijj1RaWnrac3/zm98oOztbs2fPVkVFhY4dOxaGFo7cPffco/Hjx2vu3Lm67777hhxWq62tVWdnp0pKSvzHZs6cqSlTpqimpiYczR2V1tZWZWVlnfa8SPwMPR6Pamtr+/23t9vtKikpGfS/fU1NTb/zpe6fyWj5rCSd9vM6evSozjzzTOXl5emLX/zioL9rIsU//vEPTZo0SdOmTdN1112nffv2DXpuNH9+Ho9Hjz/+uP7t3/5tyE1Zo+3zM+3evVt1dXX9Pp+MjAwVFRUN+vmM5Gd4JKJio7xQqqur6xdEJPm/r6urG/SanJycfscSEhKUlZU16DVWWLt2rRYuXHjaTQavvfZanXnmmZo0aZLefvtt3Xbbbdq5c6eefvrpMLU0MN/+9rf1T//0T8rKytLmzZtVUVGhw4cPa+XKlQOeX1dXp6SkpFNqhlwuV0R9XgPZtWuXHnzwQd1///1Dnhepn2FTU5O8Xu+AP2M7duwY8JrBfiYj/bPy+Xz6zne+o0984hOaPXv2oOfNmDFD69at0/nnn6/W1lbdf//9WrBggd57772Qbgg6UkVFRXrsscc0Y8YMHT58WHfeeacuvPBCvfvuu0pLSzvl/Gj9/CTpmWeeUUtLi/71X/910HOi7fPry/wMAvl8RvIzPBJRGUZuv/12/fSnPx3ynO3bt5+2yCpajOR+Dxw4oBdeeEG//e1vT/v6fWtdzjvvPE2cOFGXXnqpPvjgA02fPn3kDQ9AIPdYXl7uP3b++ecrKSlJX//611VVVRWxyzWP5DM8ePCgPvvZz+rqq6/WsmXLhrw2Ej7DeLd8+XK9++67Q9ZTSFJxcbGKi4v93y9YsEDnnnuuHnroIf3oRz8KdTMDdvnll/u/Pv/881VUVKQzzzxTv/3tb3XDDTdY2LLgW7t2rS6//HJNmjRp0HOi7fOLFlEZRm699dYhk6skTZs2bVivlZube0pVsDnLIjc3d9BrTi7c6erqUnNz86DXjMZI7vfRRx/V+PHj9YUvfCHg9ysqKpLU/a/ycP1FNprPtKioSF1dXdqzZ49mzJhxyvO5ubnyeDxqaWnp1ztSX18fks9rIIHe36FDh/SpT31KCxYs0MMPPxzw+1nxGQ4kOztbDofjlJlLQ/23z83NDej8SFBWVuYvZA/0X8eJiYmaO3eudu3aFaLWBVdmZqbOOeecQdsbjZ+fJO3du1cvvfRSwL2J0fT5mZ9BfX29Jk6c6D9eX1+vgoKCAa8Zyc/wiASt+iTCna6Atb6+3n/soYceMtLT040TJ04M+FpmAeubb77pP/bCCy9ETAGrz+czpk6datx6660jun7Tpk2GJONvf/tbkFsWGo8//rhht9uN5ubmAZ83C1h/97vf+Y/t2LEjYgtYDxw4YJx99tnGNddcY3R1dY3oNSLpMywsLDTKysr833u9XmPy5MlDFrB+/vOf73esuLg4IgsgfT6fsXz5cmPSpEnG+++/P6LX6OrqMmbMmGHccsstQW5daLS3txvjxo0zfv7znw/4fDR9fn1VVlYaubm5RmdnZ0DXRfLnp0EKWO+//37/sdbW1mEVsAbyMzyitgbtlSLU3r17jbfeesu48847jdTUVOOtt94y3nrrLaO9vd0wjO7/kWbPnm1cdtllxrZt24wNGzYYEyZMMCoqKvyv8frrrxszZswwDhw44D/22c9+1pg7d67x+uuvG5s2bTLOPvtsY/HixWG/v4G89NJLhiRj+/btpzx34MABY8aMGcbrr79uGIZh7Nq1y7jrrruMN99809i9e7fx7LPPGtOmTTMuuuiicDd7WDZv3mw88MADxrZt24wPPvjAePzxx40JEyYYS5Ys8Z9z8j0ahmF84xvfMKZMmWL85S9/Md58802juLjYKC4utuIWhnTgwAHjrLPOMi699FLjwIEDxuHDh/2PvudE02f45JNPGk6n03jssceMv//978bXvvY1IzMz0z+D7frrrzduv/12//l//etfjYSEBOP+++83tm/fblRWVhqJiYnGO++8Y9UtDOqmm24yMjIyjI0bN/b7rI4dO+Y/5+T7u/POO40XXnjB+OCDD4za2lrjmmuuMZKTk4333nvPils4rVtvvdXYuHGjsXv3buOvf/2rUVJSYmRnZxsNDQ2GYUT352fyer3GlClTjNtuu+2U56Lt82tvb/f/PSfJWLlypfHWW28Ze/fuNQzDMO655x4jMzPTePbZZ423337b+OIXv2hMnTrVOH78uP81Pv3pTxsPPvig//vT/QwHQ8yHkaVLlxqSTnm8/PLL/nP27NljXH755caYMWOM7Oxs49Zbb+2Xjl9++WVDkrF7927/sY8++shYvHixkZqaaqSnpxulpaX+gGO1xYsXGwsWLBjwud27d/e7/3379hkXXXSRkZWVZTidTuOss84yvvvd7xqtra1hbPHw1dbWGkVFRUZGRoaRnJxsnHvuucbdd9/drxfr5Hs0DMM4fvy48c1vftMYN26ckZKSYnzpS1/q9xd8pHj00UcH/P+1bydmNH6GDz74oDFlyhQjKSnJKCwsNF577TX/cxdffLGxdOnSfuf/9re/Nc455xwjKSnJ+NjHPmY899xzYW7x8Az2WT366KP+c06+v+985zv+/xYul8v43Oc+Z2zdujX8jR+mRYsWGRMnTjSSkpKMyZMnG4sWLTJ27drlfz6aPz/TCy+8YEgydu7cecpz0fb5mX9fnfww78Hn8xl33HGH4XK5DKfTaVx66aWn3PeZZ55pVFZW9js21M9wMNgMwzCCN+gDAAAQmLhfZwQAAFiLMAIAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAAS/1/gCPG+bZHva0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import f\n",
    "from scipy.stats import lognorm\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_filter(size, **args):\n",
    "    indices = np.arange(-size, size+1, 1)\n",
    "    weights =  norm.pdf(indices, **args)\n",
    "    return weights# / np.sum(weights)\n",
    "\n",
    "\n",
    "def f_filter(size, **args):\n",
    "    indices = np.arange(-size, size+1, 1)\n",
    "    print(indices)\n",
    "    weights = f.pdf(indices+1, **args)\n",
    "    return weights# / np.sum(weights)\n",
    "def lognorm_filter(size, **args):\n",
    "    #print(args)\n",
    "    indices = np.arange(-size, size+1, 1)\n",
    "    #print(indices)\n",
    "    weights = lognorm.pdf(indices+1, **args)\n",
    "    return weights / np.sum(weights)\n",
    "\n",
    "\n",
    "\n",
    "with open(\"./configs/random_10M_2024\") as f:\n",
    "    config = json.load(f)\n",
    "    print(config)\n",
    "config[\"influence_output_dir\"] = os.path.join(\"./influence\", os.path.basename(config[\"curriculum_path\"]))\n",
    "dataset = datasets.load_from_disk(config[\"dataset_folder\"])\n",
    "df = pd.DataFrame({int(result_checkpoint): torch.load(os.path.join(config[\"influence_output_dir\"],result_checkpoint),weights_only=True,map_location=\"cpu\").numpy().flatten() for result_checkpoint in os.listdir(config[\"influence_output_dir\"])})\n",
    "df.sort_index(axis=1)\n",
    "\n",
    "df = df.reindex(sorted(df.columns, reverse=False), axis=1)\n",
    "influence_cols = df.columns\n",
    "df[\"total\"] = df.sum(axis=1)\n",
    "df[[\"text\", \"source\"]] = dataset.to_pandas()\n",
    "df[\"document_lenght\"] = df[\"text\"].str.split(r\"\\S+\").str.len()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reweight_df(df, influence_cols, filter_weights):\n",
    "    scores = pd.DataFrame(np.apply_along_axis(lambda m: np.convolve(m,filter_weights, mode=\"valid\")[1:-1], axis=1, arr=df[influence_cols].to_numpy()))\n",
    "    scores.columns = influence_cols\n",
    "    df_reweighted = df.copy()\n",
    "    df_reweighted[influence_cols] = scores\n",
    "    df_reweighted[\"total\"] = df_reweighted[influence_cols].sum(axis=1)\n",
    "    return df_reweighted\n",
    "\n",
    "\n",
    "\n",
    "filter_weights = lognorm_filter(len(influence_cols), s=1, loc=0, scale=0.5)\n",
    "plt.plot(np.arange(-len(influence_cols),len(influence_cols)+1, 1),filter_weights)\n",
    "plt.vlines([0], ymin=0, ymax=max(filter_weights)+0.1, colors=[\"red\"])\n",
    "df_reweighted = reweight_df(df, influence_cols, lognorm_filter(len(influence_cols), s=1, loc=0, scale=0.5))\n",
    "display(df_reweighted)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'source'],\n",
       "    num_rows: 1179014\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'packed_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mpacked_dataset\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'packed_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "len(packed_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset_folder\": config[\"dataset_folder\"],   \n",
    "}\n",
    "args[\"raw_dataset_folder_babylm\"] = \"./train_10M\"\n",
    "args[\"curriculum_path\"] = \"./curricula/lognorm_curriculum_from_random_10M_2024\"\n",
    "args[\"eval_dataset_folder\"] = config[\"eval_dataset_folder\"]\n",
    "args[\"epochs\"] = config[\"epochs\"]\n",
    "\n",
    "torch.save(torch.stack([torch.tensor(df[checkpoint].sort_values(ascending=False).index.to_numpy()) for checkpoint in influence_cols]), args[\"curriculum_path\"])\n",
    "\n",
    "\n",
    "with open(\"./configs/lognorm_curriculum_from_random_10M_2024\", 'w') as f:\n",
    "    json.dump(args, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
