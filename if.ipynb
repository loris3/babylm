{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting extract_gradients.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile extract_gradients.py\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "parser = argparse.ArgumentParser(\"gradient_extraction\")\n",
    "parser.add_argument(\"dataset_folder\", help=\"Path to a dataset folder of .train files that can be read by calling load_dataset('text', <path>)\")\n",
    "parser.add_argument(\"model_dir\", help=\"Where the model and checkpoints are stored\")\n",
    "parser.add_argument(\"gradient_output_dir\", help=\"Where to save the gradients to\")\n",
    "\n",
    "\n",
    "parser.add_argument(\"--num_processes\", help=\"Number of processes to use (one model per process)\", type=int, nargs=\"?\", const=1, default=6)\n",
    "parser.add_argument(\"--cuda_visible_devices\", help=\"Comma seperated GPU ids to use\", nargs=\"?\", const=1, default=\"0,1\")\n",
    "parser.add_argument(\"--gradients_per_file\", help=\"Number of gradients per output file\", type=int, nargs=\"?\", const=1, default=10000)\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "if not os.path.exists(args.gradient_output_dir):\n",
    "    os.makedirs(args.gradient_output_dir)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda_visible_devices\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "\n",
    "\n",
    "from transformers import RobertaConfig,AutoConfig\n",
    "from transformers import RobertaForMaskedLM\n",
    "import torch\n",
    "\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(args.model_dir, max_len=512)\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "def get_loss_gradient(model, example,device):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    input_ids, labels = data_collator((torch.tensor(example),)).values() # TODO make static maybe probably\n",
    "    inputs_embeds=model.get_input_embeddings().weight[input_ids].to(device)\n",
    "    inputs_embeds.retain_grad()\n",
    "\n",
    "    outputs = model.forward(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            labels=labels.to(device)\n",
    "        )\n",
    "    loss = outputs.loss\n",
    "    loss.retain_grad()\n",
    "    return  torch.autograd.grad(loss, inputs_embeds, retain_graph=True)[0].squeeze()\n",
    "\n",
    "def get_for_checkpoint(checkpoint_path, i_start, i_end):\n",
    "    \n",
    "    try:\n",
    "        gpu_id = queue.get()\n",
    "        out_path = os.path.join(args.gradient_output_dir, checkpoint_path.split(\"-\")[-1] + \"_\" +  str(i_start) + \"_\" + str(i_end))\n",
    "        \n",
    "        if os.path.isfile(out_path):\n",
    "            queue.put(gpu_id)\n",
    "            return out_path\n",
    "\n",
    "        from datasets import load_dataset\n",
    "        dataset = load_dataset(\"text\", data_dir=args.dataset_folder)\n",
    "        dataset.set_transform(lambda x : tokenizer(x[\"text\"], return_special_tokens_mask=True, truncation=True, padding=\"max_length\", max_length=512))\n",
    "\n",
    "        device = \"cuda:\" + str(gpu_id)\n",
    "        config = AutoConfig.from_pretrained(checkpoint_path)\n",
    "        model = RobertaForMaskedLM(config=config).to(device)\n",
    "\n",
    "        gradients = [get_loss_gradient(model, example,device).to(torch.bfloat16) for example in tqdm(dataset[\"train\"][i_start:i_end][\"input_ids\"])]\n",
    "\n",
    "        torch.save( torch.stack(gradients), out_path)\n",
    "        queue.put(gpu_id)\n",
    "        return out_path\n",
    "    except Exception as e:\n",
    "        print(e,flush=True)\n",
    "\n",
    "from multiprocessing import Pool, current_process, Queue\n",
    "import time \n",
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(args.model_dir, max_len=512)\n",
    "\n",
    "\n",
    "from util import get_epoch_checkpoints\n",
    "checkpoints = [str(x) for x in Path(args.model_dir).glob(\"checkpoint-*\") if int(str(x).split(\"-\")[-1]) in get_epoch_checkpoints(args.model_dir)]\n",
    "print(\"checkpoints\", checkpoints)\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"text\", data_dir=args.dataset_folder)\n",
    "dataset.set_transform(lambda x : tokenizer(x[\"text\"], return_special_tokens_mask=True, truncation=True, padding=\"max_length\", max_length=512))\n",
    "\n",
    "\n",
    "import itertools\n",
    "queue = Queue()\n",
    "\n",
    "for _ in range(args.num_processes//torch.cuda.device_count()):\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        queue.put(i)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    tasks = list(itertools.chain(*[[(checkpoint,i, i + args.gradients_per_file) for i in range(0, len(dataset[\"train\"]), args.gradients_per_file)]  for checkpoint in checkpoints ]))\n",
    "    with Pool(args.num_processes) as p:\n",
    "        r = p.starmap_async(get_for_checkpoint, tasks, callback=print )\n",
    "        r.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Estimate\n",
    "For 10M 10 checkpoints (one per epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset_folder\": \"./train_10M\",\n",
    "    \"model_dir\": \"./10MModel\",\n",
    "    \"num_processes\": 4,\n",
    "    \"influence_output_dir\": \"./influence\",\n",
    "    \"curriculum_output_folder\": \"./10MCurriculum\",\n",
    "    \"gradient_input_dir\": \"./gradients\",\n",
    "    \"gradients_per_file\" : 10000,\n",
    "    \"epochs\" : 5,\n",
    "    \"batch_size\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325.6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(args[\"batch_size\"]+1)*args[\"num_processes\"]*7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run extract_gradients.py ./train_10M ./10MModel ./gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_PER_BATCH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.825116666666666 hours\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"text\", data_dir=args[\"dataset_folder\"])\n",
    "#dataset.set_transform(lambda x : tokenizer(x[\"text\"], return_special_tokens_mask=True, truncation=True, padding=\"max_length\", max_length=512))\n",
    "\n",
    "print(((((len(dataset[\"train\"]) / args[\"gradients_per_file\"]) *args[\"epochs\"]) /args[\"num_processes\"]) * TIME_PER_BATCH)/60, \"hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.826645875680556"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((((len(dataset[\"train\"]) / args[\"gradients_per_file\"]))**2))/args[\"batch_size\"]*args[\"epochs\"]*10)/args[\"num_processes\"]/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.660771308439167"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((((len(dataset[\"train\"]) / args[\"gradients_per_file\"]))**2)/10)*6.9)/60/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.73219254223077"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((((len(dataset[\"train\"]) / args[\"gradients_per_file\"]))**2))*args[\"epochs\"]*12)/args[\"batch_size\"]/args[\"num_processes\"]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3623518 TB\n"
     ]
    }
   ],
   "source": [
    "print((((len(dataset[\"train\"]) / args[\"gradients_per_file\"]) *args[\"epochs\"]) *7.4)/1000, \"TB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872.47036"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(dataset[\"train\"]) / args[\"gradients_per_file\"])*7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./gradients/589488_0_10000',\n",
       " './gradients/589488_10000_20000',\n",
       " './gradients/589488_20000_30000',\n",
       " './gradients/589488_30000_40000',\n",
       " './gradients/589488_40000_50000',\n",
       " './gradients/589488_50000_60000',\n",
       " './gradients/589488_60000_70000',\n",
       " './gradients/589488_70000_80000',\n",
       " './gradients/589488_80000_90000',\n",
       " './gradients/589488_90000_100000',\n",
       " './gradients/589488_100000_110000',\n",
       " './gradients/589488_110000_120000',\n",
       " './gradients/589488_120000_130000',\n",
       " './gradients/589488_130000_140000',\n",
       " './gradients/589488_140000_150000',\n",
       " './gradients/589488_150000_160000',\n",
       " './gradients/589488_160000_170000',\n",
       " './gradients/589488_170000_180000',\n",
       " './gradients/589488_180000_190000',\n",
       " './gradients/589488_190000_200000',\n",
       " './gradients/589488_200000_210000',\n",
       " './gradients/589488_210000_220000',\n",
       " './gradients/589488_220000_230000',\n",
       " './gradients/589488_230000_240000',\n",
       " './gradients/589488_240000_250000',\n",
       " './gradients/589488_250000_260000',\n",
       " './gradients/589488_260000_270000',\n",
       " './gradients/589488_270000_280000',\n",
       " './gradients/589488_280000_290000',\n",
       " './gradients/589488_290000_300000',\n",
       " './gradients/589488_300000_310000',\n",
       " './gradients/589488_310000_320000',\n",
       " './gradients/589488_320000_330000',\n",
       " './gradients/589488_330000_340000',\n",
       " './gradients/589488_340000_350000',\n",
       " './gradients/589488_350000_360000',\n",
       " './gradients/589488_360000_370000',\n",
       " './gradients/589488_370000_380000',\n",
       " './gradients/589488_380000_390000',\n",
       " './gradients/589488_390000_400000',\n",
       " './gradients/589488_400000_410000',\n",
       " './gradients/589488_410000_420000',\n",
       " './gradients/589488_420000_430000',\n",
       " './gradients/589488_430000_440000',\n",
       " './gradients/589488_440000_450000',\n",
       " './gradients/589488_450000_460000',\n",
       " './gradients/589488_460000_470000',\n",
       " './gradients/589488_470000_480000',\n",
       " './gradients/589488_480000_490000',\n",
       " './gradients/589488_490000_500000',\n",
       " './gradients/589488_500000_510000',\n",
       " './gradients/589488_510000_520000',\n",
       " './gradients/589488_520000_530000',\n",
       " './gradients/589488_530000_540000',\n",
       " './gradients/589488_540000_550000',\n",
       " './gradients/589488_550000_560000',\n",
       " './gradients/589488_560000_570000',\n",
       " './gradients/589488_570000_580000',\n",
       " './gradients/589488_580000_590000',\n",
       " './gradients/589488_590000_600000',\n",
       " './gradients/589488_600000_610000',\n",
       " './gradients/589488_610000_620000',\n",
       " './gradients/589488_620000_630000',\n",
       " './gradients/589488_630000_640000',\n",
       " './gradients/589488_640000_650000',\n",
       " './gradients/589488_650000_660000',\n",
       " './gradients/589488_660000_670000',\n",
       " './gradients/589488_670000_680000',\n",
       " './gradients/589488_680000_690000',\n",
       " './gradients/589488_690000_700000',\n",
       " './gradients/589488_700000_710000',\n",
       " './gradients/589488_710000_720000',\n",
       " './gradients/589488_720000_730000',\n",
       " './gradients/589488_730000_740000',\n",
       " './gradients/589488_740000_750000',\n",
       " './gradients/589488_750000_760000',\n",
       " './gradients/589488_760000_770000',\n",
       " './gradients/589488_770000_780000',\n",
       " './gradients/589488_780000_790000',\n",
       " './gradients/589488_790000_800000',\n",
       " './gradients/589488_800000_810000',\n",
       " './gradients/589488_810000_820000',\n",
       " './gradients/589488_820000_830000',\n",
       " './gradients/589488_830000_840000',\n",
       " './gradients/589488_840000_850000',\n",
       " './gradients/589488_850000_860000',\n",
       " './gradients/589488_860000_870000',\n",
       " './gradients/589488_870000_880000',\n",
       " './gradients/589488_880000_890000',\n",
       " './gradients/589488_890000_900000',\n",
       " './gradients/589488_900000_910000',\n",
       " './gradients/589488_910000_920000',\n",
       " './gradients/589488_920000_930000',\n",
       " './gradients/589488_930000_940000',\n",
       " './gradients/589488_940000_950000',\n",
       " './gradients/589488_950000_960000',\n",
       " './gradients/589488_960000_970000',\n",
       " './gradients/589488_970000_980000',\n",
       " './gradients/589488_980000_990000',\n",
       " './gradients/589488_990000_1000000',\n",
       " './gradients/589488_1000000_1010000',\n",
       " './gradients/589488_1010000_1020000',\n",
       " './gradients/589488_1020000_1030000',\n",
       " './gradients/589488_1030000_1040000',\n",
       " './gradients/589488_1040000_1050000',\n",
       " './gradients/589488_1050000_1060000',\n",
       " './gradients/589488_1060000_1070000',\n",
       " './gradients/589488_1070000_1080000',\n",
       " './gradients/589488_1080000_1090000',\n",
       " './gradients/589488_1090000_1100000',\n",
       " './gradients/589488_1100000_1110000',\n",
       " './gradients/589488_1110000_1120000',\n",
       " './gradients/589488_1120000_1130000',\n",
       " './gradients/589488_1130000_1140000',\n",
       " './gradients/589488_1140000_1150000',\n",
       " './gradients/589488_1150000_1160000',\n",
       " './gradients/589488_1160000_1170000',\n",
       " './gradients/589488_1170000_1180000']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[ os.path.join(args[\"gradient_input_dir\"], a + \"_\" + str(i) + \"_\" + str(i +args[\"gradients_per_file\"])) for i in range(0, len(dataset[\"train\"]), args[\"gradients_per_file\"])] for a in epoch_checkpoints]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.05405405405405"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "800/(2*7.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73688.375"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(dataset[\"train\"]) / (16))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.9014"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(dataset[\"train\"]) / args[\"gradients_per_file\"])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for x in Path(args[\"gradient_input_dir\"]).glob(\"*\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646.0279864372436"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((((len(dataset[\"train\"]) / args[\"gradients_per_file\"])**2)/args[\"num_processes\"])*5*29)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24562,\n",
       " 49124,\n",
       " 73686,\n",
       " 98248,\n",
       " 122810,\n",
       " 147372,\n",
       " 171934,\n",
       " 196496,\n",
       " 221058,\n",
       " 245620,\n",
       " 270182,\n",
       " 294744,\n",
       " 319306,\n",
       " 343868,\n",
       " 368430,\n",
       " 392992,\n",
       " 417554,\n",
       " 442116,\n",
       " 466678,\n",
       " 491240,\n",
       " 515802,\n",
       " 540364,\n",
       " 564926,\n",
       " 589488,\n",
       " 614050,\n",
       " 638612,\n",
       " 663174,\n",
       " 687736,\n",
       " 712298,\n",
       " 736860,\n",
       " 736890]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([int(str(x).split(\"-\")[-1]) for x in Path(args[\"model_dir\"]).glob(\"checkpoint-*\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[147372, 294744, 442116, 589488, 736890]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import util\n",
    "epoch_checkpoints = util.get_epoch_checkpoints(args[\"model_dir\"])\n",
    "epoch_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./gradients/147372_0_10000',\n",
       " './gradients/147372_10000_20000',\n",
       " './gradients/147372_20000_30000',\n",
       " './gradients/147372_30000_40000',\n",
       " './gradients/147372_40000_50000',\n",
       " './gradients/147372_50000_60000',\n",
       " './gradients/147372_60000_70000',\n",
       " './gradients/147372_70000_80000',\n",
       " './gradients/147372_80000_90000',\n",
       " './gradients/147372_90000_100000',\n",
       " './gradients/147372_100000_110000',\n",
       " './gradients/147372_110000_120000',\n",
       " './gradients/147372_120000_130000',\n",
       " './gradients/147372_130000_140000',\n",
       " './gradients/147372_140000_150000',\n",
       " './gradients/147372_150000_160000',\n",
       " './gradients/147372_160000_170000',\n",
       " './gradients/147372_170000_180000',\n",
       " './gradients/147372_180000_190000',\n",
       " './gradients/147372_190000_200000',\n",
       " './gradients/147372_200000_210000',\n",
       " './gradients/147372_210000_220000',\n",
       " './gradients/147372_220000_230000',\n",
       " './gradients/147372_230000_240000',\n",
       " './gradients/147372_240000_250000',\n",
       " './gradients/147372_250000_260000',\n",
       " './gradients/147372_260000_270000',\n",
       " './gradients/147372_270000_280000',\n",
       " './gradients/147372_280000_290000',\n",
       " './gradients/147372_290000_300000',\n",
       " './gradients/147372_300000_310000',\n",
       " './gradients/147372_310000_320000',\n",
       " './gradients/147372_320000_330000',\n",
       " './gradients/147372_330000_340000',\n",
       " './gradients/147372_340000_350000',\n",
       " './gradients/147372_350000_360000',\n",
       " './gradients/147372_360000_370000',\n",
       " './gradients/147372_370000_380000',\n",
       " './gradients/147372_380000_390000',\n",
       " './gradients/147372_390000_400000',\n",
       " './gradients/147372_400000_410000',\n",
       " './gradients/147372_410000_420000',\n",
       " './gradients/147372_420000_430000',\n",
       " './gradients/147372_430000_440000',\n",
       " './gradients/147372_440000_450000',\n",
       " './gradients/147372_450000_460000',\n",
       " './gradients/147372_460000_470000',\n",
       " './gradients/147372_470000_480000',\n",
       " './gradients/147372_480000_490000',\n",
       " './gradients/147372_490000_500000',\n",
       " './gradients/147372_500000_510000',\n",
       " './gradients/147372_510000_520000',\n",
       " './gradients/147372_520000_530000',\n",
       " './gradients/147372_530000_540000',\n",
       " './gradients/147372_540000_550000',\n",
       " './gradients/147372_550000_560000',\n",
       " './gradients/147372_560000_570000',\n",
       " './gradients/147372_570000_580000',\n",
       " './gradients/147372_580000_590000',\n",
       " './gradients/147372_590000_600000',\n",
       " './gradients/147372_600000_610000',\n",
       " './gradients/147372_610000_620000',\n",
       " './gradients/147372_620000_630000',\n",
       " './gradients/147372_630000_640000',\n",
       " './gradients/147372_640000_650000',\n",
       " './gradients/147372_650000_660000',\n",
       " './gradients/147372_660000_670000',\n",
       " './gradients/147372_670000_680000',\n",
       " './gradients/147372_680000_690000',\n",
       " './gradients/147372_690000_700000',\n",
       " './gradients/147372_700000_710000',\n",
       " './gradients/147372_710000_720000',\n",
       " './gradients/147372_720000_730000',\n",
       " './gradients/147372_730000_740000',\n",
       " './gradients/147372_740000_750000',\n",
       " './gradients/147372_750000_760000',\n",
       " './gradients/147372_760000_770000',\n",
       " './gradients/147372_770000_780000',\n",
       " './gradients/147372_780000_790000',\n",
       " './gradients/147372_790000_800000',\n",
       " './gradients/147372_800000_810000',\n",
       " './gradients/147372_810000_820000',\n",
       " './gradients/147372_820000_830000',\n",
       " './gradients/147372_830000_840000',\n",
       " './gradients/147372_840000_850000',\n",
       " './gradients/147372_850000_860000',\n",
       " './gradients/147372_860000_870000',\n",
       " './gradients/147372_870000_880000',\n",
       " './gradients/147372_880000_890000',\n",
       " './gradients/147372_890000_900000',\n",
       " './gradients/147372_900000_910000',\n",
       " './gradients/147372_910000_920000',\n",
       " './gradients/147372_920000_930000',\n",
       " './gradients/147372_930000_940000',\n",
       " './gradients/147372_940000_950000',\n",
       " './gradients/147372_950000_960000',\n",
       " './gradients/147372_960000_970000',\n",
       " './gradients/147372_970000_980000',\n",
       " './gradients/147372_980000_990000',\n",
       " './gradients/147372_990000_1000000',\n",
       " './gradients/147372_1000000_1010000',\n",
       " './gradients/147372_1010000_1020000',\n",
       " './gradients/147372_1020000_1030000',\n",
       " './gradients/147372_1030000_1040000',\n",
       " './gradients/147372_1040000_1050000',\n",
       " './gradients/147372_1050000_1060000',\n",
       " './gradients/147372_1060000_1070000',\n",
       " './gradients/147372_1070000_1080000',\n",
       " './gradients/147372_1080000_1090000',\n",
       " './gradients/147372_1090000_1100000',\n",
       " './gradients/147372_1100000_1110000',\n",
       " './gradients/147372_1110000_1120000',\n",
       " './gradients/147372_1120000_1130000',\n",
       " './gradients/147372_1130000_1140000',\n",
       " './gradients/147372_1140000_1150000',\n",
       " './gradients/147372_1150000_1160000',\n",
       " './gradients/147372_1160000_1170000',\n",
       " './gradients/147372_1170000_1180000',\n",
       " './gradients/294744_0_10000',\n",
       " './gradients/294744_10000_20000',\n",
       " './gradients/294744_20000_30000',\n",
       " './gradients/294744_30000_40000',\n",
       " './gradients/294744_40000_50000',\n",
       " './gradients/294744_50000_60000',\n",
       " './gradients/294744_60000_70000',\n",
       " './gradients/294744_70000_80000',\n",
       " './gradients/294744_80000_90000',\n",
       " './gradients/294744_90000_100000',\n",
       " './gradients/294744_100000_110000',\n",
       " './gradients/294744_110000_120000',\n",
       " './gradients/294744_120000_130000',\n",
       " './gradients/294744_130000_140000',\n",
       " './gradients/294744_140000_150000',\n",
       " './gradients/294744_150000_160000',\n",
       " './gradients/294744_160000_170000',\n",
       " './gradients/294744_170000_180000',\n",
       " './gradients/294744_180000_190000',\n",
       " './gradients/294744_190000_200000',\n",
       " './gradients/294744_200000_210000',\n",
       " './gradients/294744_210000_220000',\n",
       " './gradients/294744_220000_230000',\n",
       " './gradients/294744_230000_240000',\n",
       " './gradients/294744_240000_250000',\n",
       " './gradients/294744_250000_260000',\n",
       " './gradients/294744_260000_270000',\n",
       " './gradients/294744_270000_280000',\n",
       " './gradients/294744_280000_290000',\n",
       " './gradients/294744_290000_300000',\n",
       " './gradients/294744_300000_310000',\n",
       " './gradients/294744_310000_320000',\n",
       " './gradients/294744_320000_330000',\n",
       " './gradients/294744_330000_340000',\n",
       " './gradients/294744_340000_350000',\n",
       " './gradients/294744_350000_360000',\n",
       " './gradients/294744_360000_370000',\n",
       " './gradients/294744_370000_380000',\n",
       " './gradients/294744_380000_390000',\n",
       " './gradients/294744_390000_400000',\n",
       " './gradients/294744_400000_410000',\n",
       " './gradients/294744_410000_420000',\n",
       " './gradients/294744_420000_430000',\n",
       " './gradients/294744_430000_440000',\n",
       " './gradients/294744_440000_450000',\n",
       " './gradients/294744_450000_460000',\n",
       " './gradients/294744_460000_470000',\n",
       " './gradients/294744_470000_480000',\n",
       " './gradients/294744_480000_490000',\n",
       " './gradients/294744_490000_500000',\n",
       " './gradients/294744_500000_510000',\n",
       " './gradients/294744_510000_520000',\n",
       " './gradients/294744_520000_530000',\n",
       " './gradients/294744_530000_540000',\n",
       " './gradients/294744_540000_550000',\n",
       " './gradients/294744_550000_560000',\n",
       " './gradients/294744_560000_570000',\n",
       " './gradients/294744_570000_580000',\n",
       " './gradients/294744_580000_590000',\n",
       " './gradients/294744_590000_600000',\n",
       " './gradients/294744_600000_610000',\n",
       " './gradients/294744_610000_620000',\n",
       " './gradients/294744_620000_630000',\n",
       " './gradients/294744_630000_640000',\n",
       " './gradients/294744_640000_650000',\n",
       " './gradients/294744_650000_660000',\n",
       " './gradients/294744_660000_670000',\n",
       " './gradients/294744_670000_680000',\n",
       " './gradients/294744_680000_690000',\n",
       " './gradients/294744_690000_700000',\n",
       " './gradients/294744_700000_710000',\n",
       " './gradients/294744_710000_720000',\n",
       " './gradients/294744_720000_730000',\n",
       " './gradients/294744_730000_740000',\n",
       " './gradients/294744_740000_750000',\n",
       " './gradients/294744_750000_760000',\n",
       " './gradients/294744_760000_770000',\n",
       " './gradients/294744_770000_780000',\n",
       " './gradients/294744_780000_790000',\n",
       " './gradients/294744_790000_800000',\n",
       " './gradients/294744_800000_810000',\n",
       " './gradients/294744_810000_820000',\n",
       " './gradients/294744_820000_830000',\n",
       " './gradients/294744_830000_840000',\n",
       " './gradients/294744_840000_850000',\n",
       " './gradients/294744_850000_860000',\n",
       " './gradients/294744_860000_870000',\n",
       " './gradients/294744_870000_880000',\n",
       " './gradients/294744_880000_890000',\n",
       " './gradients/294744_890000_900000',\n",
       " './gradients/294744_900000_910000',\n",
       " './gradients/294744_910000_920000',\n",
       " './gradients/294744_920000_930000',\n",
       " './gradients/294744_930000_940000',\n",
       " './gradients/294744_940000_950000',\n",
       " './gradients/294744_950000_960000',\n",
       " './gradients/294744_960000_970000',\n",
       " './gradients/294744_970000_980000',\n",
       " './gradients/294744_980000_990000',\n",
       " './gradients/294744_990000_1000000',\n",
       " './gradients/294744_1000000_1010000',\n",
       " './gradients/294744_1010000_1020000',\n",
       " './gradients/294744_1020000_1030000',\n",
       " './gradients/294744_1030000_1040000',\n",
       " './gradients/294744_1040000_1050000',\n",
       " './gradients/294744_1050000_1060000',\n",
       " './gradients/294744_1060000_1070000',\n",
       " './gradients/294744_1070000_1080000',\n",
       " './gradients/294744_1080000_1090000',\n",
       " './gradients/294744_1090000_1100000',\n",
       " './gradients/294744_1100000_1110000',\n",
       " './gradients/294744_1110000_1120000',\n",
       " './gradients/294744_1120000_1130000',\n",
       " './gradients/294744_1130000_1140000',\n",
       " './gradients/294744_1140000_1150000',\n",
       " './gradients/294744_1150000_1160000',\n",
       " './gradients/294744_1160000_1170000',\n",
       " './gradients/294744_1170000_1180000',\n",
       " './gradients/442116_0_10000',\n",
       " './gradients/442116_10000_20000',\n",
       " './gradients/442116_20000_30000',\n",
       " './gradients/442116_30000_40000',\n",
       " './gradients/442116_40000_50000',\n",
       " './gradients/442116_50000_60000',\n",
       " './gradients/442116_60000_70000',\n",
       " './gradients/442116_70000_80000',\n",
       " './gradients/442116_80000_90000',\n",
       " './gradients/442116_90000_100000',\n",
       " './gradients/442116_100000_110000',\n",
       " './gradients/442116_110000_120000',\n",
       " './gradients/442116_120000_130000',\n",
       " './gradients/442116_130000_140000',\n",
       " './gradients/442116_140000_150000',\n",
       " './gradients/442116_150000_160000',\n",
       " './gradients/442116_160000_170000',\n",
       " './gradients/442116_170000_180000',\n",
       " './gradients/442116_180000_190000',\n",
       " './gradients/442116_190000_200000',\n",
       " './gradients/442116_200000_210000',\n",
       " './gradients/442116_210000_220000',\n",
       " './gradients/442116_220000_230000',\n",
       " './gradients/442116_230000_240000',\n",
       " './gradients/442116_240000_250000',\n",
       " './gradients/442116_250000_260000',\n",
       " './gradients/442116_260000_270000',\n",
       " './gradients/442116_270000_280000',\n",
       " './gradients/442116_280000_290000',\n",
       " './gradients/442116_290000_300000',\n",
       " './gradients/442116_300000_310000',\n",
       " './gradients/442116_310000_320000',\n",
       " './gradients/442116_320000_330000',\n",
       " './gradients/442116_330000_340000',\n",
       " './gradients/442116_340000_350000',\n",
       " './gradients/442116_350000_360000',\n",
       " './gradients/442116_360000_370000',\n",
       " './gradients/442116_370000_380000',\n",
       " './gradients/442116_380000_390000',\n",
       " './gradients/442116_390000_400000',\n",
       " './gradients/442116_400000_410000',\n",
       " './gradients/442116_410000_420000',\n",
       " './gradients/442116_420000_430000',\n",
       " './gradients/442116_430000_440000',\n",
       " './gradients/442116_440000_450000',\n",
       " './gradients/442116_450000_460000',\n",
       " './gradients/442116_460000_470000',\n",
       " './gradients/442116_470000_480000',\n",
       " './gradients/442116_480000_490000',\n",
       " './gradients/442116_490000_500000',\n",
       " './gradients/442116_500000_510000',\n",
       " './gradients/442116_510000_520000',\n",
       " './gradients/442116_520000_530000',\n",
       " './gradients/442116_530000_540000',\n",
       " './gradients/442116_540000_550000',\n",
       " './gradients/442116_550000_560000',\n",
       " './gradients/442116_560000_570000',\n",
       " './gradients/442116_570000_580000',\n",
       " './gradients/442116_580000_590000',\n",
       " './gradients/442116_590000_600000',\n",
       " './gradients/442116_600000_610000',\n",
       " './gradients/442116_610000_620000',\n",
       " './gradients/442116_620000_630000',\n",
       " './gradients/442116_630000_640000',\n",
       " './gradients/442116_640000_650000',\n",
       " './gradients/442116_650000_660000',\n",
       " './gradients/442116_660000_670000',\n",
       " './gradients/442116_670000_680000',\n",
       " './gradients/442116_680000_690000',\n",
       " './gradients/442116_690000_700000',\n",
       " './gradients/442116_700000_710000',\n",
       " './gradients/442116_710000_720000',\n",
       " './gradients/442116_720000_730000',\n",
       " './gradients/442116_730000_740000',\n",
       " './gradients/442116_740000_750000',\n",
       " './gradients/442116_750000_760000',\n",
       " './gradients/442116_760000_770000',\n",
       " './gradients/442116_770000_780000',\n",
       " './gradients/442116_780000_790000',\n",
       " './gradients/442116_790000_800000',\n",
       " './gradients/442116_800000_810000',\n",
       " './gradients/442116_810000_820000',\n",
       " './gradients/442116_820000_830000',\n",
       " './gradients/442116_830000_840000',\n",
       " './gradients/442116_840000_850000',\n",
       " './gradients/442116_850000_860000',\n",
       " './gradients/442116_860000_870000',\n",
       " './gradients/442116_870000_880000',\n",
       " './gradients/442116_880000_890000',\n",
       " './gradients/442116_890000_900000',\n",
       " './gradients/442116_900000_910000',\n",
       " './gradients/442116_910000_920000',\n",
       " './gradients/442116_920000_930000',\n",
       " './gradients/442116_930000_940000',\n",
       " './gradients/442116_940000_950000',\n",
       " './gradients/442116_950000_960000',\n",
       " './gradients/442116_960000_970000',\n",
       " './gradients/442116_970000_980000',\n",
       " './gradients/442116_980000_990000',\n",
       " './gradients/442116_990000_1000000',\n",
       " './gradients/442116_1000000_1010000',\n",
       " './gradients/442116_1010000_1020000',\n",
       " './gradients/442116_1020000_1030000',\n",
       " './gradients/442116_1030000_1040000',\n",
       " './gradients/442116_1040000_1050000',\n",
       " './gradients/442116_1050000_1060000',\n",
       " './gradients/442116_1060000_1070000',\n",
       " './gradients/442116_1070000_1080000',\n",
       " './gradients/442116_1080000_1090000',\n",
       " './gradients/442116_1090000_1100000',\n",
       " './gradients/442116_1100000_1110000',\n",
       " './gradients/442116_1110000_1120000',\n",
       " './gradients/442116_1120000_1130000',\n",
       " './gradients/442116_1130000_1140000',\n",
       " './gradients/442116_1140000_1150000',\n",
       " './gradients/442116_1150000_1160000',\n",
       " './gradients/442116_1160000_1170000',\n",
       " './gradients/442116_1170000_1180000',\n",
       " './gradients/589488_0_10000',\n",
       " './gradients/589488_10000_20000',\n",
       " './gradients/589488_20000_30000',\n",
       " './gradients/589488_30000_40000',\n",
       " './gradients/589488_40000_50000',\n",
       " './gradients/589488_50000_60000',\n",
       " './gradients/589488_60000_70000',\n",
       " './gradients/589488_70000_80000',\n",
       " './gradients/589488_80000_90000',\n",
       " './gradients/589488_90000_100000',\n",
       " './gradients/589488_100000_110000',\n",
       " './gradients/589488_110000_120000',\n",
       " './gradients/589488_120000_130000',\n",
       " './gradients/589488_130000_140000',\n",
       " './gradients/589488_140000_150000',\n",
       " './gradients/589488_150000_160000',\n",
       " './gradients/589488_160000_170000',\n",
       " './gradients/589488_170000_180000',\n",
       " './gradients/589488_180000_190000',\n",
       " './gradients/589488_190000_200000',\n",
       " './gradients/589488_200000_210000',\n",
       " './gradients/589488_210000_220000',\n",
       " './gradients/589488_220000_230000',\n",
       " './gradients/589488_230000_240000',\n",
       " './gradients/589488_240000_250000',\n",
       " './gradients/589488_250000_260000',\n",
       " './gradients/589488_260000_270000',\n",
       " './gradients/589488_270000_280000',\n",
       " './gradients/589488_280000_290000',\n",
       " './gradients/589488_290000_300000',\n",
       " './gradients/589488_300000_310000',\n",
       " './gradients/589488_310000_320000',\n",
       " './gradients/589488_320000_330000',\n",
       " './gradients/589488_330000_340000',\n",
       " './gradients/589488_340000_350000',\n",
       " './gradients/589488_350000_360000',\n",
       " './gradients/589488_360000_370000',\n",
       " './gradients/589488_370000_380000',\n",
       " './gradients/589488_380000_390000',\n",
       " './gradients/589488_390000_400000',\n",
       " './gradients/589488_400000_410000',\n",
       " './gradients/589488_410000_420000',\n",
       " './gradients/589488_420000_430000',\n",
       " './gradients/589488_430000_440000',\n",
       " './gradients/589488_440000_450000',\n",
       " './gradients/589488_450000_460000',\n",
       " './gradients/589488_460000_470000',\n",
       " './gradients/589488_470000_480000',\n",
       " './gradients/589488_480000_490000',\n",
       " './gradients/589488_490000_500000',\n",
       " './gradients/589488_500000_510000',\n",
       " './gradients/589488_510000_520000',\n",
       " './gradients/589488_520000_530000',\n",
       " './gradients/589488_530000_540000',\n",
       " './gradients/589488_540000_550000',\n",
       " './gradients/589488_550000_560000',\n",
       " './gradients/589488_560000_570000',\n",
       " './gradients/589488_570000_580000',\n",
       " './gradients/589488_580000_590000',\n",
       " './gradients/589488_590000_600000',\n",
       " './gradients/589488_600000_610000',\n",
       " './gradients/589488_610000_620000',\n",
       " './gradients/589488_620000_630000',\n",
       " './gradients/589488_630000_640000',\n",
       " './gradients/589488_640000_650000',\n",
       " './gradients/589488_650000_660000',\n",
       " './gradients/589488_660000_670000',\n",
       " './gradients/589488_670000_680000',\n",
       " './gradients/589488_680000_690000',\n",
       " './gradients/589488_690000_700000',\n",
       " './gradients/589488_700000_710000',\n",
       " './gradients/589488_710000_720000',\n",
       " './gradients/589488_720000_730000',\n",
       " './gradients/589488_730000_740000',\n",
       " './gradients/589488_740000_750000',\n",
       " './gradients/589488_750000_760000',\n",
       " './gradients/589488_760000_770000',\n",
       " './gradients/589488_770000_780000',\n",
       " './gradients/589488_780000_790000',\n",
       " './gradients/589488_790000_800000',\n",
       " './gradients/589488_800000_810000',\n",
       " './gradients/589488_810000_820000',\n",
       " './gradients/589488_820000_830000',\n",
       " './gradients/589488_830000_840000',\n",
       " './gradients/589488_840000_850000',\n",
       " './gradients/589488_850000_860000',\n",
       " './gradients/589488_860000_870000',\n",
       " './gradients/589488_870000_880000',\n",
       " './gradients/589488_880000_890000',\n",
       " './gradients/589488_890000_900000',\n",
       " './gradients/589488_900000_910000',\n",
       " './gradients/589488_910000_920000',\n",
       " './gradients/589488_920000_930000',\n",
       " './gradients/589488_930000_940000',\n",
       " './gradients/589488_940000_950000',\n",
       " './gradients/589488_950000_960000',\n",
       " './gradients/589488_960000_970000',\n",
       " './gradients/589488_970000_980000',\n",
       " './gradients/589488_980000_990000',\n",
       " './gradients/589488_990000_1000000',\n",
       " './gradients/589488_1000000_1010000',\n",
       " './gradients/589488_1010000_1020000',\n",
       " './gradients/589488_1020000_1030000',\n",
       " './gradients/589488_1030000_1040000',\n",
       " './gradients/589488_1040000_1050000',\n",
       " './gradients/589488_1050000_1060000',\n",
       " './gradients/589488_1060000_1070000',\n",
       " './gradients/589488_1070000_1080000',\n",
       " './gradients/589488_1080000_1090000',\n",
       " './gradients/589488_1090000_1100000',\n",
       " './gradients/589488_1100000_1110000',\n",
       " './gradients/589488_1110000_1120000',\n",
       " './gradients/589488_1120000_1130000',\n",
       " './gradients/589488_1130000_1140000',\n",
       " './gradients/589488_1140000_1150000',\n",
       " './gradients/589488_1150000_1160000',\n",
       " './gradients/589488_1160000_1170000',\n",
       " './gradients/589488_1170000_1180000',\n",
       " './gradients/736890_0_10000',\n",
       " './gradients/736890_10000_20000',\n",
       " './gradients/736890_20000_30000',\n",
       " './gradients/736890_30000_40000',\n",
       " './gradients/736890_40000_50000',\n",
       " './gradients/736890_50000_60000',\n",
       " './gradients/736890_60000_70000',\n",
       " './gradients/736890_70000_80000',\n",
       " './gradients/736890_80000_90000',\n",
       " './gradients/736890_90000_100000',\n",
       " './gradients/736890_100000_110000',\n",
       " './gradients/736890_110000_120000',\n",
       " './gradients/736890_120000_130000',\n",
       " './gradients/736890_130000_140000',\n",
       " './gradients/736890_140000_150000',\n",
       " './gradients/736890_150000_160000',\n",
       " './gradients/736890_160000_170000',\n",
       " './gradients/736890_170000_180000',\n",
       " './gradients/736890_180000_190000',\n",
       " './gradients/736890_190000_200000',\n",
       " './gradients/736890_200000_210000',\n",
       " './gradients/736890_210000_220000',\n",
       " './gradients/736890_220000_230000',\n",
       " './gradients/736890_230000_240000',\n",
       " './gradients/736890_240000_250000',\n",
       " './gradients/736890_250000_260000',\n",
       " './gradients/736890_260000_270000',\n",
       " './gradients/736890_270000_280000',\n",
       " './gradients/736890_280000_290000',\n",
       " './gradients/736890_290000_300000',\n",
       " './gradients/736890_300000_310000',\n",
       " './gradients/736890_310000_320000',\n",
       " './gradients/736890_320000_330000',\n",
       " './gradients/736890_330000_340000',\n",
       " './gradients/736890_340000_350000',\n",
       " './gradients/736890_350000_360000',\n",
       " './gradients/736890_360000_370000',\n",
       " './gradients/736890_370000_380000',\n",
       " './gradients/736890_380000_390000',\n",
       " './gradients/736890_390000_400000',\n",
       " './gradients/736890_400000_410000',\n",
       " './gradients/736890_410000_420000',\n",
       " './gradients/736890_420000_430000',\n",
       " './gradients/736890_430000_440000',\n",
       " './gradients/736890_440000_450000',\n",
       " './gradients/736890_450000_460000',\n",
       " './gradients/736890_460000_470000',\n",
       " './gradients/736890_470000_480000',\n",
       " './gradients/736890_480000_490000',\n",
       " './gradients/736890_490000_500000',\n",
       " './gradients/736890_500000_510000',\n",
       " './gradients/736890_510000_520000',\n",
       " './gradients/736890_520000_530000',\n",
       " './gradients/736890_530000_540000',\n",
       " './gradients/736890_540000_550000',\n",
       " './gradients/736890_550000_560000',\n",
       " './gradients/736890_560000_570000',\n",
       " './gradients/736890_570000_580000',\n",
       " './gradients/736890_580000_590000',\n",
       " './gradients/736890_590000_600000',\n",
       " './gradients/736890_600000_610000',\n",
       " './gradients/736890_610000_620000',\n",
       " './gradients/736890_620000_630000',\n",
       " './gradients/736890_630000_640000',\n",
       " './gradients/736890_640000_650000',\n",
       " './gradients/736890_650000_660000',\n",
       " './gradients/736890_660000_670000',\n",
       " './gradients/736890_670000_680000',\n",
       " './gradients/736890_680000_690000',\n",
       " './gradients/736890_690000_700000',\n",
       " './gradients/736890_700000_710000',\n",
       " './gradients/736890_710000_720000',\n",
       " './gradients/736890_720000_730000',\n",
       " './gradients/736890_730000_740000',\n",
       " './gradients/736890_740000_750000',\n",
       " './gradients/736890_750000_760000',\n",
       " './gradients/736890_760000_770000',\n",
       " './gradients/736890_770000_780000',\n",
       " './gradients/736890_780000_790000',\n",
       " './gradients/736890_790000_800000',\n",
       " './gradients/736890_800000_810000',\n",
       " './gradients/736890_810000_820000',\n",
       " './gradients/736890_820000_830000',\n",
       " './gradients/736890_830000_840000',\n",
       " './gradients/736890_840000_850000',\n",
       " './gradients/736890_850000_860000',\n",
       " './gradients/736890_860000_870000',\n",
       " './gradients/736890_870000_880000',\n",
       " './gradients/736890_880000_890000',\n",
       " './gradients/736890_890000_900000',\n",
       " './gradients/736890_900000_910000',\n",
       " './gradients/736890_910000_920000',\n",
       " './gradients/736890_920000_930000',\n",
       " './gradients/736890_930000_940000',\n",
       " './gradients/736890_940000_950000',\n",
       " './gradients/736890_950000_960000',\n",
       " './gradients/736890_960000_970000',\n",
       " './gradients/736890_970000_980000',\n",
       " './gradients/736890_980000_990000',\n",
       " './gradients/736890_990000_1000000',\n",
       " './gradients/736890_1000000_1010000',\n",
       " './gradients/736890_1010000_1020000',\n",
       " './gradients/736890_1020000_1030000',\n",
       " './gradients/736890_1030000_1040000',\n",
       " './gradients/736890_1040000_1050000',\n",
       " './gradients/736890_1050000_1060000',\n",
       " './gradients/736890_1060000_1070000',\n",
       " './gradients/736890_1070000_1080000',\n",
       " './gradients/736890_1080000_1090000',\n",
       " './gradients/736890_1090000_1100000',\n",
       " './gradients/736890_1100000_1110000',\n",
       " './gradients/736890_1110000_1120000',\n",
       " './gradients/736890_1120000_1130000',\n",
       " './gradients/736890_1130000_1140000',\n",
       " './gradients/736890_1140000_1150000',\n",
       " './gradients/736890_1150000_1160000',\n",
       " './gradients/736890_1160000_1170000',\n",
       " './gradients/736890_1170000_1180000']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " list(itertools.chain(*[[ os.path.join(args[\"gradient_input_dir\"], str(a) + \"_\" + str(i) + \"_\" + str(i +args[\"gradients_per_file\"])) for i in range(0, len(dataset[\"train\"]), args[\"gradients_per_file\"])] for a in epoch_checkpoints]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ./gradients/638612_30000_40000\n",
      "Deleted: ./gradients/368430_780000_790000\n",
      "Deleted: ./gradients/589488_1060000_1070000\n",
      "Deleted: ./gradients/589488_990000_1000000\n",
      "Deleted: ./gradients/221058_240000_250000\n",
      "Deleted: ./gradients/368430_870000_880000\n",
      "Deleted: ./gradients/589488_210000_220000\n",
      "Deleted: ./gradients/294744_240000_250000\n",
      "Deleted: ./gradients/294744_890000_900000\n",
      "Deleted: ./gradients/294744_790000_800000\n",
      "Deleted: ./gradients/589488_100000_110000\n",
      "Deleted: ./gradients/614050_1120000_1130000\n",
      "Deleted: ./gradients/589488_540000_550000\n",
      "Deleted: ./gradients/221058_300000_310000\n",
      "Deleted: ./gradients/294744_130000_140000\n",
      "Deleted: ./gradients/368430_90000_100000\n",
      "Deleted: ./gradients/221058_700000_710000\n",
      "Deleted: ./gradients/221058_820000_830000\n",
      "Deleted: ./gradients/73686_320000_330000\n",
      "Deleted: ./gradients/221058_1080000_1090000\n",
      "Deleted: ./gradients/687736_20000_30000\n",
      "Deleted: ./gradients/221058_720000_730000\n",
      "Deleted: ./gradients/589488_1050000_1060000\n",
      "Deleted: ./gradients/294744_180000_190000\n",
      "Deleted: ./gradients/589488_1110000_1120000\n",
      "Deleted: ./gradients/589488_650000_660000\n",
      "Deleted: ./gradients/294744_120000_130000\n",
      "Deleted: ./gradients/73686_1040000_1050000\n",
      "Deleted: ./gradients/368430_310000_320000\n",
      "Deleted: ./gradients/368430_500000_510000\n",
      "Deleted: ./gradients/589488_160000_170000\n",
      "Deleted: ./gradients/589488_0_10000\n",
      "Deleted: ./gradients/368430_670000_680000\n",
      "Deleted: ./gradients/294744_360000_370000\n",
      "Deleted: ./gradients/589488_790000_800000\n",
      "Deleted: ./gradients/73686_880000_890000\n",
      "Deleted: ./gradients/294744_340000_350000\n",
      "Deleted: ./gradients/294744_960000_970000\n",
      "Deleted: ./gradients/368430_650000_660000\n",
      "Deleted: ./gradients/368430_730000_740000\n",
      "Deleted: ./gradients/540364_1070000_1080000\n",
      "Deleted: ./gradients/368430_960000_970000\n",
      "Deleted: ./gradients/589488_780000_790000\n",
      "Deleted: ./gradients/221058_640000_650000\n",
      "Deleted: ./gradients/294744_40000_50000\n",
      "Deleted: ./gradients/589488_970000_980000\n",
      "Deleted: ./gradients/589488_550000_560000\n",
      "Deleted: ./gradients/540364_1040000_1050000\n",
      "Deleted: ./gradients/589488_1150000_1160000\n",
      "Deleted: ./gradients/73686_550000_560000\n",
      "Deleted: ./gradients/368430_190000_200000\n",
      "Deleted: ./gradients/589488_960000_970000\n",
      "Deleted: ./gradients/221058_100000_110000\n",
      "Deleted: ./gradients/368430_220000_230000\n",
      "Deleted: ./gradients/368430_1020000_1030000\n",
      "Deleted: ./gradients/221058_180000_190000\n",
      "Deleted: ./gradients/368430_1110000_1120000\n",
      "Deleted: ./gradients/294744_260000_270000\n",
      "Deleted: ./gradients/294744_1090000_1100000\n",
      "Deleted: ./gradients/294744_1060000_1070000\n",
      "Deleted: ./gradients/294744_1150000_1160000\n",
      "Deleted: ./gradients/294744_1120000_1130000\n",
      "Deleted: ./gradients/368430_320000_330000\n",
      "Deleted: ./gradients/589488_250000_260000\n",
      "Deleted: ./gradients/294744_370000_380000\n",
      "Deleted: ./gradients/540364_1050000_1060000\n",
      "Deleted: ./gradients/589488_600000_610000\n",
      "Deleted: ./gradients/73686_470000_480000\n",
      "Deleted: ./gradients/589488_560000_570000\n",
      "Deleted: ./gradients/589488_370000_380000\n",
      "Deleted: ./gradients/368430_1040000_1050000\n",
      "Deleted: ./gradients/368430_900000_910000\n",
      "Deleted: ./gradients/368430_330000_340000\n",
      "Deleted: ./gradients/73686_890000_900000\n",
      "Deleted: ./gradients/589488_90000_100000\n",
      "Deleted: ./gradients/294744_860000_870000\n",
      "Deleted: ./gradients/491240_280000_290000\n",
      "Deleted: ./gradients/294744_80000_90000\n",
      "Deleted: ./gradients/221058_1120000_1130000\n",
      "Deleted: ./gradients/221058_200000_210000\n",
      "Deleted: ./gradients/73686_10000_20000\n",
      "Deleted: ./gradients/368430_490000_500000\n",
      "Deleted: ./gradients/221058_130000_140000\n",
      "Deleted: ./gradients/589488_80000_90000\n",
      "Deleted: ./gradients/368430_440000_450000\n",
      "Deleted: ./gradients/294744_380000_390000\n",
      "Deleted: ./gradients/368430_260000_270000\n",
      "Deleted: ./gradients/368430_110000_120000\n",
      "Deleted: ./gradients/294744_170000_180000\n",
      "Deleted: ./gradients/221058_670000_680000\n",
      "Deleted: ./gradients/294744_930000_940000\n",
      "Deleted: ./gradients/589488_400000_410000\n",
      "Deleted: ./gradients/73686_20000_30000\n",
      "Deleted: ./gradients/221058_510000_520000\n",
      "Deleted: ./gradients/540364_1110000_1120000\n",
      "Deleted: ./gradients/589488_580000_590000\n",
      "Deleted: ./gradients/221058_990000_1000000\n",
      "Deleted: ./gradients/589488_230000_240000\n",
      "Deleted: ./gradients/368430_290000_300000\n",
      "Deleted: ./gradients/294744_320000_330000\n",
      "Deleted: ./gradients/368430_1100000_1110000\n",
      "Deleted: ./gradients/589488_30000_40000\n",
      "Deleted: ./gradients/368430_370000_380000\n",
      "Deleted: ./gradients/73686_780000_790000\n",
      "Deleted: ./gradients/589488_1000000_1010000\n",
      "Deleted: ./gradients/589488_290000_300000\n",
      "Deleted: ./gradients/368430_630000_640000\n",
      "Deleted: ./gradients/294744_230000_240000\n",
      "Deleted: ./gradients/589488_900000_910000\n",
      "Deleted: ./gradients/221058_770000_780000\n",
      "Deleted: ./gradients/294744_990000_1000000\n",
      "Deleted: ./gradients/73686_350000_360000\n",
      "Deleted: ./gradients/589488_330000_340000\n",
      "Deleted: ./gradients/368430_130000_140000\n",
      "Deleted: ./gradients/368430_1140000_1150000\n",
      "Deleted: ./gradients/368430_230000_240000\n",
      "Deleted: ./gradients/368430_400000_410000\n",
      "Deleted: ./gradients/294744_1080000_1090000\n",
      "Deleted: ./gradients/368430_520000_530000\n",
      "Deleted: ./gradients/638612_920000_930000\n",
      "Deleted: ./gradients/368430_360000_370000\n",
      "Deleted: ./gradients/589488_800000_810000\n",
      "Deleted: ./gradients/294744_70000_80000\n",
      "Deleted: ./gradients/368430_610000_620000\n",
      "Deleted: ./gradients/73686_490000_500000\n",
      "Deleted: ./gradients/368430_160000_170000\n",
      "Deleted: ./gradients/589488_450000_460000\n",
      "Deleted: ./gradients/442116_390000_400000\n",
      "Deleted: ./gradients/638612_130000_140000\n",
      "Deleted: ./gradients/73686_920000_930000\n",
      "Deleted: ./gradients/73686_930000_940000\n",
      "Deleted: ./gradients/589488_840000_850000\n",
      "Deleted: ./gradients/589488_350000_360000\n",
      "Deleted: ./gradients/368430_300000_310000\n",
      "Deleted: ./gradients/221058_710000_720000\n",
      "Deleted: ./gradients/221058_580000_590000\n",
      "Deleted: ./gradients/294744_820000_830000\n",
      "Deleted: ./gradients/589488_910000_920000\n",
      "Deleted: ./gradients/589488_50000_60000\n",
      "Deleted: ./gradients/589488_40000_50000\n",
      "Deleted: ./gradients/638612_20000_30000\n",
      "Deleted: ./gradients/368430_750000_760000\n",
      "Deleted: ./gradients/73686_800000_810000\n",
      "Deleted: ./gradients/221058_140000_150000\n",
      "Deleted: ./gradients/294744_160000_170000\n",
      "Deleted: ./gradients/638612_40000_50000\n",
      "Deleted: ./gradients/221058_750000_760000\n",
      "Deleted: ./gradients/221058_1150000_1160000\n",
      "Deleted: ./gradients/221058_650000_660000\n",
      "Deleted: ./gradients/221058_40000_50000\n",
      "Deleted: ./gradients/294744_210000_220000\n",
      "Deleted: ./gradients/221058_70000_80000\n",
      "Deleted: ./gradients/589488_930000_940000\n",
      "Deleted: ./gradients/589488_380000_390000\n",
      "Deleted: ./gradients/589488_1040000_1050000\n",
      "Deleted: ./gradients/638612_160000_170000\n",
      "Deleted: ./gradients/73686_500000_510000\n",
      "Deleted: ./gradients/221058_160000_170000\n",
      "Deleted: ./gradients/589488_1140000_1150000\n",
      "Deleted: ./gradients/368430_740000_750000\n",
      "Deleted: ./gradients/221058_630000_640000\n",
      "Deleted: ./gradients/221058_30000_40000\n",
      "Deleted: ./gradients/368430_70000_80000\n",
      "Deleted: ./gradients/73686_360000_370000\n",
      "Deleted: ./gradients/368430_1170000_1180000\n",
      "Deleted: ./gradients/638612_90000_100000\n",
      "Deleted: ./gradients/73686_940000_950000\n",
      "Deleted: ./gradients/73686_450000_460000\n",
      "Deleted: ./gradients/589488_1020000_1030000\n",
      "Deleted: ./gradients/221058_1050000_1060000\n",
      "Deleted: ./gradients/294744_50000_60000\n",
      "Deleted: ./gradients/294744_810000_820000\n",
      "Deleted: ./gradients/368430_720000_730000\n",
      "Deleted: ./gradients/221058_20000_30000\n",
      "Deleted: ./gradients/442116_890000_900000\n",
      "Deleted: ./gradients/294744_330000_340000\n",
      "Deleted: ./gradients/294744_90000_100000\n",
      "Deleted: ./gradients/368430_990000_1000000\n",
      "Deleted: ./gradients/368430_1070000_1080000\n",
      "Deleted: ./gradients/73686_310000_320000\n",
      "Deleted: ./gradients/368430_700000_710000\n",
      "Deleted: ./gradients/294744_1170000_1180000\n",
      "Deleted: ./gradients/221058_170000_180000\n",
      "Deleted: ./gradients/368430_80000_90000\n",
      "Deleted: ./gradients/73686_510000_520000\n",
      "Deleted: ./gradients/368430_200000_210000\n",
      "Deleted: ./gradients/589488_890000_900000\n",
      "Deleted: ./gradients/73686_540000_550000\n",
      "Deleted: ./gradients/73686_380000_390000\n",
      "Deleted: ./gradients/221058_1100000_1110000\n",
      "Deleted: ./gradients/368430_250000_260000\n",
      "Deleted: ./gradients/294744_150000_160000\n",
      "Deleted: ./gradients/589488_490000_500000\n",
      "Deleted: ./gradients/368430_600000_610000\n",
      "Deleted: ./gradients/589488_670000_680000\n",
      "Deleted: ./gradients/294744_640000_650000\n",
      "Deleted: ./gradients/368430_850000_860000\n",
      "Deleted: ./gradients/221058_790000_800000\n",
      "Deleted: ./gradients/589488_710000_720000\n",
      "Deleted: ./gradients/294744_780000_790000\n",
      "Deleted: ./gradients/73686_300000_310000\n",
      "Deleted: ./gradients/589488_820000_830000\n",
      "Deleted: ./gradients/221058_1110000_1120000\n",
      "Deleted: ./gradients/368430_530000_540000\n",
      "Deleted: ./gradients/294744_1130000_1140000\n",
      "Deleted: ./gradients/589488_1080000_1090000\n",
      "Deleted: ./gradients/73686_870000_880000\n",
      "Deleted: ./gradients/221058_10000_20000\n",
      "Deleted: ./gradients/73686_460000_470000\n",
      "Deleted: ./gradients/294744_690000_700000\n",
      "Deleted: ./gradients/589488_760000_770000\n",
      "Deleted: ./gradients/368430_50000_60000\n",
      "Deleted: ./gradients/294744_1040000_1050000\n",
      "Deleted: ./gradients/368430_150000_160000\n",
      "Deleted: ./gradients/221058_740000_750000\n",
      "Deleted: ./gradients/294744_670000_680000\n",
      "Deleted: ./gradients/221058_660000_670000\n",
      "Deleted: ./gradients/368430_470000_480000\n",
      "Deleted: ./gradients/221058_470000_480000\n",
      "Deleted: ./gradients/73686_390000_400000\n",
      "Deleted: ./gradients/294744_540000_550000\n",
      "Deleted: ./gradients/540364_1010000_1020000\n",
      "Deleted: ./gradients/73686_970000_980000\n",
      "Deleted: ./gradients/589488_20000_30000\n",
      "Deleted: ./gradients/368430_620000_630000\n",
      "Deleted: ./gradients/368430_940000_950000\n",
      "Deleted: ./gradients/589488_980000_990000\n",
      "Deleted: ./gradients/540364_970000_980000\n",
      "Deleted: ./gradients/221058_1070000_1080000\n",
      "Deleted: ./gradients/294744_910000_920000\n",
      "Deleted: ./gradients/221058_610000_620000\n",
      "Deleted: ./gradients/589488_530000_540000\n",
      "Deleted: ./gradients/294744_750000_760000\n",
      "Deleted: ./gradients/73686_900000_910000\n",
      "Deleted: ./gradients/221058_970000_980000\n",
      "Deleted: ./gradients/73686_50000_60000\n",
      "Deleted: ./gradients/368430_590000_600000\n",
      "Deleted: ./gradients/589488_220000_230000\n",
      "Deleted: ./gradients/589488_1070000_1080000\n",
      "Deleted: ./gradients/638612_60000_70000\n",
      "Deleted: ./gradients/368430_980000_990000\n",
      "Deleted: ./gradients/73686_0_10000\n",
      "Deleted: ./gradients/73686_850000_860000\n",
      "Deleted: ./gradients/589488_750000_760000\n",
      "Deleted: ./gradients/368430_380000_390000\n",
      "Deleted: ./gradients/368430_140000_150000\n",
      "Deleted: ./gradients/73686_400000_410000\n",
      "Deleted: ./gradients/221058_600000_610000\n",
      "Deleted: ./gradients/540364_1120000_1130000\n",
      "Deleted: ./gradients/73686_520000_530000\n",
      "Deleted: ./gradients/221058_110000_120000\n",
      "Deleted: ./gradients/589488_690000_700000\n",
      "Deleted: ./gradients/73686_430000_440000\n",
      "Deleted: ./gradients/294744_850000_860000\n",
      "Deleted: ./gradients/589488_620000_630000\n",
      "Deleted: ./gradients/221058_210000_220000\n",
      "Deleted: ./gradients/368430_270000_280000\n",
      "Deleted: ./gradients/589488_640000_650000\n",
      "Deleted: ./gradients/589488_460000_470000\n",
      "Deleted: ./gradients/589488_1090000_1100000\n",
      "Deleted: ./gradients/368430_910000_920000\n",
      "Deleted: ./gradients/221058_620000_630000\n",
      "Deleted: ./gradients/368430_970000_980000\n",
      "Deleted: ./gradients/294744_110000_120000\n",
      "Deleted: ./gradients/368430_350000_360000\n",
      "Deleted: ./gradients/294744_800000_810000\n",
      "Deleted: ./gradients/221058_1170000_1180000\n",
      "Deleted: ./gradients/368430_460000_470000\n",
      "Deleted: ./gradients/73686_950000_960000\n",
      "Deleted: ./gradients/294744_470000_480000\n",
      "Deleted: ./gradients/614050_1110000_1120000\n",
      "Deleted: ./gradients/638612_10000_20000\n",
      "Deleted: ./gradients/589488_200000_210000\n",
      "Deleted: ./gradients/294744_280000_290000\n",
      "Deleted: ./gradients/294744_630000_640000\n",
      "Deleted: ./gradients/294744_870000_880000\n",
      "Deleted: ./gradients/368430_820000_830000\n",
      "Deleted: ./gradients/294744_880000_890000\n",
      "Deleted: ./gradients/589488_1030000_1040000\n",
      "Deleted: ./gradients/368430_410000_420000\n",
      "Deleted: ./gradients/73686_40000_50000\n",
      "Deleted: ./gradients/221058_80000_90000\n",
      "Deleted: ./gradients/294744_10000_20000\n",
      "Deleted: ./gradients/589488_170000_180000\n",
      "Deleted: ./gradients/589488_60000_70000\n",
      "Deleted: ./gradients/221058_280000_290000\n",
      "Deleted: ./gradients/540364_990000_1000000\n",
      "Deleted: ./gradients/294744_920000_930000\n",
      "Deleted: ./gradients/294744_680000_690000\n",
      "Deleted: ./gradients/368430_890000_900000\n",
      "Deleted: ./gradients/368430_830000_840000\n",
      "Deleted: ./gradients/589488_660000_670000\n",
      "Deleted: ./gradients/614050_1170000_1180000\n",
      "Deleted: ./gradients/73686_30000_40000\n",
      "Deleted: ./gradients/294744_460000_470000\n",
      "Deleted: ./gradients/368430_790000_800000\n",
      "Deleted: ./gradients/73686_80000_90000\n",
      "Deleted: ./gradients/73686_280000_290000\n",
      "Deleted: ./gradients/589488_260000_270000\n",
      "Deleted: ./gradients/221058_260000_270000\n",
      "Deleted: ./gradients/368430_1010000_1020000\n",
      "Deleted: ./gradients/368430_0_10000\n",
      "Deleted: ./gradients/368430_1160000_1170000\n",
      "Deleted: ./gradients/221058_50000_60000\n",
      "Deleted: ./gradients/73686_860000_870000\n",
      "Deleted: ./gradients/221058_1040000_1050000\n",
      "Deleted: ./gradients/589488_130000_140000\n",
      "Deleted: ./gradients/294744_140000_150000\n",
      "Deleted: ./gradients/294744_740000_750000\n",
      "Deleted: ./gradients/589488_770000_780000\n",
      "Deleted: ./gradients/368430_450000_460000\n",
      "Deleted: ./gradients/294744_480000_490000\n",
      "Deleted: ./gradients/368430_30000_40000\n",
      "Deleted: ./gradients/221058_1140000_1150000\n",
      "Deleted: ./gradients/589488_720000_730000\n",
      "Deleted: ./gradients/589488_390000_400000\n",
      "Deleted: ./gradients/294744_970000_980000\n",
      "Deleted: ./gradients/540364_1000000_1010000\n",
      "Deleted: ./gradients/73686_530000_540000\n",
      "Deleted: ./gradients/368430_1000000_1010000\n",
      "Deleted: ./gradients/294744_530000_540000\n",
      "Deleted: ./gradients/294744_620000_630000\n",
      "Deleted: ./gradients/221058_310000_320000\n",
      "Deleted: ./gradients/73686_440000_450000\n",
      "Deleted: ./gradients/294744_250000_260000\n",
      "Deleted: ./gradients/294744_660000_670000\n",
      "Deleted: ./gradients/221058_1060000_1070000\n",
      "Deleted: ./gradients/73686_420000_430000\n",
      "Deleted: ./gradients/589488_630000_640000\n",
      "Deleted: ./gradients/368430_580000_590000\n",
      "Deleted: ./gradients/294744_60000_70000\n",
      "Deleted: ./gradients/294744_720000_730000\n",
      "Deleted: ./gradients/589488_300000_310000\n",
      "Deleted: ./gradients/368430_690000_700000\n",
      "Deleted: ./gradients/589488_940000_950000\n",
      "Deleted: ./gradients/442116_650000_660000\n",
      "Deleted: ./gradients/368430_810000_820000\n",
      "Deleted: ./gradients/368430_920000_930000\n",
      "Deleted: ./gradients/589488_190000_200000\n",
      "Deleted: ./gradients/368430_20000_30000\n",
      "Deleted: ./gradients/368430_40000_50000\n",
      "Deleted: ./gradients/442116_140000_150000\n",
      "Deleted: ./gradients/73686_1000000_1010000\n",
      "Deleted: ./gradients/589488_880000_890000\n",
      "Deleted: ./gradients/294744_560000_570000\n",
      "Deleted: ./gradients/294744_550000_560000\n",
      "Deleted: ./gradients/589488_730000_740000\n",
      "Deleted: ./gradients/368430_1090000_1100000\n",
      "Deleted: ./gradients/368430_770000_780000\n",
      "Deleted: ./gradients/540364_1030000_1040000\n",
      "Deleted: ./gradients/221058_1160000_1170000\n",
      "Deleted: ./gradients/73686_1030000_1040000\n",
      "Deleted: ./gradients/294744_350000_360000\n",
      "Deleted: ./gradients/73686_60000_70000\n",
      "Deleted: ./gradients/294744_390000_400000\n",
      "Deleted: ./gradients/294744_520000_530000\n",
      "Deleted: ./gradients/589488_1120000_1130000\n",
      "Deleted: ./gradients/294744_420000_430000\n",
      "Deleted: ./gradients/589488_320000_330000\n",
      "Deleted: ./gradients/221058_590000_600000\n",
      "Deleted: ./gradients/294744_840000_850000\n",
      "Deleted: ./gradients/221058_980000_990000\n",
      "Deleted: ./gradients/221058_1030000_1040000\n",
      "Deleted: ./gradients/294744_830000_840000\n",
      "Deleted: ./gradients/294744_1000000_1010000\n",
      "Deleted: ./gradients/294744_310000_320000\n",
      "Deleted: ./gradients/589488_340000_350000\n",
      "Deleted: ./gradients/221058_1000000_1010000\n",
      "Deleted: ./gradients/73686_330000_340000\n",
      "Deleted: ./gradients/221058_320000_330000\n",
      "Deleted: ./gradients/221058_500000_510000\n",
      "Deleted: ./gradients/294744_710000_720000\n",
      "Deleted: ./gradients/221058_270000_280000\n",
      "Deleted: ./gradients/73686_960000_970000\n",
      "Deleted: ./gradients/73686_910000_920000\n",
      "Deleted: ./gradients/368430_240000_250000\n",
      "Deleted: ./gradients/589488_150000_160000\n",
      "Deleted: ./gradients/221058_60000_70000\n",
      "Deleted: ./gradients/589488_110000_120000\n",
      "Deleted: ./gradients/221058_460000_470000\n",
      "Deleted: ./gradients/73686_480000_490000\n",
      "Deleted: ./gradients/221058_960000_970000\n",
      "Deleted: ./gradients/73686_990000_1000000\n",
      "Deleted: ./gradients/589488_310000_320000\n",
      "Deleted: ./gradients/589488_120000_130000\n",
      "Deleted: ./gradients/368430_180000_190000\n",
      "Deleted: ./gradients/368430_540000_550000\n",
      "Deleted: ./gradients/368430_840000_850000\n",
      "Deleted: ./gradients/368430_480000_490000\n",
      "Deleted: ./gradients/294744_190000_200000\n",
      "Deleted: ./gradients/589488_420000_430000\n",
      "Deleted: ./gradients/589488_470000_480000\n",
      "Deleted: ./gradients/221058_190000_200000\n",
      "Deleted: ./gradients/294744_570000_580000\n",
      "Deleted: ./gradients/221058_220000_230000\n",
      "Deleted: ./gradients/294744_450000_460000\n",
      "Deleted: ./gradients/294744_400000_410000\n",
      "Deleted: ./gradients/221058_150000_160000\n",
      "Deleted: ./gradients/589488_1170000_1180000\n",
      "Deleted: ./gradients/73686_290000_300000\n",
      "Deleted: ./gradients/589488_280000_290000\n",
      "Deleted: ./gradients/638612_140000_150000\n",
      "Deleted: ./gradients/294744_590000_600000\n",
      "Deleted: ./gradients/638612_110000_120000\n",
      "Deleted: ./gradients/221058_480000_490000\n",
      "Deleted: ./gradients/368430_1060000_1070000\n",
      "Deleted: ./gradients/540364_1020000_1030000\n",
      "Deleted: ./gradients/589488_1160000_1170000\n",
      "Deleted: ./gradients/221058_1020000_1030000\n",
      "Deleted: ./gradients/368430_1050000_1060000\n",
      "Deleted: ./gradients/294744_1110000_1120000\n",
      "Deleted: ./gradients/368430_640000_650000\n",
      "Deleted: ./gradients/294744_580000_590000\n",
      "Deleted: ./gradients/540364_1080000_1090000\n",
      "Deleted: ./gradients/589488_810000_820000\n",
      "Deleted: ./gradients/221058_760000_770000\n",
      "Deleted: ./gradients/368430_1120000_1130000\n",
      "Deleted: ./gradients/368430_1130000_1140000\n",
      "Deleted: ./gradients/589488_860000_870000\n",
      "Deleted: ./gradients/73686_370000_380000\n",
      "Deleted: ./gradients/589488_1100000_1110000\n",
      "Deleted: ./gradients/294744_20000_30000\n",
      "Deleted: ./gradients/540364_540000_550000\n",
      "Deleted: ./gradients/589488_830000_840000\n",
      "Deleted: ./gradients/294744_30000_40000\n",
      "Deleted: ./gradients/368430_710000_720000\n",
      "Deleted: ./gradients/589488_870000_880000\n",
      "Deleted: ./gradients/638612_150000_160000\n",
      "Deleted: ./gradients/221058_810000_820000\n",
      "Deleted: ./gradients/221058_340000_350000\n",
      "Deleted: ./gradients/589488_590000_600000\n",
      "Deleted: ./gradients/368430_660000_670000\n",
      "Deleted: ./gradients/638612_100000_110000\n",
      "Deleted: ./gradients/368430_60000_70000\n",
      "Deleted: ./gradients/638612_70000_80000\n",
      "Deleted: ./gradients/368430_550000_560000\n",
      "Deleted: ./gradients/589488_520000_530000\n",
      "Deleted: ./gradients/73686_840000_850000\n",
      "Deleted: ./gradients/368430_880000_890000\n",
      "Deleted: ./gradients/294744_760000_770000\n",
      "Deleted: ./gradients/589488_10000_20000\n",
      "Deleted: ./gradients/294744_1010000_1020000\n",
      "Deleted: ./gradients/442116_1140000_1150000\n",
      "Deleted: ./gradients/368430_120000_130000\n",
      "Deleted: ./gradients/368430_1150000_1160000\n",
      "Deleted: ./gradients/589488_1010000_1020000\n",
      "Deleted: ./gradients/221058_1130000_1140000\n",
      "Deleted: ./gradients/73686_810000_820000\n",
      "Deleted: ./gradients/221058_250000_260000\n",
      "Deleted: ./gradients/294744_770000_780000\n",
      "Deleted: ./gradients/368430_760000_770000\n",
      "Deleted: ./gradients/589488_270000_280000\n",
      "Deleted: ./gradients/614050_1130000_1140000\n",
      "Deleted: ./gradients/294744_430000_440000\n",
      "Deleted: ./gradients/614050_1140000_1150000\n",
      "Deleted: ./gradients/368430_680000_690000\n",
      "Deleted: ./gradients/221058_290000_300000\n",
      "Deleted: ./gradients/294744_600000_610000\n",
      "Deleted: ./gradients/294744_700000_710000\n",
      "Deleted: ./gradients/589488_180000_190000\n",
      "Deleted: ./gradients/221058_520000_530000\n",
      "Deleted: ./gradients/221058_0_10000\n",
      "Deleted: ./gradients/221058_800000_810000\n",
      "Deleted: ./gradients/589488_70000_80000\n",
      "Deleted: ./gradients/589488_680000_690000\n",
      "Deleted: ./gradients/294744_1030000_1040000\n",
      "Deleted: ./gradients/589488_570000_580000\n",
      "Deleted: ./gradients/589488_140000_150000\n",
      "Deleted: ./gradients/221058_230000_240000\n",
      "Deleted: ./gradients/294744_1050000_1060000\n",
      "Deleted: ./gradients/442116_640000_650000\n",
      "Deleted: ./gradients/294744_290000_300000\n",
      "Deleted: ./gradients/589488_410000_420000\n",
      "Deleted: ./gradients/221058_680000_690000\n",
      "Deleted: ./gradients/73686_70000_80000\n",
      "Deleted: ./gradients/368430_280000_290000\n",
      "Deleted: ./gradients/368430_1030000_1040000\n",
      "Deleted: ./gradients/540364_1100000_1110000\n",
      "Deleted: ./gradients/294744_940000_950000\n",
      "Deleted: ./gradients/589488_510000_520000\n",
      "Deleted: ./gradients/221058_540000_550000\n",
      "Deleted: ./gradients/294744_490000_500000\n",
      "Deleted: ./gradients/294744_300000_310000\n",
      "Deleted: ./gradients/221058_350000_360000\n",
      "Deleted: ./gradients/638612_50000_60000\n",
      "Deleted: ./gradients/368430_100000_110000\n",
      "Deleted: ./gradients/73686_820000_830000\n",
      "Deleted: ./gradients/589488_440000_450000\n",
      "Deleted: ./gradients/589488_920000_930000\n",
      "Deleted: ./gradients/73686_980000_990000\n",
      "Deleted: ./gradients/221058_530000_540000\n",
      "Deleted: ./gradients/368430_930000_940000\n",
      "Deleted: ./gradients/589488_240000_250000\n",
      "Deleted: ./gradients/294744_1140000_1150000\n",
      "Deleted: ./gradients/589488_430000_440000\n",
      "Deleted: ./gradients/638612_0_10000\n",
      "Deleted: ./gradients/294744_510000_520000\n",
      "Deleted: ./gradients/294744_1100000_1110000\n",
      "Deleted: ./gradients/221058_1090000_1100000\n",
      "Deleted: ./gradients/73686_830000_840000\n",
      "Deleted: ./gradients/589488_950000_960000\n",
      "Deleted: ./gradients/294744_0_10000\n",
      "Deleted: ./gradients/221058_570000_580000\n",
      "Deleted: ./gradients/294744_1070000_1080000\n",
      "Deleted: ./gradients/540364_1090000_1100000\n",
      "Deleted: ./gradients/540364_1060000_1070000\n",
      "Deleted: ./gradients/368430_950000_960000\n",
      "Deleted: ./gradients/368430_430000_440000\n",
      "Deleted: ./gradients/589488_610000_620000\n",
      "Deleted: ./gradients/589488_700000_710000\n",
      "Deleted: ./gradients/294744_650000_660000\n",
      "Deleted: ./gradients/638612_120000_130000\n",
      "Deleted: ./gradients/221058_1010000_1020000\n",
      "Deleted: ./gradients/294744_950000_960000\n",
      "Deleted: ./gradients/368430_210000_220000\n",
      "Deleted: ./gradients/368430_10000_20000\n",
      "Deleted: ./gradients/294744_900000_910000\n",
      "Deleted: ./gradients/221058_780000_790000\n",
      "Deleted: ./gradients/221058_690000_700000\n",
      "Deleted: ./gradients/221058_120000_130000\n",
      "Deleted: ./gradients/368430_800000_810000\n",
      "Deleted: ./gradients/221058_560000_570000\n",
      "Deleted: ./gradients/221058_550000_560000\n",
      "Deleted: ./gradients/294744_730000_740000\n",
      "Deleted: ./gradients/294744_220000_230000\n",
      "Deleted: ./gradients/589488_500000_510000\n",
      "Deleted: ./gradients/294744_610000_620000\n",
      "Deleted: ./gradients/294744_980000_990000\n",
      "Deleted: ./gradients/368430_420000_430000\n",
      "Deleted: ./gradients/368430_340000_350000\n",
      "Deleted: ./gradients/73686_340000_350000\n",
      "Deleted: ./gradients/638612_80000_90000\n",
      "Deleted: ./gradients/73686_410000_420000\n",
      "Deleted: ./gradients/294744_1020000_1030000\n",
      "Deleted: ./gradients/614050_1150000_1160000\n",
      "Deleted: ./gradients/221058_90000_100000\n",
      "Deleted: ./gradients/540364_980000_990000\n",
      "Deleted: ./gradients/589488_360000_370000\n",
      "Deleted: ./gradients/589488_1130000_1140000\n",
      "Deleted: ./gradients/221058_330000_340000\n",
      "Deleted: ./gradients/368430_860000_870000\n",
      "Deleted: ./gradients/294744_1160000_1170000\n",
      "Deleted: ./gradients/73686_790000_800000\n",
      "Deleted: ./gradients/614050_660000_670000\n",
      "Deleted: ./gradients/294744_100000_110000\n",
      "Deleted: ./gradients/294744_440000_450000\n",
      "Deleted: ./gradients/221058_490000_500000\n",
      "Deleted: ./gradients/589488_740000_750000\n",
      "Deleted: ./gradients/294744_270000_280000\n",
      "Deleted: ./gradients/294744_200000_210000\n",
      "Deleted: ./gradients/368430_1080000_1090000\n",
      "Deleted: ./gradients/589488_850000_860000\n",
      "Deleted: ./gradients/294744_410000_420000\n",
      "Deleted: ./gradients/368430_390000_400000\n",
      "Deleted: ./gradients/294744_500000_510000\n",
      "Deleted: ./gradients/368430_170000_180000\n",
      "Deleted: ./gradients/368430_570000_580000\n",
      "Deleted: ./gradients/73686_1010000_1020000\n",
      "Deleted: ./gradients/589488_480000_490000\n",
      "Deleted: ./gradients/73686_1050000_1060000\n",
      "Deleted: ./gradients/368430_560000_570000\n",
      "Deleted: ./gradients/614050_1160000_1170000\n",
      "Deleted: ./gradients/368430_510000_520000\n",
      "Deleted: ./gradients/221058_730000_740000\n",
      "Deleted: ./gradients/73686_1020000_1030000\n"
     ]
    }
   ],
   "source": [
    "# for file_name in os.listdir(\"./gradients\"):\n",
    "#     file_path = os.path.join(\"./gradients\", file_name)\n",
    "    \n",
    "#     # Check if the current file is not in the list of files to keep\n",
    "#     if str(file_path) not in epoch_checkpoints:\n",
    "\n",
    "        \n",
    "#         if os.path.isfile(file_path):  # Ensure it's a file and not a directory\n",
    "#             # print(file_path)\n",
    "#             # continue\n",
    "#             os.remove(file_path)  # Delete the file\n",
    "#             print(f\"Deleted: {file_path}\")\n",
    "#         else:\n",
    "#             print(f\"Skipped (not a file): {file_path}\")\n",
    "#     else:\n",
    "#         print(f\"Kept: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40847457627118644"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "sum([1 for path \n",
    " in list(itertools.chain(*[[ os.path.join(args[\"gradient_input_dir\"], str(a) + \"_\" + str(i) + \"_\" + str(i +args[\"gradients_per_file\"])) for i in range(0, len(dataset[\"train\"]), args[\"gradients_per_file\"])] for a in epoch_checkpoints]))\n",
    "    if os.path.isfile(path)\n",
    "])/sum([1 for path \n",
    " in list(itertools.chain(*[[ os.path.join(args[\"gradient_input_dir\"], str(a) + \"_\" + str(i) + \"_\" + str(i +args[\"gradients_per_file\"])) for i in range(0, len(dataset[\"train\"]), args[\"gradients_per_file\"])] for a in epoch_checkpoints]))\n",
    "   \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.04658116"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((((len(dataset[\"train\"]) / 10000) *31) ) * 7.4)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"It's very good isn't it?\"}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDX = 9999\n",
    "dataset[\"train\"][IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([c for c in os.listdir(\"10MModel\") if \"checkpoint\" in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.load(os.path.join(args[\"gradient_input_dir\"],\"638612_0_10000\"), weights_only=True,map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{638612: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.bfloat16),\n",
       " 294744: tensor([[-1.1861e-05,  1.0147e-03, -3.9816e-05,  ..., -1.8024e-04,\n",
       "           3.8338e-04,  3.2234e-04],\n",
       "         [-2.6953e-01, -4.5703e-01,  3.4375e-01,  ..., -1.1328e+00,\n",
       "          -8.3923e-04,  4.1211e-01],\n",
       "         [ 2.1362e-03,  4.7493e-04,  1.3123e-03,  ...,  1.4484e-05,\n",
       "           5.0735e-04, -2.1267e-04],\n",
       "         ...,\n",
       "         [ 1.5945e-03,  4.6539e-04,  8.3160e-04,  ...,  2.1362e-04,\n",
       "           6.1798e-04, -2.8419e-04],\n",
       "         [ 1.3885e-03,  6.2180e-04,  1.0910e-03,  ..., -4.4632e-04,\n",
       "           3.3569e-04,  3.9814e-08],\n",
       "         [ 1.5411e-03,  5.0783e-05,  9.6560e-06,  ..., -1.5068e-04,\n",
       "           7.3624e-04, -2.8801e-04]], dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{int(p.split(\"_\")[0]) : torch.load(os.path.join(args[\"gradient_input_dir\"],p), weights_only=True,map_location=\"cpu\")[IDX] for p in os.listdir(args[\"gradient_input_dir\"]) if (IDX >= int(p.split(\"_\")[1])) and (IDX < int(p.split(\"_\")[2]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients =[ (int(p.split(\"_\")[0]), torch.load(os.path.join(args[\"gradient_input_dir\"],p), weights_only=True,map_location=\"cpu\")[IDX].float().flatten(0)) for p in os.listdir(args[\"gradient_input_dir\"]) if (IDX >= int(p.split(\"_\")[1])) and (IDX < int(p.split(\"_\")[2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = sorted(gradients, key=lambda x: x[0])\n",
    "_, gradients = zip(*gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-1.1861e-05,  1.0147e-03, -3.9816e-05,  ..., -1.5068e-04,\n",
       "          7.3624e-04, -2.8801e-04]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.])]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.1861e-05,  1.0147e-03, -3.9816e-05,  ..., -1.5068e-04,\n",
       "          7.3624e-04, -2.8801e-04]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.]))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 393216])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(gradients).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/loriss21dm/babylm/results/10000'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/loriss21dm/babylm/results/10000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m gradients_at_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mlen\u001b[39m(gradients_at_checkpoint)\n",
      "File \u001b[0;32m/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/loriss21dm/babylm/results/10000'"
     ]
    }
   ],
   "source": [
    "# import pickle \n",
    "# import os\n",
    "\n",
    "\n",
    "# path = \"/data/loriss21dm/babylm/results/10000\"\n",
    "\n",
    "# gradients_at_checkpoint = torch.load(path,weights_only=True,map_location=\"cpu\")\n",
    "# len(gradients_at_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 393216])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.flatten(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[188], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "gradients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (10000) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[195], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (10000) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "(torch.stack(gradients) * test_data.flatten(1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01829289,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.dot(torch.stack(gradients).float().numpy(), test_data.flatten(1).T.float().numpy()).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 393216])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(gradients).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([393216, 10000])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.flatten(1).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "batch1 must be a 3D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[190], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: batch1 must be a 3D tensor"
     ]
    }
   ],
   "source": [
    "torch.bmm(torch.stack(gradients),test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 393216])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(gradients).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 393216])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_flat = torch.stack(gradients)#.flatten(-2,-1)\n",
    "t_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[176.0469],\n",
       "        [  0.0000]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(t_flat, torch.transpose(t_flat, 1,2)).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puhzf9dupkolp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm\n",
    "tensor = torch.bmm(t_flat, torch.transpose(t_flat, 1,2)).mean(1)[:, 0:10000]\n",
    "\n",
    "x = np.arange(tensor.shape[0])  \n",
    "y = np.arange(tensor.shape[1])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 15))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors = cm.viridis(np.linspace(0, 1, tensor.shape[1]))\n",
    "for i in range(tensor.shape[1]):  \n",
    "    ax.plot(x, np.full_like(x, y[i]), tensor[:, i], color=colors[i], linewidth=2)\n",
    "\n",
    "\n",
    "ax.set_xlabel('Time [Checkpoints]')\n",
    "ax.set_ylabel('Training example #')\n",
    "ax.set_zlabel('Influence at checkpoint')\n",
    "\n",
    "\n",
    "ax.view_init(elev=25, azim=-40, roll=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, inf in enumerate(torch.bmm(t_flat, torch.transpose(t_flat, 1,2))):\n",
    "    plt.imshow(inf)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.einsum('ijkl,nolp->ijnokp', t_flat, t_flat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_instance =  \"Test <mask>\"\n",
    "# # training_examples = [\"test\", \"is\"]\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# models = []\n",
    "# influences_at_cps = []\n",
    "# for checkpoint in tqdm(checkpoints, desc=\"Checkpoints\"):\n",
    "#   config = RobertaConfig.from_pretrained(checkpoint)\n",
    "#   model = RobertaForMaskedLM(config=config)\n",
    "#   influences_at_cps.append(pw_influence_at_cp(model, test_instance,training_examples[\"input_ids\"]))\n",
    "# end = time.time()\n",
    "# print(datetime.timedelta(seconds=end - start))    \n",
    "# influences_total = torch.stack(influences_at_cps).sum(dim=0)\n",
    "# influences_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(influences_at_cps).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "influences_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
