{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import os\n",
    "import torch\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "2024-10-09 13:09:46.991603: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-09 13:09:47.027854: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-09 13:09:47.073540: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-09 13:09:47.081592: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-09 13:09:47.132958: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-09 13:09:48.559865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "from pathlib import Path\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"TODO\", max_len=512)\n",
    "\n",
    "checkpoints = [str(x) for x in Path(\"/data/loriss21dm/babylm/TODO/\").glob(\"checkpoint-*\") if (int(str(x).split(\"-\")[-1]) % 50000) == 0]#if (int(str(x).split(\"-\")[-1] % 1000)) == 0]\n",
    "checkpoints = checkpoints[0:12]\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"text\", data_dir=\"/data/loriss21dm/babylm/train_test/\")\n",
    "#dataset.set_transform(lambda x : tokenizer(x[\"text\"], return_special_tokens_mask=True, truncation=True, padding=\"max_length\", max_length=512))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataset[\"train\"]) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((len(dataset[\"train\"]) / 1000)*751)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BATCH_SIZE = 1000\n",
    "# def get_all_chunks(checkpoint_path):\n",
    "#     _, start, end = \"/data/loriss21dm/babylm/results/100000_65000_66000\".split(\"_\")\n",
    "#     BATCH_SIZE = int(end) - int(start)\n",
    "#     return [checkpoint_path.split(\"_\")[-3] + \"_\" + str(i) + \"_\" + str(i + BATCH_SIZE) for i in range(0, len(dataset[\"train\"]), BATCH_SIZE)][0:100]\n",
    "# def all_chunks_done_for_checkpoint(checkpoint_path):\n",
    "#     return all([os.path.isfile(chunk) for chunk in get_all_chunks(checkpoint_path)])\n",
    "# all_chunks_done_for_checkpoint(\"/data/loriss21dm/babylm/results/100000_65000_66000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in get_all_chunks(\"/data/loriss21dm/babylm/results/100000_65000_66000\"):\n",
    "#     gradients_at_checkpoint = torch.load(chunk,weights_only=True,map_location=\"cpu\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(get_all_chunks(\"/data/loriss21dm/babylm/results/100000_65000_66000\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"/data/loriss21dm/babylm/results/100000_65000_66000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [torch.load(chunk, weights_only=True,map_location=\"cpu\") for chunk in get_all_chunks(\"/data/loriss21dm/babylm/results/100000_65000_66000\")[0:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradients_at_checkpoint = torch.concat([torch.load(chunk, weights_only=True,map_location=\"cpu\") for chunk in tqdm(get_all_chunks(\"/data/loriss21dm/babylm/results/100000_65000_66000\"), desc=\"Loading checkpoint chunks from disk\")]).flatten(1)#.to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mean_influence_at_checkpoint_at(checkpoint_path):\n",
    "#     with torch.no_grad(): # TODO redundant\n",
    "#         gradients_at_checkpoint = torch.concat([torch.load(chunk, weights_only=True,map_location=\"cpu\") for chunk in tqdm(get_all_chunks(checkpoint_path), desc=\"Loading checkpoint chunks from disk\")]).flatten(1)\n",
    "#         return (gradients_at_checkpoint @ gradients_at_checkpoint.transpose(1, 0)).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mean_influence_at_checkpoint(checkpoint_path):\n",
    "#     with torch.no_grad(): # TODO redundant\n",
    "#         gradients_at_checkpoint = torch.concat([torch.load(chunk, weights_only=True,map_location=\"cpu\") for chunk in tqdm(get_all_chunks(checkpoint_path), desc=\"Loading checkpoint chunks from disk\")]).unsqueeze(0)\n",
    "#         t_flat = gradients_at_checkpoint.flatten(-2,-1)\n",
    "#         return torch.bmm(t_flat, torch.transpose(t_flat, 1,2)).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mean_influence_at_checkpoint_einsum(checkpoint_path):\n",
    "    \n",
    "#     gradients_at_checkpoint = torch.concat([torch.load(chunk, weights_only=True,map_location=\"cpu\") for chunk in tqdm(get_all_chunks(checkpoint_path), desc=\"Loading checkpoint chunks from disk\")]).flatten(1)\n",
    "#   #  print(gradients_at_checkpoint.shape)\n",
    "#     return (torch.einsum('ik, kj -> i', gradients_at_checkpoint, gradients_at_checkpoint.T) / gradients_at_checkpoint.shape[0]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mean_influence_at_checkpoint_chunked(checkpoint_path):\n",
    "#     gradients_at_checkpoint = torch.zeros((len(dataset[\"train\"],)))#.to(\"cuda:0\")\n",
    "#     for chunk_path_a in tqdm(get_all_chunks(checkpoint_path), desc=\"Calculating chunk-wise mean influence\"):\n",
    "#         _, start_id_a, stop_id_a = chunk_path_a.split( \"_\")\n",
    "#         start_id_a = int(start_id_a)\n",
    "#         stop_id_a = int(stop_id_a)\n",
    "#         chunk_a = torch.load(chunk_path_a, weights_only=True,map_location=\"cpu\").flatten(1)\n",
    "#         for chunk_path_b in get_all_chunks(checkpoint_path):\n",
    "#             _, start_id_b, stop_id_b = chunk_path_b.split( \"_\")\n",
    "        \n",
    "#             start_id_b = int(start_id_b)\n",
    "#             stop_id_b = int(stop_id_b)\n",
    "\n",
    "#             #print(chunk_path_a, chunk_path_b)\n",
    "            \n",
    "#             chunk_b = torch.load(chunk_path_b, weights_only=True,map_location=\"cpu\").flatten(1)\n",
    "\n",
    "#             gradients_at_checkpoint[start_id_a:stop_id_a] += torch.einsum('ik, kj -> i', chunk_a, chunk_b.T)\n",
    "#     return (gradients_at_checkpoint / len(dataset[\"train\"])).unsqueeze(0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mean_influence_at_checkpoint_chunked(checkpoint_path):\n",
    "#     gradients_at_checkpoint = torch.zeros((len(dataset[\"train\"],)))#.to(\"cuda:0\")\n",
    "#     for chunk_path_a in tqdm(get_all_chunks(checkpoint_path), desc=\"Calculating chunk-wise mean influence\"):\n",
    "#         _, start_id_a, stop_id_a = chunk_path_a.split( \"_\")\n",
    "#         start_id_a = int(start_id_a)\n",
    "#         stop_id_a = int(stop_id_a)\n",
    "#         chunk_a = torch.load(chunk_path_a, weights_only=True,map_location=\"cpu\").flatten(1)\n",
    "#         for chunk_path_b in get_all_chunks(checkpoint_path):\n",
    "#             _, start_id_b, stop_id_b = chunk_path_b.split( \"_\")\n",
    "        \n",
    "#             start_id_b = int(start_id_b)\n",
    "#             stop_id_b = int(stop_id_b)\n",
    "\n",
    "#             #print(chunk_path_a, chunk_path_b)\n",
    "            \n",
    "#             chunk_b = torch.load(chunk_path_b, weights_only=True,map_location=\"cpu\").flatten(1)\n",
    "\n",
    "#             gradients_at_checkpoint[start_id_a:stop_id_a] += torch.einsum('ik, kj -> i', chunk_a, chunk_b.T)\n",
    "#     return (gradients_at_checkpoint / len(dataset[\"train\"])).unsqueeze(0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘results2’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335.7130666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "((psutil.virtual_memory().available >> 20)/750)*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.761111111111111"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((677/90)*30)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting merge.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile merge.py\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "os.environ['HF_HOME'] = '/data/loriss21dm/hfcache'\n",
    "import traceback\n",
    "\n",
    "\n",
    "# cache = {} \n",
    "# import random \n",
    "# def get_cached(tensor_path, device, cache):\n",
    "\n",
    "#     #return torch.load(tensor_path, weights_only=True,map_location=device).flatten(1)\n",
    "#     if tensor_path in cache:\n",
    "#         # cache[tensor_path] = (cache[tensor_path][0]+1, cache[tensor_path][1])\n",
    "#             return cache[tensor_path]\n",
    "#     else:\n",
    "        \n",
    "#         if len(cache) >= CACHE_SIZE:\n",
    "#             cache.pop(random.choice(cache.keys()))\n",
    "#         cache[tensor_path] = torch.load(tensor_path, \n",
    "#       #  print(cache, flush=True)\n",
    "#         return cache[tensor_path]\n",
    "\n",
    "def run(chunk_path_a, start_id_a, stop_id_a, subtasks):\n",
    "   # print(\"start\",start_id_a, stop_id_a, flush=True)\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "    gpu_id = queue.get()\n",
    "    device = \"cpu\"#\"cuda:\" + str(gpu_id)\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "       #     print(\"start\", start_id_a, stop_id_a, flush=True)\n",
    "            chunk_a = torch.load(chunk_path_a, weights_only=True,map_location=device).flatten(1)\n",
    "           # print(\"f\", flush=True)\n",
    "            result = torch.zeros((chunk_a.shape[0])).to(device)\n",
    "            # return (start_id_a, stop_id_a, result.cpu())\n",
    "        # return (start_id_a, stop_id_a, result)\n",
    "            for chunk_path_b,start_id_b, stop_id_b in tqdm(subtasks, leave=False):\n",
    "                chunk_b = torch.load(chunk_path_b, weights_only=True,map_location=device).flatten(1)\n",
    "               # print(\"loaded\", flush=True)\n",
    "               # print(chunk_b.shape,flush=True)\n",
    "                \n",
    "                # print(chunk_a.shape, chunk_b.shape, flush=True)\n",
    "                # print(torch.einsum('ik, kj -> i', chunk_a[0:10], chunk_b[0:10].T), flush=True)\n",
    "                result  += torch.einsum('ik, kj -> i', chunk_a, chunk_b.T)\n",
    "                \n",
    "                #print(\"t\", start_id_b, stop_id_b, flush=True)\n",
    "            #print(\"result\", result.shape, flush=True)\n",
    "       #     print(\"got\", start_id_a, stop_id_a, flush=True)\n",
    "            queue.put(gpu_id)\n",
    "            # print(\"aaaaaaaa\", )\n",
    "            return (start_id_a, stop_id_a, result)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc(),flush=True)\n",
    "        raise e\n",
    "###############\n",
    "from multiprocessing import Pool, current_process\n",
    "import time \n",
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from itertools import cycle\n",
    "os.environ['HF_HOME'] = '/data/loriss21dm/hfcache'\n",
    "# # import multiprocessing as mp\n",
    "# # mp.set_start_method('spawn', force=True)\n",
    "\n",
    "\n",
    "\n",
    "from multiprocessing import Pool,Queue,Manager\n",
    "\n",
    "# def f(x):\n",
    "#     return x*x\n",
    "import multiprocessing as mp\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mp.set_start_method('fork')\n",
    "    import os\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "    os.environ['HF_HOME'] = '/data/loriss21dm/hfcache'\n",
    "    from transformers import RobertaConfig,AutoConfig\n",
    "    from transformers import RobertaForMaskedLM\n",
    "    import torch\n",
    "    from tqdm import tqdm\n",
    "    from transformers import RobertaTokenizerFast\n",
    "    from transformers import DataCollatorForLanguageModeling\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(\"TODO\", max_len=512)\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    "    )\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(\"text\", data_dir=\"/data/loriss21dm/babylm/train_test/\")\n",
    "    dataset.set_transform(lambda x : tokenizer(x[\"text\"], return_special_tokens_mask=True, truncation=True, padding=\"max_length\", max_length=512))\n",
    "\n",
    "\n",
    "    \n",
    "    def get_all_chunks(checkpoint_path):\n",
    "        BATCH_SIZE = 1000\n",
    "        return [ \"./results/\"  + checkpoint_path.split(\"-\")[-1] + \"_\" + str(i) + \"_\" + str(i + BATCH_SIZE) for i in range(0, len(dataset[\"train\"]), BATCH_SIZE)]#[0:100]\n",
    "\n",
    "    #.to(\"cuda:0\")\n",
    "# torch.zeros((chunk_a.shape[0]))\n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    PROCCESSES = 90\n",
    "    NUM_GPUS = 2\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "   \n",
    "\n",
    "    queue = Queue()\n",
    "    NUM_GPUS = 2\n",
    "    for _ in range(PROCCESSES//NUM_GPUS):\n",
    "        for i in range(NUM_GPUS):\n",
    "            queue.put(i)\n",
    "\n",
    "    with Pool(PROCCESSES) as p:\n",
    "        checkpoints = [str(x) for x in Path(\"/data/loriss21dm/babylm/TODO/\").glob(\"checkpoint-*\") if (int(str(x).split(\"-\")[-1]) % 50000) == 0]#if (int(str(x).split(\"-\")[-1] % 1000)) == 0]\n",
    "        checkpoints = checkpoints#[0:2]\n",
    "        for checkpoint_path in tqdm(checkpoints, desc=\"Running for checkpoints\", leave=False):\n",
    "            result_checkpoint = torch.zeros((len(dataset[\"train\"])))\n",
    "            out_path = os.path.join(\"./results2/\", checkpoint_path.split(\"-\")[-1])\n",
    "            print(out_path, checkpoint_path)\n",
    "            if os.path.isfile(out_path):\n",
    "                True\n",
    "                #continue\n",
    "\n",
    "            tasks = []\n",
    "            for chunk_path_a in get_all_chunks(checkpoint_path):\n",
    "                _, start_id_a, stop_id_a = chunk_path_a.split( \"_\")\n",
    "                start_id_a = int(start_id_a)\n",
    "                stop_id_a = int(stop_id_a)\n",
    "                subtasks = []\n",
    "                for chunk_path_b in get_all_chunks(checkpoint_path):\n",
    "                    _, start_id_b, stop_id_b = chunk_path_b.split( \"_\")\n",
    "                    start_id_b = int(start_id_b)\n",
    "                    stop_id_b = int(stop_id_b)\n",
    "                    subtasks.append((chunk_path_b,start_id_b, stop_id_b))\n",
    "                tasks.append((chunk_path_a, start_id_a, stop_id_a, subtasks))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            r = p.starmap(run, tasks )\n",
    "            # r.wait()\n",
    "            print(\"merging\", flush=True) \n",
    "            for start_id_a, _, rr in r:\n",
    "                # print(start_id_a, stop_id_b, start_id_a + rr.shape[0])\n",
    "                #  print(\"jjj\",rr.shape, (result[start_id_a:start_id_a + rr.shape[0]]).shape)\n",
    "                # print(\"before\", result_checkpoint.shape)\n",
    "                result_checkpoint[start_id_a:start_id_a + rr.shape[0]] += rr #  the stop_ids are taken from the task description in if.ipynb and can therefore be higher than the actual lenght\n",
    "                # print(\"after\", result_checkpoint.shape)\n",
    "\n",
    "            result_checkpoint = (result_checkpoint / len(dataset[\"train\"])).unsqueeze(0) \n",
    "            # print(result.shape)\n",
    "            \n",
    "            print(\"saving\", out_path, flush=True)    \n",
    "            torch.save(result_checkpoint, out_path)\n",
    "# pickle.dump( result, open( \"./results/\"+(path.split(\"-\")[-1]), \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run merge.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"train\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "# pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000</th>\n",
       "      <th>50000</th>\n",
       "      <th>150000</th>\n",
       "      <th>total</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000595</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>= = = PG21374 = = =</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>!TENTION: A STORY OF BOY-LIFE DURING THE PENIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>Produced by Nick Hodson of London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>!Tention, a Story of Boy-Life during the Penin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001105</td>\n",
       "      <td>______________________________________________...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676009</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Page 242 out of your gripe _changed to_ out of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676010</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Page 326 20. HARDSCRABBLE OF ELM ISLAND _chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676011</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Number 32 in the list of books or the Fortunes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676012</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>End of the Project Gutenberg EBook of Charle B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676013</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676014 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               100000     50000    150000     total  \\\n",
       "document_id                                           \n",
       "0           -0.000595 -0.000072  0.000004 -0.000663   \n",
       "1            0.000379  0.000225 -0.000127  0.000477   \n",
       "2            0.000660  0.000464  0.001031  0.002155   \n",
       "3            0.000282  0.000187  0.000283  0.000752   \n",
       "4            0.000000 -0.001105  0.000000 -0.001105   \n",
       "...               ...       ...       ...       ...   \n",
       "676009       0.000000  0.000000  0.000000  0.000000   \n",
       "676010       0.000000  0.000000  0.000000  0.000000   \n",
       "676011       0.000000  0.000000  0.000000  0.000000   \n",
       "676012       0.000000  0.000000  0.000000  0.000000   \n",
       "676013       0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                                          text  \n",
       "document_id                                                     \n",
       "0                                          = = = PG21374 = = =  \n",
       "1            !TENTION: A STORY OF BOY-LIFE DURING THE PENIN...  \n",
       "2                   Produced by Nick Hodson of London, England  \n",
       "3            !Tention, a Story of Boy-Life during the Penin...  \n",
       "4            ______________________________________________...  \n",
       "...                                                        ...  \n",
       "676009       Page 242 out of your gripe _changed to_ out of...  \n",
       "676010       Page 326 20. HARDSCRABBLE OF ELM ISLAND _chang...  \n",
       "676011       Number 32 in the list of books or the Fortunes...  \n",
       "676012       End of the Project Gutenberg EBook of Charle B...  \n",
       "676013                                                          \n",
       "\n",
       "[676014 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame({result_checkpoint: torch.load(os.path.join(\"./results2/\",result_checkpoint),weights_only=True,map_location=\"cpu\").numpy().flatten() for result_checkpoint in os.listdir(\"./results2\")})\n",
    "# df = df.rename({0: \"influence\"}, axis=1)\n",
    "df.index = df.index.rename(\"document_id\")\n",
    "df[\"total\"] = df.sum(axis=1)\n",
    "df[\"text\"] = dataset[\"train\"].to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STAGES = os.listdir(\"./results2\")\n",
    "NUM_STAGES = len(STAGES)\n",
    "NUM_STAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225338"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_DOCS_STAGE = len(df) // NUM_STAGES\n",
    "NUM_DOCS_STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225338"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_DOCS_STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676014"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_DOCS_STAGE*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8313808"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def influence_stage(df, stage):\n",
    "    return df[stage].nlargest(NUM_DOCS_STAGE).sum()\n",
    "influence_stage(df, \"50000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.176044, 2.8313808, 3.2834117]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[influence_stage(df, t) for t in STAGES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225871"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take NUM_DOCS_STAGE of each stage\n",
    "len(set.union(*[set(df[s].nlargest(NUM_DOCS_STAGE).index) for s in STAGES]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximize with budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_col = lambda col, selection : selection[col].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7947662"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influence_col(\"50000\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = df[200:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04796267207711935"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#       sum\n",
    "score = sum([influence_col(s, selection) for s in  STAGES])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = df[STAGES].to_numpy()[0:1000,:]\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,n.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.convolve(n[0,:],np.array([0,1,0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1002, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_along_axis(lambda m: np.convolve(m, np.array([1,3,1]), mode='full'), axis=0, arr=n).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.stats import f\n",
    "from scipy.stats import lognorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "size=len(STAGES)\n",
    "print(size)\n",
    "def gaussian_filter(size, **args):\n",
    "    print(args)\n",
    "    indices = np.arange(-size, size+1, 1)\n",
    "    weights =  norm.pdf(indices, **args)\n",
    "    return weights# / np.sum(weights)\n",
    "\n",
    "\n",
    "def f_filter(size, **args):\n",
    "    print(args)\n",
    "    indices = np.arange(-size, size+1, 1)\n",
    "    print(indices)\n",
    "    weights = f.pdf(indices+1, **args)\n",
    "    return weights# / np.sum(weights)\n",
    "def lognorm_filter(size, **args):\n",
    "    #print(args)\n",
    "    indices = np.arange(-size, size+1, 1)\n",
    "    #print(indices)\n",
    "    weights = lognorm.pdf(indices+1, **args)\n",
    "    return weights / np.sum(weights)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_weights = f_filter(size, dfn=15, dfd=3)\n",
    "# print(filter_weights)\n",
    "# plt.plot(np.arange(-size,size, 1),filter_weights)\n",
    "# plt.vlines(0, ymin=0, ymax=max(filter_weights)+0.1, colors=[\"red\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7f1ef6f2b5e0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "filter_weights = lognorm_filter(size, s=1, loc=0, scale=0.5)\n",
    "plt.plot(np.arange(-size,size+1, 1),filter_weights)\n",
    "plt.vlines([0], ymin=0, ymax=max(filter_weights)+0.1, colors=[\"red\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.73264085, 0.17818617,\n",
       "       0.06236903, 0.02680395])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_STAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.32640851e+02,\n",
       "       1.85512580e+02, 6.48835321e+01, 2.76058246e+01, 3.30408511e-01,\n",
       "       2.68039481e-02])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1000,10,1,]\n",
    "np.convolve(a,filter_weights, mode=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676014, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = df[STAGES].to_numpy()#[0:1000,:]\n",
    "scores = np.apply_along_axis(lambda m: np.convolve(m,filter_weights, mode=\"valid\")[1:-1], axis=1, arr=n)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usefulness = df.copy()\n",
    "df_usefulness[STAGES] = np.apply_along_axis(lambda m: np.convolve(m,filter_weights, mode=\"valid\")[1:-1], axis=1, arr=n)\n",
    "df_usefulness[\"total\"] = df_usefulness[STAGES].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000</th>\n",
       "      <th>50000</th>\n",
       "      <th>150000</th>\n",
       "      <th>total</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>0.019242</td>\n",
       "      <td>\"Listen.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>\"Do you feel so hungry now, Punch?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>0.009301</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>\"Back to prison.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9820</th>\n",
       "      <td>0.012525</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.016581</td>\n",
       "      <td>\"Ugh!\" shuddered Aileen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0.009694</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015824</td>\n",
       "      <td>\"I can't, Punch.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8038</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001429</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>Ranworth shook his head.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001398</td>\n",
       "      <td>-0.001489</td>\n",
       "      <td>EDINBURGH, 1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>-0.001910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>\"_Frances_?\" he said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>-0.000534</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.001685</td>\n",
       "      <td>Perhaps so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>-0.001999</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-0.001755</td>\n",
       "      <td>SAN FRANCISCO                              104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676014 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               100000     50000    150000     total  \\\n",
       "document_id                                           \n",
       "1859         0.007310  0.000000  0.011932  0.019242   \n",
       "1105         0.002396  0.003626  0.011488  0.017509   \n",
       "2177         0.009301  0.007586  0.000558  0.017446   \n",
       "9820         0.012525  0.003974  0.000082  0.016581   \n",
       "936          0.009694  0.006130  0.000000  0.015824   \n",
       "...               ...       ...       ...       ...   \n",
       "8038         0.000065  0.000000 -0.001429 -0.001363   \n",
       "3518        -0.000091  0.000000 -0.001398 -0.001489   \n",
       "1625        -0.001910  0.000000  0.000314 -0.001596   \n",
       "8994        -0.000534 -0.001066 -0.000085 -0.001685   \n",
       "3026        -0.001999  0.000144  0.000100 -0.001755   \n",
       "\n",
       "                                                       text  \n",
       "document_id                                                  \n",
       "1859                                              \"Listen.\"  \n",
       "1105                    \"Do you feel so hungry now, Punch?\"  \n",
       "2177                                      \"Back to prison.\"  \n",
       "9820                               \"Ugh!\" shuddered Aileen.  \n",
       "936                                       \"I can't, Punch.\"  \n",
       "...                                                     ...  \n",
       "8038                               Ranworth shook his head.  \n",
       "3518                                        EDINBURGH, 1870  \n",
       "1625                                  \"_Frances_?\" he said.  \n",
       "8994                                            Perhaps so.  \n",
       "3026         SAN FRANCISCO                              104  \n",
       "\n",
       "[676014 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"total\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000</th>\n",
       "      <th>50000</th>\n",
       "      <th>150000</th>\n",
       "      <th>total</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>\"Back to prison.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9820</th>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>\"Ugh!\" shuddered Aileen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>0.015856</td>\n",
       "      <td>\"Listen.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.015018</td>\n",
       "      <td>\"I can't, Punch.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148</th>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>\"You aren’t afraid?\" he asked.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>-0.000870</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>Joe grinned happily.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>-0.001106</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>Carrots got slowly down off his high chair, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.000876</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>-0.001553</td>\n",
       "      <td>Perhaps so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>-0.001399</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.001629</td>\n",
       "      <td>\"_Frances_?\" he said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>-0.001464</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>SAN FRANCISCO                              104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676014 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               100000     50000    150000     total  \\\n",
       "document_id                                           \n",
       "2177         0.006815  0.007215  0.002341  0.016371   \n",
       "9820         0.009176  0.005143  0.001549  0.015869   \n",
       "1859         0.005356  0.001303  0.009198  0.015856   \n",
       "936          0.007102  0.006219  0.001697  0.015018   \n",
       "9148         0.003666  0.006296  0.004129  0.014091   \n",
       "...               ...       ...       ...       ...   \n",
       "9967        -0.000870 -0.000212 -0.000074 -0.001155   \n",
       "4192        -0.001106 -0.000124 -0.000047 -0.001277   \n",
       "8994        -0.000391 -0.000876 -0.000286 -0.001553   \n",
       "1625        -0.001399 -0.000340  0.000111 -0.001629   \n",
       "3026        -0.001464 -0.000251 -0.000026 -0.001741   \n",
       "\n",
       "                                                          text  \n",
       "document_id                                                     \n",
       "2177                                         \"Back to prison.\"  \n",
       "9820                                  \"Ugh!\" shuddered Aileen.  \n",
       "1859                                                 \"Listen.\"  \n",
       "936                                          \"I can't, Punch.\"  \n",
       "9148                            \"You aren’t afraid?\" he asked.  \n",
       "...                                                        ...  \n",
       "9967                                      Joe grinned happily.  \n",
       "4192         Carrots got slowly down off his high chair, an...  \n",
       "8994                                               Perhaps so.  \n",
       "1625                                     \"_Frances_?\" he said.  \n",
       "3026            SAN FRANCISCO                              104  \n",
       "\n",
       "[676014 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usefulness = df_usefulness.sort_values(by=\"total\", ascending=False)\n",
    "df_usefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000</th>\n",
       "      <th>50000</th>\n",
       "      <th>150000</th>\n",
       "      <th>total</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>\"No,\" agreed Carrots again, \"we never did.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.012254</td>\n",
       "      <td>\"Yes.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9820</th>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>\"Ugh!\" shuddered Aileen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>0.008605</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>\"Thou will not fail To listen to a fairy tale.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7751</th>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>\"Nine.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228173</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Antony Blake--or Frank Antony Blake, to give h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228115</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>'Well,' said the young fellow, 'I have a sweet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228127</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>It was getting early dark to-night, and one gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228128</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes they had to creep quite sideways thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228129</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>'On the whole,' said young Blake, 'I'm glad yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225338 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               100000     50000    150000     total  \\\n",
       "document_id                                           \n",
       "4266         0.009384  0.002282  0.000837  0.012504   \n",
       "4777         0.009225  0.002244  0.000785  0.012254   \n",
       "9820         0.009176  0.005143  0.001549  0.015869   \n",
       "4026         0.008605  0.002091  0.000969  0.011664   \n",
       "7751         0.008308  0.002161  0.000741  0.011210   \n",
       "...               ...       ...       ...       ...   \n",
       "228173       0.000000  0.000000  0.000000  0.000000   \n",
       "228115       0.000000  0.000000  0.000000  0.000000   \n",
       "228127       0.000000  0.000000  0.000000  0.000000   \n",
       "228128       0.000000  0.000000  0.000000  0.000000   \n",
       "228129       0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                                          text  \n",
       "document_id                                                     \n",
       "4266               \"No,\" agreed Carrots again, \"we never did.\"  \n",
       "4777                                                    \"Yes.\"  \n",
       "9820                                  \"Ugh!\" shuddered Aileen.  \n",
       "4026           \"Thou will not fail To listen to a fairy tale.\"  \n",
       "7751                                                   \"Nine.\"  \n",
       "...                                                        ...  \n",
       "228173       Antony Blake--or Frank Antony Blake, to give h...  \n",
       "228115       'Well,' said the young fellow, 'I have a sweet...  \n",
       "228127       It was getting early dark to-night, and one gr...  \n",
       "228128       Sometimes they had to creep quite sideways thr...  \n",
       "228129       'On the whole,' said young Blake, 'I'm glad yo...  \n",
       "\n",
       "[225338 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usefulness.sort_values(by=STAGES[0], ascending=False)[0:NUM_DOCS_STAGE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_usefulness_ = df_usefulness.copy()\n",
    "for stage in STAGES:\n",
    "    pd.concat([df_usefulness_,df_usefulness.sort_values(by=STAGES[1], ascending=False)]).drop_duplicates(keep=\"first\")[0:2*NUM_DOCS_STAGE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000</th>\n",
       "      <th>50000</th>\n",
       "      <th>150000</th>\n",
       "      <th>total</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>\"Back to prison.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9820</th>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>\"Ugh!\" shuddered Aileen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>0.015856</td>\n",
       "      <td>\"Listen.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.015018</td>\n",
       "      <td>\"I can't, Punch.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148</th>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>\"You aren’t afraid?\" he asked.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>-0.000870</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>Joe grinned happily.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>-0.001106</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>Carrots got slowly down off his high chair, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.000876</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>-0.001553</td>\n",
       "      <td>Perhaps so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>-0.001399</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.001629</td>\n",
       "      <td>\"_Frances_?\" he said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>-0.001464</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>SAN FRANCISCO                              104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676014 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               100000     50000    150000     total  \\\n",
       "document_id                                           \n",
       "2177         0.006815  0.007215  0.002341  0.016371   \n",
       "9820         0.009176  0.005143  0.001549  0.015869   \n",
       "1859         0.005356  0.001303  0.009198  0.015856   \n",
       "936          0.007102  0.006219  0.001697  0.015018   \n",
       "9148         0.003666  0.006296  0.004129  0.014091   \n",
       "...               ...       ...       ...       ...   \n",
       "9967        -0.000870 -0.000212 -0.000074 -0.001155   \n",
       "4192        -0.001106 -0.000124 -0.000047 -0.001277   \n",
       "8994        -0.000391 -0.000876 -0.000286 -0.001553   \n",
       "1625        -0.001399 -0.000340  0.000111 -0.001629   \n",
       "3026        -0.001464 -0.000251 -0.000026 -0.001741   \n",
       "\n",
       "                                                          text  \n",
       "document_id                                                     \n",
       "2177                                         \"Back to prison.\"  \n",
       "9820                                  \"Ugh!\" shuddered Aileen.  \n",
       "1859                                                 \"Listen.\"  \n",
       "936                                          \"I can't, Punch.\"  \n",
       "9148                            \"You aren’t afraid?\" he asked.  \n",
       "...                                                        ...  \n",
       "9967                                      Joe grinned happily.  \n",
       "4192         Carrots got slowly down off his high chair, an...  \n",
       "8994                                               Perhaps so.  \n",
       "1625                                     \"_Frances_?\" he said.  \n",
       "3026            SAN FRANCISCO                              104  \n",
       "\n",
       "[676014 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450676\n",
      "225338\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000</th>\n",
       "      <th>50000</th>\n",
       "      <th>150000</th>\n",
       "      <th>total</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>\"No,\" agreed Carrots again, \"we never did.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.012254</td>\n",
       "      <td>\"Yes.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9820</th>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>\"Ugh!\" shuddered Aileen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>0.008605</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>\"Thou will not fail To listen to a fairy tale.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7751</th>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>\"Nine.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659369</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>“Well, I hope you’ll try for the crew,” answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659401</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>When the door had closed again Dick took up th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659402</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>“Dear Dick” (it ran), “Wheels has sent for me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659419</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>“Do you run much?” he asked.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659404</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>“CARL.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225338 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               100000     50000    150000     total  \\\n",
       "document_id                                           \n",
       "4266         0.009384  0.002282  0.000837  0.012504   \n",
       "4777         0.009225  0.002244  0.000785  0.012254   \n",
       "9820         0.009176  0.005143  0.001549  0.015869   \n",
       "4026         0.008605  0.002091  0.000969  0.011664   \n",
       "7751         0.008308  0.002161  0.000741  0.011210   \n",
       "...               ...       ...       ...       ...   \n",
       "659369       0.000000  0.000000  0.000000  0.000000   \n",
       "659401       0.000000  0.000000  0.000000  0.000000   \n",
       "659402       0.000000  0.000000  0.000000  0.000000   \n",
       "659419       0.000000  0.000000  0.000000  0.000000   \n",
       "659404       0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                                          text  \n",
       "document_id                                                     \n",
       "4266               \"No,\" agreed Carrots again, \"we never did.\"  \n",
       "4777                                                    \"Yes.\"  \n",
       "9820                                  \"Ugh!\" shuddered Aileen.  \n",
       "4026           \"Thou will not fail To listen to a fairy tale.\"  \n",
       "7751                                                   \"Nine.\"  \n",
       "...                                                        ...  \n",
       "659369       “Well, I hope you’ll try for the crew,” answer...  \n",
       "659401       When the door had closed again Dick took up th...  \n",
       "659402       “Dear Dick” (it ran), “Wheels has sent for me ...  \n",
       "659419                            “Do you run much?” he asked.  \n",
       "659404                                                  “CARL.  \n",
       "\n",
       "[225338 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000</th>\n",
       "      <th>50000</th>\n",
       "      <th>150000</th>\n",
       "      <th>total</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>\"No.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9160</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.008753</td>\n",
       "      <td>\"And for you?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.005933</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>\"Think so?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>\"Of course.  What will happen?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>\"So's mine.  I say, don't they ache?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666904</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>“Thank you, my dear young ‘maw,’ but you will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666905</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CHAPTER XIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666906</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>THE MYSTERIOUS GIRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666923</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>“Yes; Diane and Grace and I were standing on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666908</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Cathalina’s chair had happened to be turned wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225338 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               100000     50000    150000     total  \\\n",
       "document_id                                           \n",
       "744          0.000000  0.006352  0.001545  0.007896   \n",
       "9160         0.000000  0.005938  0.002815  0.008753   \n",
       "426         -0.000146  0.005933  0.001462  0.007249   \n",
       "9129         0.000000  0.005925  0.001721  0.007646   \n",
       "2514         0.000000  0.005742  0.001397  0.007139   \n",
       "...               ...       ...       ...       ...   \n",
       "666904       0.000000  0.000000  0.000000  0.000000   \n",
       "666905       0.000000  0.000000  0.000000  0.000000   \n",
       "666906       0.000000  0.000000  0.000000  0.000000   \n",
       "666923       0.000000  0.000000  0.000000  0.000000   \n",
       "666908       0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                                          text  \n",
       "document_id                                                     \n",
       "744                                                      \"No.\"  \n",
       "9160                                            \"And for you?\"  \n",
       "426                                                \"Think so?\"  \n",
       "9129                           \"Of course.  What will happen?\"  \n",
       "2514                     \"So's mine.  I say, don't they ache?\"  \n",
       "...                                                        ...  \n",
       "666904       “Thank you, my dear young ‘maw,’ but you will ...  \n",
       "666905                                            CHAPTER XIII  \n",
       "666906                                     THE MYSTERIOUS GIRL  \n",
       "666923       “Yes; Diane and Grace and I were standing on t...  \n",
       "666908       Cathalina’s chair had happened to be turned wi...  \n",
       "\n",
       "[225338 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000</th>\n",
       "      <th>50000</th>\n",
       "      <th>150000</th>\n",
       "      <th>total</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>\"No.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>\"Which way?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>\"But--\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>\"Bread.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>\"You don't?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>-0.000870</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>Joe grinned happily.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8011</th>\n",
       "      <td>-0.000123</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>On the windward side of the huts, dome-shaped ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8552</th>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>THE SCOUT LIBRARY STORIES OF ADVENTURE.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.000876</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>-0.001553</td>\n",
       "      <td>Perhaps so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.001030</td>\n",
       "      <td>-0.001112</td>\n",
       "      <td>EDINBURGH, 1870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225338 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               100000     50000    150000     total  \\\n",
       "document_id                                           \n",
       "1217         0.000000  0.000000  0.008638  0.008638   \n",
       "2025         0.000000  0.000000  0.006068  0.006068   \n",
       "1673         0.000000  0.000000  0.004493  0.004493   \n",
       "463          0.000000  0.000000  0.003912  0.003912   \n",
       "743          0.000000  0.000000  0.003774  0.003774   \n",
       "...               ...       ...       ...       ...   \n",
       "9967        -0.000870 -0.000212 -0.000074 -0.001155   \n",
       "8011        -0.000123 -0.000045 -0.000147 -0.000315   \n",
       "8552        -0.000006 -0.000001 -0.000250 -0.000257   \n",
       "8994        -0.000391 -0.000876 -0.000286 -0.001553   \n",
       "3518        -0.000066 -0.000016 -0.001030 -0.001112   \n",
       "\n",
       "                                                          text  \n",
       "document_id                                                     \n",
       "1217                                                     \"No.\"  \n",
       "2025                                              \"Which way?\"  \n",
       "1673                                                   \"But--\"  \n",
       "463                                                   \"Bread.\"  \n",
       "743                                               \"You don't?\"  \n",
       "...                                                        ...  \n",
       "9967                                      Joe grinned happily.  \n",
       "8011         On the windward side of the huts, dome-shaped ...  \n",
       "8552                   THE SCOUT LIBRARY STORIES OF ADVENTURE.  \n",
       "8994                                               Perhaps so.  \n",
       "3518                                           EDINBURGH, 1870  \n",
       "\n",
       "[225338 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_usefulness_ = df_usefulness.copy()\n",
    "dfs_selection = []\n",
    "for stage in STAGES:\n",
    "    dfs_selection.append(df_usefulness_.nlargest(NUM_DOCS_STAGE, columns=stage))\n",
    "    df_usefulness_ = df_usefulness_.nsmallest(len(df_usefulness_) - NUM_DOCS_STAGE, columns=stage)\n",
    "    print(len(df_usefulness_))\n",
    "print(len(df_usefulness_))\n",
    "for a in dfs_selection:\n",
    "    display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000</th>\n",
       "      <th>50000</th>\n",
       "      <th>150000</th>\n",
       "      <th>total</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>\"Back to prison.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9820</th>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>\"Ugh!\" shuddered Aileen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>0.015856</td>\n",
       "      <td>\"Listen.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.015018</td>\n",
       "      <td>\"I can't, Punch.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148</th>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>\"You aren’t afraid?\" he asked.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>-0.000870</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>Joe grinned happily.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>-0.001106</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>Carrots got slowly down off his high chair, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.000876</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>-0.001553</td>\n",
       "      <td>Perhaps so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>-0.001399</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.001629</td>\n",
       "      <td>\"_Frances_?\" he said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>-0.001464</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>SAN FRANCISCO                              104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676014 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               100000     50000    150000     total  \\\n",
       "document_id                                           \n",
       "2177         0.006815  0.007215  0.002341  0.016371   \n",
       "9820         0.009176  0.005143  0.001549  0.015869   \n",
       "1859         0.005356  0.001303  0.009198  0.015856   \n",
       "936          0.007102  0.006219  0.001697  0.015018   \n",
       "9148         0.003666  0.006296  0.004129  0.014091   \n",
       "...               ...       ...       ...       ...   \n",
       "9967        -0.000870 -0.000212 -0.000074 -0.001155   \n",
       "4192        -0.001106 -0.000124 -0.000047 -0.001277   \n",
       "8994        -0.000391 -0.000876 -0.000286 -0.001553   \n",
       "1625        -0.001399 -0.000340  0.000111 -0.001629   \n",
       "3026        -0.001464 -0.000251 -0.000026 -0.001741   \n",
       "\n",
       "                                                          text  \n",
       "document_id                                                     \n",
       "2177                                         \"Back to prison.\"  \n",
       "9820                                  \"Ugh!\" shuddered Aileen.  \n",
       "1859                                                 \"Listen.\"  \n",
       "936                                          \"I can't, Punch.\"  \n",
       "9148                            \"You aren’t afraid?\" he asked.  \n",
       "...                                                        ...  \n",
       "9967                                      Joe grinned happily.  \n",
       "4192         Carrots got slowly down off his high chair, an...  \n",
       "8994                                               Perhaps so.  \n",
       "1625                                     \"_Frances_?\" he said.  \n",
       "3026            SAN FRANCISCO                              104  \n",
       "\n",
       "[676014 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curriculize(df):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.convolve(n[1,:],filter_weights, mode=\"full\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -4.35944797e-04,\n",
       "       -1.58928861e-04, -4.67267044e-05, -1.96619876e-05, -1.65867393e-06,\n",
       "        1.18949971e-07])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.convolve(n[0,:],filter_weights, mode=\"full\")\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]\n",
      " [5 5]\n",
      " [6 6]\n",
      " [7 7]\n",
      " [8 8]\n",
      " [9 9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 1.,  1.],\n",
       "       [ 3.,  3.],\n",
       "       [ 6.,  6.],\n",
       "       [ 9.,  9.],\n",
       "       [12., 12.],\n",
       "       [15., 15.],\n",
       "       [18., 18.],\n",
       "       [21., 21.],\n",
       "       [24., 24.],\n",
       "       [17., 17.],\n",
       "       [ 9.,  9.]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = np.arange(10)\n",
    "a = np.vstack((a,a)).T\n",
    "print(a)\n",
    "filt = np.ones(3)\n",
    "\n",
    "np.apply_along_axis(lambda m: np.convolve(m, filt, mode='full'), axis=0, arr=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000</th>\n",
       "      <th>50000</th>\n",
       "      <th>150000</th>\n",
       "      <th>total</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>\"No.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.009005</td>\n",
       "      <td>\"Had to!  I’d have seen them shot first!\" Tom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.008285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008549</td>\n",
       "      <td>\"No.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009408</td>\n",
       "      <td>\"What is it?\" cried Pen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>\"Think so?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>0.001661</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>CHAPTER TWENTY NINE.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-0.000657</td>\n",
       "      <td>The boys looked up and laughed at the irate li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6904</th>\n",
       "      <td>0.000374</td>\n",
       "      <td>-0.001018</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>The next minute two pairs of childish arms wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>-0.000534</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.001685</td>\n",
       "      <td>Perhaps so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001105</td>\n",
       "      <td>______________________________________________...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676014 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               100000     50000    150000     total  \\\n",
       "document_id                                           \n",
       "744          0.000000  0.008670  0.000000  0.008670   \n",
       "9724         0.000350  0.008310  0.000344  0.009005   \n",
       "2829         0.000264  0.008285  0.000000  0.008549   \n",
       "973          0.001230  0.008178  0.000000  0.009408   \n",
       "426         -0.000200  0.008147  0.000031  0.007978   \n",
       "...               ...       ...       ...       ...   \n",
       "2046         0.001661 -0.000650  0.000257  0.001268   \n",
       "5792         0.000000 -0.000829  0.000172 -0.000657   \n",
       "6904         0.000374 -0.001018  0.000035 -0.000610   \n",
       "8994        -0.000534 -0.001066 -0.000085 -0.001685   \n",
       "4            0.000000 -0.001105  0.000000 -0.001105   \n",
       "\n",
       "                                                          text  \n",
       "document_id                                                     \n",
       "744                                                      \"No.\"  \n",
       "9724         \"Had to!  I’d have seen them shot first!\" Tom ...  \n",
       "2829                                                     \"No.\"  \n",
       "973                                   \"What is it?\" cried Pen.  \n",
       "426                                                \"Think so?\"  \n",
       "...                                                        ...  \n",
       "2046                                      CHAPTER TWENTY NINE.  \n",
       "5792         The boys looked up and laughed at the irate li...  \n",
       "6904         The next minute two pairs of childish arms wer...  \n",
       "8994                                               Perhaps so.  \n",
       "4            ______________________________________________...  \n",
       "\n",
       "[676014 rows x 5 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"50000\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow = get_mean_influence_at_checkpoint(\"/data/loriss21dm/babylm/results/100000_65000_66000\")\n",
    "# fast = get_mean_influence_at_checkpoint_einsum(\"/data/loriss21dm/babylm/results/100000_65000_66000\")\n",
    "# cos = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "# cos(fast,slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2249411127.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[42], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pd.DataFrame(\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     result = get_mean_influence_at_checkpoint_at(\"/data/loriss21dm/babylm/results/100000_65000_66000\").shape\n",
    "#     print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80966294479808"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "77590 / 95830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676014"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([676014])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_at_checkpoint.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456994928196"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"train\"],)*len(dataset[\"train\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((get_all_chunks(\"/data/loriss21dm/babylm/results/100000_65000_66000\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/loriss21dm/babylm/results/100000_0_1000 /data/loriss21dm/babylm/results/100000_0_1000\n",
      "/data/loriss21dm/babylm/results/100000_0_1000 /data/loriss21dm/babylm/results/100000_1000_2000\n",
      "/data/loriss21dm/babylm/results/100000_0_1000 /data/loriss21dm/babylm/results/100000_2000_3000\n",
      "/data/loriss21dm/babylm/results/100000_1000_2000 /data/loriss21dm/babylm/results/100000_0_1000\n",
      "/data/loriss21dm/babylm/results/100000_1000_2000 /data/loriss21dm/babylm/results/100000_1000_2000\n",
      "/data/loriss21dm/babylm/results/100000_1000_2000 /data/loriss21dm/babylm/results/100000_2000_3000\n",
      "/data/loriss21dm/babylm/results/100000_2000_3000 /data/loriss21dm/babylm/results/100000_0_1000\n",
      "/data/loriss21dm/babylm/results/100000_2000_3000 /data/loriss21dm/babylm/results/100000_1000_2000\n",
      "/data/loriss21dm/babylm/results/100000_2000_3000 /data/loriss21dm/babylm/results/100000_2000_3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-108.3750,  264.9062,  436.5000,  ...,   22.7500,   28.6832,\n",
       "          32.2500])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_at_checkpoint = torch.zeros((len(dataset[\"train\"],)))\n",
    "for chunk_path_a in get_all_chunks(\"/data/loriss21dm/babylm/results/100000_65000_66000\"):\n",
    "    _, start_id_a, stop_id_a = chunk_path_a.split( \"_\")\n",
    "    start_id_a = int(start_id_a)\n",
    "    stop_id_a = int(stop_id_a)\n",
    "    chunk_a = torch.load(chunk_path_a, weights_only=True,map_location=\"cpu\").flatten(1)\n",
    "    for chunk_path_b in get_all_chunks(\"/data/loriss21dm/babylm/results/100000_65000_66000\"):\n",
    "        _, start_id_b, stop_id_b = chunk_path_b.split( \"_\")\n",
    "    \n",
    "        start_id_b = int(start_id_b)\n",
    "        stop_id_b = int(stop_id_b)\n",
    "\n",
    "        print(chunk_path_a, chunk_path_b)\n",
    "        \n",
    "        chunk_b = torch.load(chunk_path_b, weights_only=True,map_location=\"cpu\").flatten(1)\n",
    "    # print(start_id_a, stop_id_a, start_id_b, stop_id_b)\n",
    "        # print((torch.einsum('ik, kj -> i', chunk_a, chunk_b.T) / gradients_at_checkpoint.shape[0]).shape)\n",
    "        # print(gradients_at_checkpoint[start_id_a:stop_id_a].shape)\n",
    "        # print(torch.einsum('ik, kj -> i', chunk_a, chunk_b.T).shape)\n",
    "        gradients_at_checkpoint[start_id_a:stop_id_a] += torch.einsum('ik, kj -> i', chunk_a, chunk_b.T) \n",
    "gradients_at_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose((gradients_at_checkpoint / 3000).float(), slow.flatten().float(), rtol=0.1)\n",
    "cos = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "cos((gradients_at_checkpoint / 3000).float(),slow.flatten().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4850e-01,  8.4601e-03,  9.7833e-02,  4.5167e-02,  0.0000e+00,\n",
       "         1.2292e-02,  2.4633e-01,  5.3978e-03,  0.0000e+00,  9.6896e-02,\n",
       "         3.3250e-02,  9.8625e-02,  7.7773e-03,  3.7458e-02,  1.4412e-01,\n",
       "         7.8302e-02,  3.8052e-02,  3.8573e-02,  7.4396e-02,  1.7613e-01,\n",
       "         2.1374e-01,  1.0042e-02,  3.5327e-03,  2.4042e-02,  2.4813e-02,\n",
       "         0.0000e+00,  5.5245e-02,  1.3771e-02,  1.1760e-02, -4.0417e-03,\n",
       "         3.2250e-02,  3.5969e-01,  3.0286e-02,  1.8848e-01,  1.6517e-01,\n",
       "         0.0000e+00,  3.1042e-02,  0.0000e+00,  1.6567e-01,  9.4896e-02,\n",
       "         2.4958e-02,  1.8042e-02,  2.3238e-02,  1.0372e-02,  1.7880e-02,\n",
       "         2.7904e-02,  1.5000e-01,  0.0000e+00,  1.1625e-02,  3.9130e-02,\n",
       "         1.2589e-02,  2.7198e-02,  2.5135e-02,  1.6161e-02,  2.7250e-02,\n",
       "         2.6323e-02,  2.1198e-02,  2.6313e-01,  1.1548e-01,  2.1115e-02,\n",
       "         3.6875e-03,  3.2563e-02,  1.9875e-02,  1.2917e-02,  3.0167e-02,\n",
       "         2.7552e-03,  4.4417e-02,  2.6875e-02,  1.7552e-02,  8.3581e-03,\n",
       "         1.4161e-02,  7.0417e-03,  1.5633e-01,  0.0000e+00,  7.4909e-03,\n",
       "         1.1583e-02,  2.4151e-02,  9.4180e-03,  3.7630e-03,  3.6135e-02,\n",
       "        -4.7500e-03,  1.2435e-01,  3.9875e-02,  2.1531e-02,  8.8198e-02,\n",
       "         3.6667e-03,  2.7315e-02,  3.9563e-02,  0.0000e+00,  3.5583e-02,\n",
       "         1.2546e-01,  0.0000e+00,  2.6917e-02,  5.8208e-02,  7.2224e-02,\n",
       "         0.0000e+00,  2.4115e-02,  3.6900e-01,  5.3250e-02,  3.1125e-02,\n",
       "         2.6974e-02,  0.0000e+00,  3.8369e-01,  8.4349e-03,  3.0906e-02,\n",
       "         2.0865e-02,  4.5865e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         2.3229e-02,  7.9917e-02,  2.1802e-02,  1.5625e-02,  8.6135e-02,\n",
       "         5.1917e-02,  3.1438e-02,  0.0000e+00,  6.9567e-01,  7.4896e-02,\n",
       "         0.0000e+00,  2.9635e-02,  6.3479e-02,  6.6385e-02,  6.1417e-02,\n",
       "         8.1292e-02,  1.4820e-01,  6.4271e-03,  3.5250e-02,  1.8960e-02,\n",
       "         3.4854e-02,  8.6250e-02,  1.9001e-02,  2.0958e-02,  4.5458e-02,\n",
       "         4.4505e-03, -7.1719e-03,  9.5573e-03,  3.1490e-02,  3.3667e-02,\n",
       "         2.0075e-01,  1.8721e-01,  4.7167e-02,  1.4490e-02,  4.5573e-03,\n",
       "         3.8594e-02,  1.2068e-02,  7.2510e-03,  3.3035e-01,  6.8721e-02,\n",
       "         2.4010e-03,  1.9850e-02,  4.2042e-02,  8.9583e-04,  1.3193e-02,\n",
       "         9.8724e-03,  7.5612e-03,  1.8188e-02,  0.0000e+00,  0.0000e+00,\n",
       "         3.4219e-02,  6.1250e-03,  3.4083e-02,  8.1375e-02,  1.2667e-02,\n",
       "         3.8604e-02,  1.6138e-01,  2.1333e-02,  1.7547e-02,  4.8406e-02,\n",
       "         2.1854e-02,  2.1099e-02,  5.5344e-02,  7.3542e-03,  1.8258e-01,\n",
       "         3.2187e-02,  1.5625e-01,  1.0627e+00,  2.9745e-02,  5.9583e-02,\n",
       "         2.2448e-02,  6.5875e-02,  1.6594e-02,  3.4031e-02,  6.0547e-03,\n",
       "         1.4042e-01,  6.6598e-03,  0.0000e+00,  2.1604e-02,  0.0000e+00,\n",
       "         8.6250e-03,  2.1637e-01,  1.4552e-02,  6.4745e-02,  1.0642e-01,\n",
       "         5.9781e-02,  1.6812e-02,  7.7135e-03,  8.3333e-03,  4.5146e-02,\n",
       "         4.7922e-02,  1.1433e-01,  8.3667e-02,  0.0000e+00,  6.8750e-03,\n",
       "         4.9854e-02,  1.4158e-01,  1.8385e-02,  5.8688e-02,  2.2251e-02,\n",
       "         3.4565e-02,  1.8555e-01,  1.6683e-01,  1.2579e-01,  2.4833e-02,\n",
       "         3.3208e-02,  2.2292e-01,  1.4945e-01,  0.0000e+00,  3.3813e-02,\n",
       "         0.0000e+00,  1.4177e-02,  2.9517e-01,  1.2408e-01,  1.6417e-01,\n",
       "         1.3017e-01,  8.6250e-02,  3.1365e-02,  8.5625e-02,  6.0208e-03,\n",
       "         1.4456e-01,  3.7266e-03,  4.3917e-02,  1.3224e-02,  1.1547e-02,\n",
       "         4.5917e-02,  2.4266e-02,  2.9717e-01,  6.5143e-03,  3.3458e-02,\n",
       "         2.2146e-02,  3.2146e-01,  6.1623e-03,  6.3646e-03,  1.0558e-01,\n",
       "         3.9896e-03,  1.7499e-02,  8.9583e-03,  1.4123e-01,  1.4305e-02,\n",
       "         4.5938e-02,  8.5333e-02,  8.6510e-03,  1.8929e-01,  0.0000e+00,\n",
       "         1.4057e-02,  2.2781e-02,  1.0969e-02,  1.1920e+00,  1.4635e-02,\n",
       "         2.0417e-02,  5.6823e-02,  4.8208e-02,  1.3588e-01,  2.7333e-02,\n",
       "         2.0104e-02,  1.5150e-01,  1.8385e-02,  6.6042e-02,  1.5012e-01,\n",
       "         6.6125e-02,  1.9833e-02,  1.0111e-02,  1.2921e-01,  8.1531e-02,\n",
       "         6.4583e-03,  1.5505e-02,  6.3292e-02,  2.9042e-02,  1.6346e-02,\n",
       "         4.1052e-02,  2.3315e-02,  2.9958e-02,  4.8500e-02,  0.0000e+00,\n",
       "         1.6234e-02,  1.4025e-01,  1.0458e-02,  0.0000e+00,  8.5885e-03,\n",
       "         1.0401e-02,  1.3497e-02,  1.3449e-01,  4.2042e-02,  4.5021e-02,\n",
       "        -7.0313e-04,  1.5062e-02,  1.1292e-02, -1.4271e-02,  8.3333e-04,\n",
       "         2.0531e-02,  9.9779e-03,  9.6458e-03,  6.5208e-02,  2.4167e-02,\n",
       "         5.4104e-02,  7.3031e-02,  1.5092e-01,  9.0187e-02,  7.5703e-03,\n",
       "         2.0260e-03,  1.2215e-02,  1.1913e-02,  2.6833e-02,  1.7972e-01,\n",
       "         2.0006e-01,  3.7990e-02,  5.5724e-02,  6.1983e-01,  1.1922e-02,\n",
       "         2.4317e-01,  1.7792e-02,  3.4552e-02,  9.0750e-02,  2.8734e-02,\n",
       "         2.7031e-03,  1.3240e-02,  3.1083e-02,  2.5281e-02,  4.0208e-03,\n",
       "         1.2804e-01,  5.3397e-02,  3.0521e-03,  1.5401e-02,  3.1625e-02,\n",
       "         3.3646e-02,  1.5188e-02,  2.2799e-02,  4.5729e-03,  1.9198e-02,\n",
       "         2.8396e-02,  8.2864e-02,  5.5733e-01,  4.6073e-02,  3.5169e-02,\n",
       "         1.5174e-02,  1.1417e-02,  1.4130e-01,  3.2849e-02,  4.9042e-02,\n",
       "         2.5165e-01,  3.0940e-02,  5.6333e-02,  4.8833e-02, -2.5833e-03,\n",
       "         2.7602e-02, -3.5833e-03,  1.4388e-01,  2.8945e-02,  6.0575e-01,\n",
       "         1.2596e-02,  5.4781e-02,  5.6250e-04,  5.1914e-02,  3.4167e-02,\n",
       "         5.3396e-02,  3.0292e-02,  2.3250e-01,  7.9163e-03,  7.8176e-02,\n",
       "         2.8191e-01,  1.7250e-02,  4.4792e-03,  1.0198e-02,  2.9396e-02,\n",
       "         4.8281e-02,  0.0000e+00,  6.7552e-03,  4.6833e-02,  7.6667e-02,\n",
       "         9.0677e-03,  3.7917e-01,  1.3123e-01,  4.9063e-03,  2.9917e-02,\n",
       "         7.5958e-02,  1.1430e+00,  7.2729e-02,  1.3344e-02,  3.1104e-02,\n",
       "         1.4792e-01,  1.0431e-01,  3.8888e-01,  3.5439e-01,  5.2448e-03,\n",
       "         2.1645e-02,  1.5281e-02,  7.3125e-03,  2.1258e-02,  5.4635e-03,\n",
       "         1.0188e-02,  1.6729e-02,  2.2854e-02,  6.6042e-02,  9.3188e-02,\n",
       "         6.4708e-02,  1.2583e-02,  3.9370e-02,  2.1865e-02,  7.7331e-03,\n",
       "         1.5500e-02,  1.1800e-01,  6.5625e-02,  3.5583e-02, -4.6625e-02,\n",
       "         3.0672e-02,  4.4760e-02,  1.3454e-01,  1.2083e-01,  2.4052e-02,\n",
       "         2.0042e-02,  7.0604e-02,  3.1937e-02,  1.3277e-02,  5.0943e-02,\n",
       "         1.0562e-01,  5.2073e-02,  4.1500e-02,  2.1635e-02,  9.8437e-03,\n",
       "         6.4250e-02,  1.2577e-02,  0.0000e+00,  4.7500e-03,  1.1083e-02,\n",
       "         3.6417e-02,  1.0283e-01,  1.4727e-02,  4.0469e-02,  1.8923e-03,\n",
       "         9.8833e-02,  9.5524e-03,  2.5496e-01,  4.7625e-02,  1.4141e-02,\n",
       "         2.5600e-01,  3.1117e-01,  1.2833e-02,  1.4313e-02,  4.1500e-02,\n",
       "         1.6596e-02,  1.7901e-02,  1.3685e-02,  1.5346e-02,  9.5417e-03,\n",
       "         8.0592e-03,  1.4451e-02, -1.6033e-01,  3.6958e-02,  1.7292e-02,\n",
       "         3.5833e-03,  9.1635e-02,  1.2967e-01,  0.0000e+00,  2.2667e-02,\n",
       "         2.1525e-01,  4.4458e-02,  2.8129e-01,  1.2621e-02,  2.6076e-02,\n",
       "         2.3766e-02,  0.0000e+00,  9.7737e-02,  5.7729e-02,  3.1995e-02,\n",
       "         2.3937e-02,  9.1042e-02,  5.1536e-03,  3.1875e-02,  1.4263e-01,\n",
       "         3.3167e-02,  2.3125e-02,  3.8250e-02,  7.8083e-02,  0.0000e+00,\n",
       "         1.3954e-01,  9.4792e-03,  2.0833e-02,  2.8625e-01,  9.1438e-02,\n",
       "         2.0073e-02,  5.8755e-02,  1.7667e-02,  0.0000e+00,  1.2187e-02,\n",
       "         1.0029e-01,  2.2653e-01,  2.5781e-02,  4.2312e-02,  5.0563e-02,\n",
       "         2.5510e-02,  1.5073e-02,  1.0521e-01,  1.8661e-02,  9.6100e-03,\n",
       "         1.8896e-02,  6.9896e-02,  1.0762e-02,  2.7667e-02,  7.3039e-02,\n",
       "         3.4654e-02, -3.9583e-03,  2.0125e-02,  2.2085e-01,  0.0000e+00,\n",
       "         1.8484e-02,  0.0000e+00,  0.0000e+00,  2.4547e-02,  5.5417e-03,\n",
       "         1.6542e-02,  4.5417e-03,  2.9002e-01,  1.9317e-01,  0.0000e+00,\n",
       "         2.1531e-02,  6.1583e-02, -2.5859e-03,  6.5375e-02,  2.9687e-03,\n",
       "         2.0229e-02,  1.8929e-01,  1.3000e-01,  0.0000e+00,  1.8750e-04,\n",
       "         1.6788e-02,  8.8125e-02,  4.3922e-02,  8.7031e-03,  6.5625e-02,\n",
       "         9.0573e-02,  9.7552e-03,  2.9281e-02,  0.0000e+00,  1.6521e-02,\n",
       "         1.2562e-01,  2.8990e-02,  5.7031e-03,  2.2448e-02,  2.4329e-02,\n",
       "         5.3333e-03,  1.2510e-02,  0.0000e+00,  1.2464e-01,  4.2292e-03,\n",
       "         2.7982e-02,  1.5337e-01,  3.1385e-02,  1.1389e-01,  6.2240e-03,\n",
       "         2.5885e-02,  1.8268e-02,  4.7917e-02,  6.8292e-02,  6.5545e-01,\n",
       "         3.9875e-02,  2.6308e-01,  1.7167e-02,  1.0347e-01,  2.4214e-02,\n",
       "         6.7667e-02,  7.4917e-02,  7.3229e-02,  0.0000e+00,  1.7842e-01,\n",
       "         1.7112e-01,  1.4509e-01,  1.2417e-02,  2.2667e-02,  4.1914e-02,\n",
       "         1.1529e-02,  2.5378e-02,  3.0547e-02,  1.5609e-02,  6.4479e-02,\n",
       "         4.7917e-02,  6.8464e-03,  4.6000e-02,  1.2536e-02,  5.0458e-02,\n",
       "         1.0141e-02,  4.9250e-02,  1.2538e-01,  0.0000e+00,  4.6953e-02,\n",
       "         4.2550e-01,  4.1050e-01,  4.7646e-02,  3.3542e-02,  1.4898e-01,\n",
       "         1.0858e-01,  1.6751e-01,  2.0979e-01,  0.0000e+00,  2.1010e-02,\n",
       "         2.9481e-01,  5.5667e-02,  7.1460e-03,  5.6417e-02,  0.0000e+00,\n",
       "         1.6027e-01,  2.1146e-02,  1.2526e-02,  6.1842e-01,  5.2146e-02,\n",
       "         5.7805e-02,  3.1517e-03,  1.5775e-01,  1.2161e-02,  2.6500e-02,\n",
       "         4.6500e-02,  2.6792e-02,  8.1510e-02,  0.0000e+00, -8.8437e-03,\n",
       "         8.9375e-02,  9.8125e-03,  2.0750e-02,  7.0229e-02,  8.3982e-02,\n",
       "         1.2798e-02,  3.3100e-01,  4.2233e-02,  7.5250e-02,  1.4029e-01,\n",
       "         3.3969e-02, -5.1250e-03,  2.9271e-02,  2.4232e-02,  2.1594e-02,\n",
       "         1.3000e-01,  3.2021e-02,  1.1987e-01,  0.0000e+00,  5.6167e-02,\n",
       "         0.0000e+00,  9.0323e-02,  3.1081e-02,  8.7500e-02,  1.7302e-02,\n",
       "         3.5750e-02,  2.8438e-02, -1.4896e-02,  1.1958e-02,  8.3000e-02,\n",
       "         2.0417e-02,  0.0000e+00,  2.0719e-01,  1.1054e-01,  3.3042e-02,\n",
       "         7.7000e-02,  6.5542e-02,  9.2526e-03,  0.0000e+00,  1.4469e-01,\n",
       "         1.3934e-01,  2.2647e-02,  1.3153e-01,  9.8750e-03,  4.3042e-02,\n",
       "         0.0000e+00,  5.4698e-02,  1.0833e-03,  6.3871e-01,  8.7250e-02,\n",
       "         1.0052e-02,  2.2604e-03,  5.5000e-02,  4.7125e-02,  1.9281e-02,\n",
       "         1.9354e-02,  0.0000e+00,  1.0292e-02,  1.0208e-02,  3.6292e-02,\n",
       "         1.1563e-02,  1.3469e-02,  6.7182e-02,  1.6641e-02,  1.9240e-02,\n",
       "         1.1025e-01,  2.0953e-02,  2.6240e-02,  6.3896e-02,  1.2136e-02,\n",
       "         2.3204e-02,  0.0000e+00,  8.5156e-02,  7.5016e-02,  0.0000e+00,\n",
       "         0.0000e+00,  1.2762e+00,  0.0000e+00, -3.3333e-03,  2.1854e-02,\n",
       "         1.5875e-01,  3.2469e-02,  3.2969e-02,  1.7667e-02,  2.2312e-02,\n",
       "         3.0833e-02,  2.6729e-02,  3.0042e-02,  8.3333e-03,  8.5958e-02,\n",
       "         7.3604e-02,  2.0354e-02,  8.1458e-03,  2.2500e-01,  4.3094e-02,\n",
       "         1.0996e-01,  1.9055e-02,  0.0000e+00,  7.8833e-02,  3.3219e-02,\n",
       "         1.0729e-01,  3.4906e-02,  3.8880e-02,  8.7167e-02,  6.7167e-02,\n",
       "         2.5625e-02,  2.4604e-01,  1.3729e-02,  3.7344e-02,  3.7129e-01,\n",
       "         7.2438e-02,  1.7638e-01,  2.3865e-02,  2.2792e-02,  6.7042e-02,\n",
       "         2.6458e-02,  3.7188e-02,  5.5000e-02,  1.0546e-01,  1.6042e-02,\n",
       "         1.4157e-01,  1.0052e-02, -4.9167e-03,  4.9286e-02,  2.6333e-02,\n",
       "         3.9042e-02,  2.5500e-01,  7.3865e-02,  2.6474e-02,  1.9081e-02,\n",
       "         3.0167e-02,  2.0354e-02,  8.3094e-02,  1.8010e-02,  7.7604e-03,\n",
       "         4.1141e-02,  8.7542e-02,  1.4250e-02,  2.1521e-02,  1.1333e-01,\n",
       "         7.1254e-02,  0.0000e+00,  9.7552e-03, -1.4875e-02,  1.1290e-01,\n",
       "         2.2760e-02,  2.0383e-01,  1.1237e-01,  8.4167e-02,  5.3099e-03,\n",
       "         8.1510e-04,  2.2583e-02,  3.5479e-02,  1.0591e-02,  1.2052e-01,\n",
       "         3.0792e-02,  1.3750e-01,  0.0000e+00,  6.4406e-02,  1.2428e-01,\n",
       "         1.9500e-01,  1.5058e-01,  1.0615e-02,  8.9583e-03,  1.1000e-02,\n",
       "         2.9562e-02,  2.5692e-01,  1.9054e-01,  1.4985e-01,  1.0445e-02,\n",
       "         3.8969e-02,  1.0599e-02,  7.9896e-02,  2.0562e-02,  3.2302e-02,\n",
       "         3.0734e-02,  3.6906e-02,  0.0000e+00,  2.2688e-02,  1.5844e-02,\n",
       "         2.0500e-02,  2.2708e-02,  2.5583e-02,  4.1266e-02,  8.0000e-03,\n",
       "         7.1344e-02,  3.7642e-02,  1.9802e-02,  6.7417e-02,  7.2792e-02,\n",
       "         1.7958e-02,  2.6896e-02,  2.6302e-02,  2.5451e-02,  1.4281e-01,\n",
       "         1.7896e-02,  0.0000e+00,  3.1667e-02,  4.7458e-02,  3.4154e-01,\n",
       "         8.7604e-02,  2.9469e-02,  1.3030e-01,  2.6911e-02,  6.7667e-02,\n",
       "         3.7750e-02,  6.1896e-02,  8.3394e-02,  6.7521e-02,  1.3099e-02,\n",
       "         1.5198e-02,  1.8214e-02,  3.4238e-02,  2.3573e-02,  3.8438e-03,\n",
       "         8.0448e-02,  4.7417e-02,  1.3608e-01,  6.4271e-02,  1.8659e-02,\n",
       "         5.5125e-02,  9.7650e-03,  5.5500e-02,  5.1667e-02,  1.3854e-02,\n",
       "         2.2050e-01,  0.0000e+00,  8.3685e-03,  2.4771e-02,  1.3422e-02,\n",
       "         4.9042e-02,  7.0260e-03,  6.8750e-02,  3.4805e-02,  2.0450e-01,\n",
       "         0.0000e+00,  1.8708e-02,  2.7980e-01,  4.1042e-03,  1.9896e-02,\n",
       "         2.6250e-02,  2.5953e-02,  2.7771e-02,  4.6604e-02,  4.5708e-02,\n",
       "         3.2615e-02,  2.1619e-01,  8.7396e-02,  1.0094e-02,  2.1250e-03,\n",
       "         1.1910e+00,  4.3651e-02,  4.1708e-02,  4.7775e-02,  8.4500e-02,\n",
       "         3.2283e-01,  3.1646e-01,  1.7063e-02,  2.5656e-02,  3.9057e-02,\n",
       "         1.0833e-02,  0.0000e+00,  0.0000e+00,  3.3312e-02,  1.5508e-02,\n",
       "         9.5500e-02,  2.0950e-01,  1.0458e-02,  3.1073e-02,  2.0070e-02,\n",
       "         1.9633e-01,  0.0000e+00,  4.1042e-02,  2.6156e-02,  6.2615e-02,\n",
       "         1.2109e-02,  6.2073e-02,  3.8516e-03,  1.0983e-01,  1.5729e-02,\n",
       "         5.0729e-03,  4.5646e-02,  2.1536e-02,  1.0712e-01,  9.9854e-02,\n",
       "         2.4358e-01,  3.3974e-02,  1.7627e-01,  3.3306e-01,  2.9521e-02,\n",
       "         1.3802e-02,  3.5937e-02,  3.0697e-02,  1.4398e-01,  1.0669e-02,\n",
       "         1.7292e-02,  1.0500e-02,  5.3991e-02,  2.7175e-01,  1.5283e-01,\n",
       "         1.4277e-01,  3.5031e-02,  2.7391e-02,  2.4176e-02,  1.0771e-02,\n",
       "         3.3106e-02,  7.1501e-02,  6.0250e-02,  1.8250e-01,  4.3979e-02,\n",
       "         7.2406e-02,  1.2333e-02,  1.6042e-01,  7.4917e-02,  0.0000e+00,\n",
       "         3.7323e-01,  3.5833e-03,  1.5908e-01,  7.6547e-02,  1.8209e-02,\n",
       "         3.7733e-01,  3.9479e-02,  4.9396e-02,  0.0000e+00,  3.6862e-02,\n",
       "         2.0813e-02,  4.0010e-01,  1.1354e-01,  2.1625e-01,  0.0000e+00,\n",
       "         7.0396e-02,  6.9542e-02,  7.5552e-02,  3.4125e-02,  1.3979e-01,\n",
       "         2.5496e-01,  4.3688e-02,  2.3183e-01,  4.5250e-02,  8.2479e-02,\n",
       "         4.1833e-02,  4.2625e-02,  1.5750e-01,  1.2646e-01,  0.0000e+00,\n",
       "         3.7245e-02,  4.6500e-02,  7.1750e-02,  9.0531e-02,  1.0920e-01,\n",
       "         0.0000e+00,  9.5417e-02,  1.8846e-01,  1.4896e-03,  2.7669e-02,\n",
       "         1.1228e-01,  1.1258e-01,  0.0000e+00,  1.6208e-02,  7.0583e-01,\n",
       "         1.7247e-02,  3.1458e-02,  7.6652e-02,  1.1042e-02,  2.9573e-02,\n",
       "         1.8508e-01,  5.6365e-02,  1.5844e-02,  2.5008e-02,  1.4604e-02,\n",
       "         2.7354e-02,  1.0698e-02,  7.5833e-03,  9.5611e-03,  1.0750e-02])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gradients_at_checkpoint / 3000).float()[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4844e-01,  8.4229e-03,  9.8145e-02,  4.5410e-02,  0.0000e+00,\n",
       "         1.2268e-02,  2.4609e-01,  5.4932e-03,  0.0000e+00,  9.7168e-02,\n",
       "         3.3203e-02,  9.8633e-02,  7.7820e-03,  3.7598e-02,  1.4453e-01,\n",
       "         7.8613e-02,  3.8086e-02,  3.8574e-02,  7.4219e-02,  1.7578e-01,\n",
       "         2.1387e-01,  1.0010e-02,  3.5400e-03,  2.4048e-02,  2.5024e-02,\n",
       "         0.0000e+00,  5.4932e-02,  1.3794e-02,  1.1780e-02, -4.0588e-03,\n",
       "         3.2227e-02,  3.5938e-01,  3.0396e-02,  1.8848e-01,  1.6504e-01,\n",
       "         0.0000e+00,  3.1128e-02,  0.0000e+00,  1.6504e-01,  9.5215e-02,\n",
       "         2.4902e-02,  1.7944e-02,  2.3193e-02,  1.0376e-02,  1.7822e-02,\n",
       "         2.7832e-02,  1.4941e-01,  0.0000e+00,  1.1597e-02,  3.9062e-02,\n",
       "         1.2512e-02,  2.7100e-02,  2.5146e-02,  1.6235e-02,  2.7344e-02,\n",
       "         2.6367e-02,  2.1240e-02,  2.6367e-01,  1.1572e-01,  2.1118e-02,\n",
       "         3.6774e-03,  3.2715e-02,  1.9897e-02,  1.2878e-02,  3.0273e-02,\n",
       "         2.7618e-03,  4.4434e-02,  2.6855e-02,  1.7456e-02,  8.3618e-03,\n",
       "         1.4160e-02,  7.0496e-03,  1.5625e-01,  0.0000e+00,  7.5073e-03,\n",
       "         1.1597e-02,  2.4170e-02,  9.4604e-03,  3.7231e-03,  3.6133e-02,\n",
       "        -4.7913e-03,  1.2451e-01,  3.9795e-02,  2.1606e-02,  8.8379e-02,\n",
       "         3.7689e-03,  2.7344e-02,  3.9551e-02,  0.0000e+00,  3.5645e-02,\n",
       "         1.2598e-01,  0.0000e+00,  2.6855e-02,  5.8105e-02,  7.2266e-02,\n",
       "         0.0000e+00,  2.4048e-02,  3.6914e-01,  5.3223e-02,  3.1128e-02,\n",
       "         2.7100e-02,  0.0000e+00,  3.8281e-01,  8.4839e-03,  3.1006e-02,\n",
       "         2.0874e-02,  4.5654e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         2.3315e-02,  8.0078e-02,  2.1729e-02,  1.5625e-02,  8.5938e-02,\n",
       "         5.2002e-02,  3.1494e-02,  0.0000e+00,  6.9531e-01,  7.4707e-02,\n",
       "         0.0000e+00,  2.9541e-02,  6.3477e-02,  6.6406e-02,  6.1523e-02,\n",
       "         8.1543e-02,  1.4844e-01,  6.3782e-03,  3.5400e-02,  1.8921e-02,\n",
       "         3.4668e-02,  8.6426e-02,  1.8921e-02,  2.0996e-02,  4.5654e-02,\n",
       "         4.4556e-03, -7.1411e-03,  9.5215e-03,  3.1494e-02,  3.3691e-02,\n",
       "         2.0020e-01,  1.8750e-01,  4.7119e-02,  1.4526e-02,  4.5471e-03,\n",
       "         3.8574e-02,  1.2085e-02,  7.2327e-03,  3.3008e-01,  6.8848e-02,\n",
       "         2.4109e-03,  1.9775e-02,  4.1992e-02,  8.7357e-04,  1.3184e-02,\n",
       "         9.8267e-03,  7.5684e-03,  1.8188e-02,  0.0000e+00,  0.0000e+00,\n",
       "         3.4424e-02,  6.1035e-03,  3.4180e-02,  8.1543e-02,  1.2695e-02,\n",
       "         3.8574e-02,  1.6113e-01,  2.1362e-02,  1.7578e-02,  4.8340e-02,\n",
       "         2.1851e-02,  2.1118e-02,  5.5420e-02,  7.3242e-03,  1.8359e-01,\n",
       "         3.2227e-02,  1.5625e-01,  1.0625e+00,  2.9785e-02,  5.9814e-02,\n",
       "         2.2583e-02,  6.5918e-02,  1.6479e-02,  3.3936e-02,  6.0425e-03,\n",
       "         1.4062e-01,  6.6833e-03,  0.0000e+00,  2.1729e-02,  0.0000e+00,\n",
       "         8.6060e-03,  2.1680e-01,  1.4587e-02,  6.4941e-02,  1.0693e-01,\n",
       "         5.9814e-02,  1.6968e-02,  7.7209e-03,  8.3008e-03,  4.4922e-02,\n",
       "         4.7607e-02,  1.1426e-01,  8.3496e-02,  0.0000e+00,  6.9580e-03,\n",
       "         4.9805e-02,  1.4160e-01,  1.8433e-02,  5.8594e-02,  2.2217e-02,\n",
       "         3.4668e-02,  1.8652e-01,  1.6602e-01,  1.2500e-01,  2.4902e-02,\n",
       "         3.3203e-02,  2.2266e-01,  1.4941e-01,  0.0000e+00,  3.3936e-02,\n",
       "         0.0000e+00,  1.4160e-02,  2.9492e-01,  1.2402e-01,  1.6504e-01,\n",
       "         1.2988e-01,  8.6426e-02,  3.1494e-02,  8.5449e-02,  6.0120e-03,\n",
       "         1.4453e-01,  3.7231e-03,  4.3945e-02,  1.3245e-02,  1.1597e-02,\n",
       "         4.6143e-02,  2.4292e-02,  2.9688e-01,  6.5308e-03,  3.3447e-02,\n",
       "         2.2095e-02,  3.2031e-01,  6.1646e-03,  6.3477e-03,  1.0547e-01,\n",
       "         3.9062e-03,  1.7456e-02,  8.9722e-03,  1.4160e-01,  1.4343e-02,\n",
       "         4.5898e-02,  8.4961e-02,  8.6670e-03,  1.8945e-01,  0.0000e+00,\n",
       "         1.4038e-02,  2.2705e-02,  1.1047e-02,  1.1875e+00,  1.4648e-02,\n",
       "         2.0508e-02,  5.6641e-02,  4.8096e-02,  1.3574e-01,  2.7466e-02,\n",
       "         2.0264e-02,  1.5137e-01,  1.8433e-02,  6.5918e-02,  1.5039e-01,\n",
       "         6.5918e-02,  1.9897e-02,  1.0071e-02,  1.2988e-01,  8.1543e-02,\n",
       "         6.4697e-03,  1.5564e-02,  6.3477e-02,  2.8931e-02,  1.6357e-02,\n",
       "         4.1260e-02,  2.3193e-02,  2.9785e-02,  4.8584e-02,  0.0000e+00,\n",
       "         1.6357e-02,  1.4062e-01,  1.0437e-02,  0.0000e+00,  8.5449e-03,\n",
       "         1.0315e-02,  1.3489e-02,  1.3379e-01,  4.1992e-02,  4.5166e-02,\n",
       "        -6.9809e-04,  1.4954e-02,  1.1230e-02, -1.4282e-02,  8.7357e-04,\n",
       "         2.0508e-02,  9.9487e-03,  9.6436e-03,  6.5430e-02,  2.4170e-02,\n",
       "         5.4199e-02,  7.3242e-02,  1.5039e-01,  9.0332e-02,  7.5378e-03,\n",
       "         2.1515e-03,  1.2268e-02,  1.1963e-02,  2.6733e-02,  1.7969e-01,\n",
       "         2.0020e-01,  3.8086e-02,  5.5908e-02,  6.2109e-01,  1.1902e-02,\n",
       "         2.4316e-01,  1.7700e-02,  3.4668e-02,  9.0820e-02,  2.8687e-02,\n",
       "         2.7161e-03,  1.3245e-02,  3.1128e-02,  2.5146e-02,  4.0894e-03,\n",
       "         1.2793e-01,  5.3223e-02,  3.0365e-03,  1.5381e-02,  3.1738e-02,\n",
       "         3.3691e-02,  1.5198e-02,  2.2827e-02,  4.5166e-03,  1.9165e-02,\n",
       "         2.8320e-02,  8.3008e-02,  5.5859e-01,  4.5898e-02,  3.5156e-02,\n",
       "         1.5137e-02,  1.1414e-02,  1.4160e-01,  3.2959e-02,  4.9072e-02,\n",
       "         2.5195e-01,  3.0884e-02,  5.6396e-02,  4.9072e-02, -2.5330e-03,\n",
       "         2.7588e-02, -3.4027e-03,  1.4355e-01,  2.8931e-02,  6.0547e-01,\n",
       "         1.2634e-02,  5.4688e-02,  5.6076e-04,  5.2002e-02,  3.4180e-02,\n",
       "         5.3467e-02,  3.0273e-02,  2.3145e-01,  7.9346e-03,  7.8125e-02,\n",
       "         2.8320e-01,  1.7212e-02,  4.4556e-03,  1.0193e-02,  2.9419e-02,\n",
       "         4.8584e-02,  0.0000e+00,  6.7749e-03,  4.6631e-02,  7.6660e-02,\n",
       "         9.0332e-03,  3.8086e-01,  1.3184e-01,  4.8828e-03,  3.0151e-02,\n",
       "         7.6172e-02,  1.1406e+00,  7.2754e-02,  1.3367e-02,  3.1128e-02,\n",
       "         1.4746e-01,  1.0449e-01,  3.8867e-01,  3.5547e-01,  5.2490e-03,\n",
       "         2.1606e-02,  1.5259e-02,  7.2937e-03,  2.1240e-02,  5.4626e-03,\n",
       "         1.0193e-02,  1.6724e-02,  2.2949e-02,  6.6406e-02,  9.3262e-02,\n",
       "         6.4453e-02,  1.2634e-02,  3.9307e-02,  2.1851e-02,  7.7209e-03,\n",
       "         1.5442e-02,  1.1768e-01,  6.5430e-02,  3.5645e-02, -4.6631e-02,\n",
       "         3.0762e-02,  4.4678e-02,  1.3477e-01,  1.2061e-01,  2.4048e-02,\n",
       "         2.0142e-02,  7.0801e-02,  3.1982e-02,  1.3245e-02,  5.1025e-02,\n",
       "         1.0547e-01,  5.2246e-02,  4.1260e-02,  2.1729e-02,  9.8267e-03,\n",
       "         6.3965e-02,  1.2634e-02,  0.0000e+00,  4.7607e-03,  1.1108e-02,\n",
       "         3.6377e-02,  1.0254e-01,  1.4771e-02,  4.0283e-02,  1.8997e-03,\n",
       "         9.9121e-02,  9.5215e-03,  2.5586e-01,  4.7363e-02,  1.4099e-02,\n",
       "         2.5586e-01,  3.1055e-01,  1.2878e-02,  1.4282e-02,  4.1504e-02,\n",
       "         1.6602e-02,  1.7944e-02,  1.3672e-02,  1.5381e-02,  9.5215e-03,\n",
       "         8.0566e-03,  1.4465e-02, -1.6113e-01,  3.6865e-02,  1.7334e-02,\n",
       "         3.5858e-03,  9.1797e-02,  1.2891e-01,  0.0000e+00,  2.2705e-02,\n",
       "         2.1484e-01,  4.4434e-02,  2.8125e-01,  1.2634e-02,  2.6123e-02,\n",
       "         2.3804e-02,  0.0000e+00,  9.7656e-02,  5.7861e-02,  3.1982e-02,\n",
       "         2.4048e-02,  9.1309e-02,  5.1575e-03,  3.1738e-02,  1.4258e-01,\n",
       "         3.3203e-02,  2.3193e-02,  3.8330e-02,  7.8125e-02,  0.0000e+00,\n",
       "         1.3965e-01,  9.4604e-03,  2.0752e-02,  2.8711e-01,  9.1309e-02,\n",
       "         2.0142e-02,  5.8594e-02,  1.7456e-02,  0.0000e+00,  1.2207e-02,\n",
       "         1.0059e-01,  2.2656e-01,  2.5757e-02,  4.2236e-02,  5.0537e-02,\n",
       "         2.5513e-02,  1.5076e-02,  1.0547e-01,  1.8677e-02,  9.5825e-03,\n",
       "         1.8921e-02,  6.9824e-02,  1.0742e-02,  2.7588e-02,  7.2754e-02,\n",
       "         3.4668e-02, -3.9673e-03,  2.0142e-02,  2.2070e-01,  0.0000e+00,\n",
       "         1.8433e-02,  0.0000e+00,  0.0000e+00,  2.4536e-02,  5.4932e-03,\n",
       "         1.6479e-02,  4.6082e-03,  2.8906e-01,  1.9336e-01,  0.0000e+00,\n",
       "         2.1484e-02,  6.1523e-02, -2.5787e-03,  6.5430e-02,  3.0823e-03,\n",
       "         2.0264e-02,  1.8848e-01,  1.2988e-01,  0.0000e+00,  2.1172e-04,\n",
       "         1.6846e-02,  8.8379e-02,  4.3701e-02,  8.7280e-03,  6.5430e-02,\n",
       "         9.0332e-02,  9.8267e-03,  2.9419e-02,  0.0000e+00,  1.6602e-02,\n",
       "         1.2500e-01,  2.9053e-02,  5.6763e-03,  2.2461e-02,  2.4292e-02,\n",
       "         5.3406e-03,  1.2573e-02,  0.0000e+00,  1.2451e-01,  4.2114e-03,\n",
       "         2.8076e-02,  1.5332e-01,  3.1494e-02,  1.1426e-01,  6.2256e-03,\n",
       "         2.6001e-02,  1.8311e-02,  4.7607e-02,  6.8359e-02,  6.5625e-01,\n",
       "         3.9795e-02,  2.6367e-01,  1.7212e-02,  1.0303e-01,  2.4170e-02,\n",
       "         6.7871e-02,  7.4707e-02,  7.3242e-02,  0.0000e+00,  1.7871e-01,\n",
       "         1.7090e-01,  1.4551e-01,  1.2451e-02,  2.2583e-02,  4.1992e-02,\n",
       "         1.1536e-02,  2.5391e-02,  3.0640e-02,  1.5625e-02,  6.4453e-02,\n",
       "         4.7852e-02,  6.8359e-03,  4.6143e-02,  1.2573e-02,  5.0537e-02,\n",
       "         1.0132e-02,  4.8828e-02,  1.2500e-01,  0.0000e+00,  4.7119e-02,\n",
       "         4.2383e-01,  4.0820e-01,  4.7607e-02,  3.3691e-02,  1.4844e-01,\n",
       "         1.0889e-01,  1.6797e-01,  2.0996e-01,  0.0000e+00,  2.0996e-02,\n",
       "         2.9492e-01,  5.5664e-02,  7.1411e-03,  5.6641e-02,  0.0000e+00,\n",
       "         1.6016e-01,  2.1118e-02,  1.2512e-02,  6.1719e-01,  5.2002e-02,\n",
       "         5.7861e-02,  3.1738e-03,  1.5723e-01,  1.2146e-02,  2.6611e-02,\n",
       "         4.6387e-02,  2.6855e-02,  8.1543e-02,  0.0000e+00, -8.7891e-03,\n",
       "         8.9355e-02,  9.8267e-03,  2.0752e-02,  7.0312e-02,  8.3984e-02,\n",
       "         1.2817e-02,  3.3203e-01,  4.2236e-02,  7.5195e-02,  1.4062e-01,\n",
       "         3.3936e-02, -5.1270e-03,  2.9297e-02,  2.4170e-02,  2.1606e-02,\n",
       "         1.2988e-01,  3.1982e-02,  1.1963e-01,  0.0000e+00,  5.6396e-02,\n",
       "         0.0000e+00,  9.0332e-02,  3.1006e-02,  8.7891e-02,  1.7334e-02,\n",
       "         3.5645e-02,  2.8320e-02, -1.4893e-02,  1.1963e-02,  8.3008e-02,\n",
       "         2.0508e-02,  0.0000e+00,  2.0801e-01,  1.1035e-01,  3.2959e-02,\n",
       "         7.7148e-02,  6.5430e-02,  9.2773e-03,  0.0000e+00,  1.4453e-01,\n",
       "         1.3965e-01,  2.2583e-02,  1.3086e-01,  9.8877e-03,  4.2969e-02,\n",
       "         0.0000e+00,  5.4688e-02,  1.0452e-03,  6.4062e-01,  8.7402e-02,\n",
       "         1.0071e-02,  2.2888e-03,  5.5176e-02,  4.7119e-02,  1.9287e-02,\n",
       "         1.9409e-02,  0.0000e+00,  1.0315e-02,  1.0193e-02,  3.6377e-02,\n",
       "         1.1536e-02,  1.3428e-02,  6.6895e-02,  1.6602e-02,  1.9287e-02,\n",
       "         1.1035e-01,  2.0996e-02,  2.6245e-02,  6.3965e-02,  1.2146e-02,\n",
       "         2.3193e-02,  0.0000e+00,  8.4961e-02,  7.4707e-02,  0.0000e+00,\n",
       "         0.0000e+00,  1.2734e+00,  0.0000e+00, -3.3264e-03,  2.1851e-02,\n",
       "         1.5918e-01,  3.2471e-02,  3.2715e-02,  1.7578e-02,  2.2217e-02,\n",
       "         3.0762e-02,  2.6733e-02,  3.0029e-02,  8.2397e-03,  8.5938e-02,\n",
       "         7.3730e-02,  2.0386e-02,  8.1787e-03,  2.2461e-01,  4.3213e-02,\n",
       "         1.0986e-01,  1.9043e-02,  0.0000e+00,  7.9102e-02,  3.3203e-02,\n",
       "         1.0742e-01,  3.4912e-02,  3.8818e-02,  8.6914e-02,  6.7383e-02,\n",
       "         2.5513e-02,  2.4609e-01,  1.3733e-02,  3.7598e-02,  3.7109e-01,\n",
       "         7.2266e-02,  1.7676e-01,  2.3926e-02,  2.2705e-02,  6.6895e-02,\n",
       "         2.6367e-02,  3.7109e-02,  5.4932e-02,  1.0596e-01,  1.6113e-02,\n",
       "         1.4160e-01,  1.0010e-02, -4.9438e-03,  4.9316e-02,  2.6245e-02,\n",
       "         3.8818e-02,  2.5586e-01,  7.3730e-02,  2.6489e-02,  1.9043e-02,\n",
       "         3.0151e-02,  2.0264e-02,  8.3008e-02,  1.8066e-02,  7.7515e-03,\n",
       "         4.1016e-02,  8.7402e-02,  1.4221e-02,  2.1484e-02,  1.1328e-01,\n",
       "         7.1289e-02,  0.0000e+00,  9.7656e-03, -1.4832e-02,  1.1328e-01,\n",
       "         2.2827e-02,  2.0410e-01,  1.1230e-01,  8.3984e-02,  5.3101e-03,\n",
       "         8.1253e-04,  2.2583e-02,  3.5645e-02,  1.0620e-02,  1.2061e-01,\n",
       "         3.0762e-02,  1.3770e-01,  0.0000e+00,  6.4453e-02,  1.2402e-01,\n",
       "         1.9434e-01,  1.5039e-01,  1.0620e-02,  8.9722e-03,  1.0986e-02,\n",
       "         2.9541e-02,  2.5781e-01,  1.9043e-01,  1.4941e-01,  1.0437e-02,\n",
       "         3.8818e-02,  1.0620e-02,  8.0078e-02,  2.0630e-02,  3.2227e-02,\n",
       "         3.0640e-02,  3.6865e-02,  0.0000e+00,  2.2705e-02,  1.5869e-02,\n",
       "         2.0508e-02,  2.2705e-02,  2.5635e-02,  4.1260e-02,  7.8735e-03,\n",
       "         7.1289e-02,  3.7598e-02,  1.9897e-02,  6.7383e-02,  7.2754e-02,\n",
       "         1.7944e-02,  2.6855e-02,  2.6245e-02,  2.5391e-02,  1.4258e-01,\n",
       "         1.7822e-02,  0.0000e+00,  3.1494e-02,  4.7363e-02,  3.4180e-01,\n",
       "         8.7891e-02,  2.9419e-02,  1.2988e-01,  2.6978e-02,  6.7871e-02,\n",
       "         3.7842e-02,  6.1768e-02,  8.3496e-02,  6.7383e-02,  1.3062e-02,\n",
       "         1.5198e-02,  1.8188e-02,  3.4424e-02,  2.3682e-02,  3.8452e-03,\n",
       "         8.0566e-02,  4.7363e-02,  1.3574e-01,  6.3965e-02,  1.8677e-02,\n",
       "         5.5176e-02,  9.7046e-03,  5.5664e-02,  5.1514e-02,  1.3855e-02,\n",
       "         2.1973e-01,  0.0000e+00,  8.3618e-03,  2.4780e-02,  1.3489e-02,\n",
       "         4.9072e-02,  7.0190e-03,  6.8848e-02,  3.4912e-02,  2.0508e-01,\n",
       "         0.0000e+00,  1.8677e-02,  2.7930e-01,  4.1199e-03,  2.0020e-02,\n",
       "         2.6367e-02,  2.6001e-02,  2.7832e-02,  4.6631e-02,  4.5654e-02,\n",
       "         3.2715e-02,  2.1582e-01,  8.7402e-02,  1.0071e-02,  2.0752e-03,\n",
       "         1.1875e+00,  4.3701e-02,  4.1504e-02,  4.7852e-02,  8.4473e-02,\n",
       "         3.2227e-01,  3.1641e-01,  1.6846e-02,  2.5757e-02,  3.9062e-02,\n",
       "         1.0864e-02,  0.0000e+00,  0.0000e+00,  3.3203e-02,  1.5503e-02,\n",
       "         9.5703e-02,  2.0898e-01,  1.0376e-02,  3.1006e-02,  2.0020e-02,\n",
       "         1.9629e-01,  0.0000e+00,  4.1016e-02,  2.6123e-02,  6.2500e-02,\n",
       "         1.2085e-02,  6.2012e-02,  3.8300e-03,  1.0986e-01,  1.5747e-02,\n",
       "         5.0354e-03,  4.5654e-02,  2.1606e-02,  1.0742e-01,  1.0010e-01,\n",
       "         2.4316e-01,  3.3936e-02,  1.7578e-01,  3.3398e-01,  2.9541e-02,\n",
       "         1.3733e-02,  3.5889e-02,  3.0640e-02,  1.4355e-01,  1.0681e-02,\n",
       "         1.7334e-02,  1.0193e-02,  5.3955e-02,  2.7148e-01,  1.5234e-01,\n",
       "         1.4258e-01,  3.5156e-02,  2.7344e-02,  2.4170e-02,  1.0742e-02,\n",
       "         3.3203e-02,  7.1289e-02,  6.0303e-02,  1.8262e-01,  4.4189e-02,\n",
       "         7.2266e-02,  1.2268e-02,  1.6016e-01,  7.4707e-02,  0.0000e+00,\n",
       "         3.7305e-01,  3.5858e-03,  1.6016e-01,  7.6660e-02,  1.8188e-02,\n",
       "         3.7695e-01,  3.9551e-02,  4.9316e-02,  0.0000e+00,  3.6865e-02,\n",
       "         2.0752e-02,  3.9844e-01,  1.1328e-01,  2.1582e-01,  0.0000e+00,\n",
       "         7.0801e-02,  6.9824e-02,  7.5684e-02,  3.4180e-02,  1.3965e-01,\n",
       "         2.5391e-01,  4.3701e-02,  2.3242e-01,  4.5166e-02,  8.2520e-02,\n",
       "         4.1992e-02,  4.2725e-02,  1.5820e-01,  1.2598e-01,  0.0000e+00,\n",
       "         3.7109e-02,  4.6387e-02,  7.1777e-02,  8.9844e-02,  1.0889e-01,\n",
       "         0.0000e+00,  9.5215e-02,  1.8848e-01,  1.5182e-03,  2.7710e-02,\n",
       "         1.1230e-01,  1.1230e-01,  0.0000e+00,  1.6235e-02,  7.0703e-01,\n",
       "         1.7334e-02,  3.1494e-02,  7.6660e-02,  1.1047e-02,  2.9663e-02,\n",
       "         1.8555e-01,  5.6152e-02,  1.5991e-02,  2.5024e-02,  1.4587e-02,\n",
       "         2.7344e-02,  1.0681e-02,  7.5684e-03,  9.5825e-03,  1.0742e-02],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow[0,2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0361,  0.0883,  0.1455,  ...,  0.0076,  0.0096,  0.0108])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gradients_at_checkpoint / 3000).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gradients_at_checkpoint / 3000).float() == slow.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0361,  0.0884,  0.1455,  ...,  0.0076,  0.0096,  0.0107]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0361,  0.0884,  0.1455,  ...,  0.0076,  0.0096,  0.0107]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(gradients_at_checkpoint == 677)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([676014])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_at_checkpoint.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with torch.no_grad(): # TODO redundant\n",
    "for chunk in tqdm(get_all_chunks(\"/data/loriss21dm/babylm/results/100000_65000_66000\"), desc=\"Loading checkpoint chunks from disk\"):\n",
    "    _, start_id, stop_id = chunk.split( \"_\")\n",
    "    \n",
    "# gradients_at_checkpoint.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4tfeu0d9üp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint chunks from disk: 100%|████████████████████████████████████████| 677/677 [05:19<00:00,  2.12it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#with torch.no_grad(): # TODO redundant\n",
    "for chunk in tqdm(get_all_chunks(\"/data/loriss21dm/babylm/results/100000_65000_66000\"), desc=\"Loading checkpoint chunks from disk\"):\n",
    "    _, start_id, stop_id = chunk.split( \"_\")\n",
    "gradients_at_checkpoint = \n",
    "[torch.load(chunk, weights_only=True,map_location=\"cpu\") ]\n",
    "# gradients_at_checkpoint.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaaaw\n",
    "def get_mean_influence_at_checkpoint_einsum_batched(checkpoint_path, batch_size=100000):\n",
    "\n",
    "    # gradients_at_checkpoint = torch.concat([torch.load(chunk, weights_only=True,map_location=\"cpu\") for chunk in tqdm(get_all_chunks(checkpoint_path), desc=\"Loading checkpoint chunks from disk\")]).flatten(1)\n",
    "\n",
    "    num_batches = (gradients_at_checkpoint.shape[0] + batch_size - 1) // batch_size  # Calculate number of batches\n",
    "    results = []\n",
    "\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        start = i * batch_size\n",
    "        end = min((i + 1) * batch_size, gradients_at_checkpoint.shape[0])\n",
    "        gradients_batch = gradients_at_checkpoint[start:end]\n",
    "        print(\"gradients_batch\",gradients_batch.shape)\n",
    "        print(\"gradients_at_checkpoint.T\", gradients_at_checkpoint.T.shape)\n",
    "      \n",
    "        batch_result = torch.einsum('ik, kj -> i', gradients_batch, gradients_at_checkpoint.T)\n",
    "        results.append(batch_result)  \n",
    "        print(\"batch_result\", batch_result.shape)\n",
    "\n",
    "    return (torch.concat(results) / gradients_at_checkpoint.shape[0]).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradients_batch torch.Size([200000, 393216])\n",
      "gradients_at_checkpoint.T torch.Size([393216, 200000])\n",
      "batch_result torch.Size([200000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slower = get_mean_influence_at_checkpoint_einsum_batched(\"/data/loriss21dm/babylm/results/100000_65000_66000\")\n",
    "slower.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast = (torch.einsum('ik, kj -> i', gradients_at_checkpoint, gradients_at_checkpoint.T) / gradients_at_checkpoint.shape[0]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0449e-01, -7.6294e-03,  0.0000e+00,  1.6357e-02,  3.6621e-02,\n",
       "         1.0742e-02, -3.3264e-03,  2.0898e-01,  4.6387e-02, -4.6997e-03,\n",
       "         7.6904e-03,  3.0060e-03,  4.1199e-03,  1.5381e-02, -1.1978e-03,\n",
       "        -1.3062e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5449e-03,\n",
       "         1.4465e-02,  3.4668e-02,  1.2970e-03,  6.6528e-03,  0.0000e+00,\n",
       "         3.0212e-03,  9.7046e-03,  6.3419e-05,  9.2285e-02,  2.5787e-03,\n",
       "         4.3457e-02,  9.9121e-02,  1.4725e-03,  1.2402e-01,  6.4392e-03,\n",
       "         1.5527e-01,  0.0000e+00,  7.0190e-04,  0.0000e+00,  1.8311e-03,\n",
       "        -2.6367e-02,  3.5248e-03, -5.6763e-03,  5.0049e-03,  2.7832e-02,\n",
       "         1.5747e-02,  3.4668e-02,  3.1128e-03,  3.8477e-01,  9.2285e-02,\n",
       "         8.3618e-03,  1.0132e-02,  1.9775e-02,  3.2349e-03,  4.7607e-02,\n",
       "         5.6458e-03,  1.5869e-02,  1.8387e-03,  0.0000e+00,  2.4292e-02,\n",
       "         2.1289e-01,  8.9844e-02,  1.2695e-02,  1.4465e-02,  1.8066e-01,\n",
       "         5.3711e-03,  1.6357e-02,  3.4668e-02,  7.8735e-03,  7.5989e-03,\n",
       "        -3.8147e-03,  0.0000e+00,  6.2256e-03,  2.2278e-03,  1.3306e-02,\n",
       "         1.0864e-02,  1.1902e-02,  9.0942e-03,  2.1484e-02,  4.9133e-03,\n",
       "         1.4355e-01,  8.3008e-03,  1.7212e-02,  1.4160e-02,  1.3965e-01,\n",
       "         6.8359e-03,  1.4465e-02,  9.5367e-04, -4.1199e-03,  1.5869e-03,\n",
       "         2.9182e-04,  3.0273e-02,  6.3171e-03, -4.9353e-05,  1.3199e-03,\n",
       "         9.4986e-04,  5.2490e-02,  1.7578e-02,  1.3504e-03,  1.6098e-03],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fast[0][100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(slower, fast, rtol=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
