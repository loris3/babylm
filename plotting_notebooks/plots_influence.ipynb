{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import config\n",
    "import util\n",
    "import plotting\n",
    "from datasets import load_dataset\n",
    "\n",
    "def process_job(args):\n",
    "    model_name, dataset_name, model_type, curriculum_name = args\n",
    "    try:\n",
    "        influence_output_dir = os.path.join(\n",
    "            \"./influence_mean_normalized\",\n",
    "            os.path.basename(model_name),\n",
    "            \"_\".join([(os.path.basename(dataset_name) + \"_\" + f\"train[0%:100%]\")]*2)\n",
    "        )\n",
    "        print(influence_output_dir)\n",
    "        dataset = load_dataset(dataset_name)[\"train\"]\n",
    "        curriculum = util.get_curriculum(dataset_name, curriculum_name)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            int(result_checkpoint.replace(\"checkpoint-\", \"\")):\n",
    "                torch.load(os.path.join(influence_output_dir, result_checkpoint),\n",
    "                           weights_only=True, map_location=\"cpu\").numpy().flatten()\n",
    "            for result_checkpoint in os.listdir(influence_output_dir)\n",
    "        })\n",
    "\n",
    "        df = df.reindex(sorted(df.columns, reverse=False), axis=1)\n",
    "        influence_cols = df.columns\n",
    "        df[\"total\"] = df.sum(axis=1)\n",
    "        df[[\"text\", \"source\", \"stage\"]] = dataset.to_pandas()\n",
    "        df[\"document_lenght\"] = df[\"text\"].str.split().str.len()\n",
    "\n",
    "        plotting.plot_per_token_in_order(df[influence_cols.to_list() + [\"stage\", \"document_lenght\"]],\n",
    "                                         curriculum_name, model_type, dataset_name, curriculum)\n",
    "        plotting.plot_per_token_per_stage(df[influence_cols.to_list() + [\"stage\", \"document_lenght\"]],\n",
    "                                          curriculum_name, model_type, dataset_name, curriculum)\n",
    "\n",
    "        for influence_curriculum_name in config.influence_curricula:\n",
    "            print(dataset_name, influence_curriculum_name)\n",
    "            influence_curriculum_name = model_type + influence_curriculum_name\n",
    "            influence_curriculum = util.get_curriculum(dataset_name, influence_curriculum_name)\n",
    "            plotting.plot_per_token_in_order(df[influence_cols.to_list() + [\"stage\", \"document_lenght\"]],\n",
    "                                             influence_curriculum_name, model_type, dataset_name, influence_curriculum)\n",
    "           \n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"skipping\", model_name, dataset_name, model_type, curriculum_name, \"due to\", str(e))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  \n",
    "\n",
    "    jobs = [\n",
    "        (d + \"_\" + t + \"_random\", d, t, \"random.pt\")\n",
    "        for d, t in product(config.datasets, config.model_types)  \n",
    "    ]\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_job, job) for job in jobs]\n",
    "        for _ in tqdm(as_completed(futures), total=len(futures), desc=\"Processing jobs\"):\n",
    "            pass\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
