{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pretrain.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pretrain.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "parser = argparse.ArgumentParser(\"pretraining\")\n",
    "parser.add_argument(\"dataset_folder\", help=\"Path to a dataset folder of .train files that can be read by calling load_dataset('text', <path>)\")\n",
    "parser.add_argument(\"model_output_dir\", help=\"Where the model and checkpoints should be stored\")\n",
    "parser.add_argument(\"epochs\", help=\"Number of epochs\", type=int)\n",
    "parser.add_argument(\"mode\", help=\"Set to 'curriculum' for curriculum training, 'shuffle' for default Trainer behaviour\")\n",
    "parser.add_argument(\"curriculum_path\", help=\"A path to a torch tensor of shape (epochs, training examples) with training data ids\")\n",
    "\n",
    "parser.add_argument(\"--per_device_train_batch_size\", help=\"per_device_train_batch_size\", type=int, nargs=\"?\", const=1, default=8)\n",
    "parser.add_argument(\"--checkpoints_per_epoch\", help=\"Checkpoints to store per epoch\", type=int, nargs=\"?\", const=1, default=3)\n",
    "parser.add_argument(\"--cuda_visible_devices\", help=\"Comma seperated GPU ids to use\", nargs=\"?\", const=1, default=\"0,1\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda_visible_devices\n",
    "\n",
    "\n",
    "if not os.path.exists(args.model_output_dir):\n",
    "    os.makedirs(args.model_output_dir)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "# paths = [str(x) for x in Path(args.dataset_folder).glob(\"**/*.train\")]\n",
    "\n",
    "# # Initialize a tokenizer\n",
    "# tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# # Customize training\n",
    "# tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
    "#     \"<s>\",\n",
    "#     \"<pad>\",\n",
    "#     \"</s>\",\n",
    "#     \"<unk>\",\n",
    "#     \"<mask>\",\n",
    "# ])\n",
    "\n",
    "# # Save files to disk\n",
    "# tokenizer.save_model(args.model_output_dir)\n",
    "\n",
    "\n",
    "\n",
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=52_000,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    ")\n",
    "\n",
    "\n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(args.model_output_dir, max_len=512)\n",
    "\n",
    "\n",
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = RobertaForMaskedLM(config=config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "import torch\n",
    "from random import randrange\n",
    "import cloudpickle\n",
    "\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# clustering = None\n",
    "# with open('brown_clustering', \"rb\") as handle:\n",
    "#     clustering = cloudpickle.load(handle)\n",
    "\n",
    "# class BrownDataset(Dataset):\n",
    "#     def rewrite(self, x):\n",
    "#         result = []\n",
    "#         for doc in x:\n",
    "#            # print(\"doc\", doc, flush=True)\n",
    "#             tokenized = tokenizer.tokenize(doc)\n",
    "#             if len(tokenized) == 0:\n",
    "#                 result.append(doc)\n",
    "#                 continue\n",
    "#             #print(\"tokenized\", tokenized, flush=True)\n",
    "#             IDX = randrange(len(tokenized))\n",
    "\n",
    "#             r = []\n",
    "#             for i, word in enumerate(tokenized):\n",
    "#                 replacement = clustering.get_similar(word)\n",
    "                \n",
    "#                 if i == IDX and len(replacement):\n",
    "#                     r.append(random.choice(replacement)[0])\n",
    "#                 else:\n",
    "#                     r.append(word)\n",
    "#             print(doc,tokenizer.convert_tokens_to_string(r), flush=True)\n",
    "#             result.append(tokenizer.convert_tokens_to_string(r))\n",
    "            \n",
    "\n",
    "#         return result\n",
    "       \n",
    "        \n",
    "\n",
    "#     def __init__(self, data_dir):\n",
    "#         self.size = float('inf')\n",
    "#         self.data = load_dataset(\"text\", data_dir=args.dataset_folder)\n",
    "#         self.data.set_transform(lambda x : tokenizer(self.rewrite(x[\"text\"]), return_special_tokens_mask=True, truncation=True, max_length=512))\n",
    "#     def __len__(self):\n",
    "#         return float('inf')\n",
    "#         # TODO argue that an infinite training dataset is cognitively plausible \n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#      #   print(self.transform(self.data[idx]))\n",
    "#      #   print(self.data[idx], idx)\n",
    "#         return self.data[idx]#tokenizer(, return_special_tokens_mask=True, truncation=True, max_length=512)\n",
    "\n",
    "# if args.mode == \"brown\":\n",
    "#     dataset = BrownDataset(args.dataset_folder)\n",
    "#     print(dataset[\"train\"][0])\n",
    "#     exit\n",
    "# else:\n",
    "dataset = load_dataset(\"text\", data_dir=args.dataset_folder)\n",
    "dataset.set_transform(lambda x : tokenizer(x[\"text\"], return_special_tokens_mask=True, truncation=True, max_length=512))\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random_order = torch.stack([torch.arange(0,len(dataset[\"train\"])) for i in range(0,2)])\n",
    "torch.save(random_order, \"random_curriculum\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import util\n",
    "\n",
    "\n",
    "data_collator = util.DeterministicDataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=args.model_output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=args.epochs,\n",
    "    per_device_train_batch_size=args.per_device_train_batch_size,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=((len(dataset[\"train\"]) / (torch.cuda.device_count()*args.per_device_train_batch_size)) // args.checkpoints_per_epoch ), # roughly N times per epoch\n",
    "    seed=42,\n",
    "    prediction_loss_only=True,\n",
    "    remove_unused_columns=False,\n",
    "\n",
    "    \n",
    "    \n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers.trainer_utils import (\n",
    "\n",
    "    seed_worker,\n",
    "\n",
    ")\n",
    "#https://discuss.huggingface.co/t/non-shuffle-training/6986/3\n",
    "from torch.utils.data import SequentialSampler\n",
    "class CurriculumTrainer(Trainer):\n",
    "    \n",
    "    def get_train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"\n",
    "        Adapted to use EpochVariableDataLoader (skips accelerator!)\n",
    "        \"\"\"\n",
    "        train_dataset = self.train_dataset\n",
    "        data_collator = self.data_collator\n",
    "\n",
    "        train_dataset = self._remove_unused_columns(train_dataset, description=\"training\")\n",
    "        dataloader_params = {\n",
    "            \"batch_size\": self._train_batch_size,\n",
    "            \"collate_fn\": data_collator,\n",
    "            \"num_workers\": self.args.dataloader_num_workers,\n",
    "            \"pin_memory\": self.args.dataloader_pin_memory,\n",
    "            \"persistent_workers\": self.args.dataloader_persistent_workers,\n",
    "        }\n",
    "\n",
    "        if not isinstance(train_dataset, torch.utils.data.IterableDataset):\n",
    "            dataloader_params[\"sampler\"] = OrderedSampler(self.train_dataset, self.state.epoch if self.state.epoch is not None else 0)\n",
    "            dataloader_params[\"drop_last\"] = self.args.dataloader_drop_last\n",
    "            dataloader_params[\"worker_init_fn\"] = seed_worker\n",
    "            dataloader_params[\"prefetch_factor\"] = self.args.dataloader_prefetch_factor\n",
    "\n",
    "        return EpochVariableDataLoader(train_dataset, data_collator.set_epoch, **dataloader_params) # the Trainer class calls set_epoch on the dataloader, but we also need it in the data_collator\n",
    "        \n",
    "class EpochVariableDataLoader(DataLoader):\n",
    "    def __init__(self, train_dataset, passtrough_function, **dataloader_params):\n",
    "        self.passtrough_function = passtrough_function\n",
    "        super().__init__(train_dataset, **dataloader_params)\n",
    "    def set_epoch(self, epoch):\n",
    "        self.sampler.epoch = epoch    \n",
    "        self.passtrough_function(epoch)    \n",
    "\n",
    "class OrderedSampler(SequentialSampler):\n",
    "    def __init__(self, data_source, epoch):\n",
    "        self.data_source = data_source\n",
    "        self.epoch = epoch\n",
    "        self.curriculum = torch.load(args.curriculum_path, weights_only=True)\n",
    "       \n",
    "    def __iter__(self):\n",
    "        print(\"getting new iterator\",flush=True)\n",
    "        return iter(self.curriculum[self.epoch].tolist())\n",
    "    \n",
    "\n",
    "\n",
    "class BrownTrainer(Trainer):\n",
    "    def _get_train_sampler(self):\n",
    "        return EpochVariableSampler(self.train_dataset, self.state.epoch, torch.randperm(len(self.train_dataset)).tolist())\n",
    "        \n",
    "\n",
    "trainer = None\n",
    "\n",
    "if args.mode == \"shuffle\":\n",
    "    print(\"Random order!\")\n",
    "    trainer = Trainer( # shuffles the data at each epoch by default!\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        \n",
    "\n",
    "        )\n",
    "elif args.mode == \"curriculum\":\n",
    "    print(\"Curriculum!\")\n",
    "    trainer = CurriculumTrainer( \n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        \n",
    "\n",
    "        )\n",
    "elif args.mode == \"brown\":\n",
    "    print(\"Brown!\")\n",
    "    trainer = BrownTrainer( \n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(args.model_output_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([0,1,2])[0:0+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "2024-10-21 06:39:40.195267: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-21 06:39:40.212236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-21 06:39:40.231326: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-21 06:39:40.236945: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-21 06:39:40.252161: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-21 06:39:41.236449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "Curriculum!\n",
      "creatk new iterator\n",
      "getting new iterator\n",
      "mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='253' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [253/254 00:36 < 00:00, 6.91 it/s, Epoch 1.98/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting new iterator\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n",
      "mask\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/data/loriss21dm/babylm/pretrain.py:268\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrown!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m BrownTrainer( \n\u001b[1;32m    260\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    261\u001b[0m         args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m \n\u001b[1;32m    265\u001b[0m         )\n\u001b[0;32m--> 268\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(args\u001b[38;5;241m.\u001b[39mmodel_output_dir)\n",
      "File \u001b[0;32m/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/transformers/trainer.py:2356\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2353\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/transformers/trainer.py:2807\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2804\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[1;32m   2806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2807\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2808\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/transformers/trainer.py:2890\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2886\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(output_dir, _internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   2889\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[0;32m-> 2890\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2891\u001b[0m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n\u001b[1;32m   2892\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_rng_state(output_dir)\n",
      "File \u001b[0;32m/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/transformers/trainer.py:3006\u001b[0m, in \u001b[0;36mTrainer._save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   3001\u001b[0m     save_fsdp_optimizer(\n\u001b[1;32m   3002\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfsdp_plugin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, output_dir\n\u001b[1;32m   3003\u001b[0m     )\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   3005\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 3006\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3008\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[1;32m   3009\u001b[0m is_deepspeed_custom_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   3010\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[1;32m   3011\u001b[0m )\n",
      "File \u001b[0;32m/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/torch/serialization.py:651\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    648\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 651\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    652\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/data/loriss21dm/TracInVenv/lib/python3.10/site-packages/torch/serialization.py:499\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run pretrain.py ./train_test ./10MModelBrown 2 curriculum random_curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run pretrain.py ./train_10M ./10MModel 10 shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Groups     |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
    "|----------------|-------|------|-----:|------|-----:|---|-----:|\n",
    "|blimp_supplement|N/A    |none  |     0|acc   |0.4314|±  |0.0069|\n",
    "|blimp_filtered  |N/A    |none  |     0|acc   |0.4831|±  |0.0019|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run pretrain.py ./10MCurriculum ./10MModelCurriculum 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
