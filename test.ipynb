{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"loris3/stratified_equitoken_10m_curriculum_random\"\n",
    "\n",
    "\n",
    "dataset_train_name =\"loris3/stratified_equitoken_10m_curriculum\"\n",
    "dataset_train_split_name = \"validation\"\n",
    "\n",
    "dataset_test_name = \"loris3/stratified_equitoken_10m_curriculum\"\n",
    "dataset_test_split_name = \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "dataset_test = load_dataset(dataset_test_name)[dataset_test_split_name] \n",
    "\n",
    "\n",
    "\n",
    "len_ds = len(dataset_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests on wether implementaiton of\n",
    "\n",
    "$\n",
    "        \\phi(f;z,z') = \\frac{\\sum_{\\forall z' \\in D_{test}} \\nabla \\ell(z) \\cdot \\nabla \\ell(z')}{ |D_{test}|}\n",
    "$\n",
    "works out with sufficent accuracy via taking the mean of the test gradients first\n",
    "$\n",
    "      = \\frac{1}{ |D_{test}|}\\cdot(\\nabla \\ell(z) \\cdot\\sum_{\\forall z' \\in D_{test}} \\nabla \\ell(z'))\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.device_count() 2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mloriss\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/loriss21dm/babylm/wandb/run-20250213_120823-14skyt78</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/loriss/babylm_gradient_extraction/runs/14skyt78' target=\"_blank\">pious-fog-354</a></strong> to <a href='https://wandb.ai/loriss/babylm_gradient_extraction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/loriss/babylm_gradient_extraction' target=\"_blank\">https://wandb.ai/loriss/babylm_gradient_extraction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/loriss/babylm_gradient_extraction/runs/14skyt78' target=\"_blank\">https://wandb.ai/loriss/babylm_gradient_extraction/runs/14skyt78</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 12:08:24,517 - INFO - Getting gradients for checkpoint-/data/loriss21dm/cache/hub/models--loris3--stratified_equitoken_10m_curriculum_random/snapshots/e6648f6a0733fa4e002b0da24ba4614e2445f654/checkpoints/checkpoint-6174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get gradients: 25.8429 s/chunk\n",
      "Time to get gradients: 55.3860 s/chunk\n",
      "Time to get gradients: 57.4563 s/chunk\n",
      "Time to get gradients: 67.0739 s/chunk\n",
      "Time to get gradients: 68.4874 s/chunk\n",
      "Time to get gradients: 70.0945 s/chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 12:09:54,538 - INFO - Got gradients for checkpoint-/data/loriss21dm/cache/hub/models--loris3--stratified_equitoken_10m_curriculum_random/snapshots/e6648f6a0733fa4e002b0da24ba4614e2445f654/checkpoints/checkpoint-6174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.device_count() 2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 12:09:58,860 - INFO - Getting gradients for checkpoint-/data/loriss21dm/cache/hub/models--loris3--stratified_equitoken_10m_curriculum_random/snapshots/e6648f6a0733fa4e002b0da24ba4614e2445f654/checkpoints/checkpoint-6174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get gradients: 29.1872 s/chunk\n"
     ]
    }
   ],
   "source": [
    "%run extract_gradients.py loris3/stratified_equitoken_10m_curriculum_random loris3/stratified_equitoken_10m_curriculum 0 --dataset_split=validation[0%:10%] --paradigm=mlm --gradients_per_file=1000 --mode=store\n",
    "%run extract_gradients.py loris3/stratified_equitoken_10m_curriculum_random loris3/stratified_equitoken_10m_curriculum 0 --dataset_split=validation[0%:10%] --paradigm=mlm --gradients_per_file=1000 --mode=store_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mean_extraction():\n",
    "    cp = \"/data/loriss21dm/babylm/gradients/stratified_equitoken_10m_curriculum_random/stratified_equitoken_10m_curriculum/validation[0%:10%]/checkpoint-6174/\"\n",
    "    paths = os.listdir(cp)\n",
    "    mean_pw = torch.cat([torch.load(os.path.join(cp,p),weights_only=True) for p in paths if p != \"mean\"],axis=0).mean(axis=0, dtype=torch.float64)\n",
    "    mean_script = torch.load(\"/data/loriss21dm/babylm/gradients/stratified_equitoken_10m_curriculum_random/stratified_equitoken_10m_curriculum/validation[0%:10%]/checkpoint-6174/mean\", weights_only=True)\n",
    "    assert torch.cosine_similarity(mean_pw, mean_script).mean().float() == torch.tensor(1.0).float()\n",
    "    assert torch.allclose(mean_pw, mean_script, atol=0.000001)\n",
    "validate_mean_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run extract_gradients.py loris3/stratified_equitoken_10m_curriculum_random loris3/stratified_equitoken_10m_curriculum 0 --dataset_split=validation[10%:15%] --paradigm=mlm --gradients_per_file=1000 --mode=store\n",
    "%run extract_gradients.py loris3/stratified_equitoken_10m_curriculum_random loris3/stratified_equitoken_10m_curriculum 0 --dataset_split=validation[10%:15%] --paradigm=mlm --gradients_per_file=1000 --mode=store_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run process_gradients.py loris3/stratified_equitoken_10m_curriculum_random loris3/stratified_equitoken_10m_curriculum 0 --dataset_train_split=validation[0%:10%] --dataset_test=\"loris3/stratified_equitoken_10m_curriculum\" --dataset_test_split=validation[10%:15%] --mode=single --gradients_per_file=1000 --batch_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_single = torch.load(\"/data/loriss21dm/babylm/influence/stratified_equitoken_10m_curriculum_random/stratified_equitoken_10m_curriculum_validation[0%:10%]_stratified_equitoken_10m_curriculum_validation[10%:15%]/checkpoint-6174\", weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run process_gradients.py loris3/stratified_equitoken_10m_curriculum_random loris3/stratified_equitoken_10m_curriculum 0 --dataset_train_split=validation[0%:10%] --dataset_test=\"loris3/stratified_equitoken_10m_curriculum\" --dataset_test_split=validation[10%:15%] --mode=mean --gradients_per_file=1000 --batch_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_mean = torch.load(\"/data/loriss21dm/babylm/mean_influence/stratified_equitoken_10m_curriculum_random/stratified_equitoken_10m_curriculum_validation[0%:10%]_stratified_equitoken_10m_curriculum_validation[10%:15%]/checkpoint-6174\", weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(influence_single.mean(-1),influence_mean.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = (torch.cosine_similarity(influence_single.mean(-1), influence_mean.squeeze())).unsqueeze(1)\n",
    "\n",
    "\n",
    "array = tensor.numpy()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(array, cmap='viridis', aspect='auto', interpolation=None)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests of the two modes \"single\" and \"mean\" against eachother for getting the mean influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_debug(start, stop):\n",
    "    return torch.arange(start*393216, stop*393216, 1, dtype=torch.float64).reshape(-1,393216) /  (len_ds*393216)\n",
    "\n",
    "gradient_dir = \"./gradients/test/test/test/test\"\n",
    "if not os.path.exists(gradient_dir):\n",
    "    os.makedirs(gradient_dir)\n",
    "    chunks_test = [ (i, min(i+10000, len_ds), os.path.join(gradient_dir, str(i) + \"_\" + str(i + 10000))) for i in range(0, len(dataset_test),10000)]\n",
    "    for start, stop, chunk in chunks_test:\n",
    "        torch.save(load_debug(start, stop), chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_train_train():\n",
    "    s = None\n",
    "    if not os.path.exists(\"test\"):\n",
    "        data = load_debug(0, len_ds).squeeze()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            s = torch.matmul(data, data.T).sum(dim=1)\n",
    "        s = s / len_ds\n",
    "        s = s.unsqueeze(0)\n",
    "        torch.save(s, \"test\")\n",
    "    else:\n",
    "        s = torch.load(\"test\")\n",
    "\n",
    "    slurm = torch.load(\"/data/loriss21dm/babylm/mean_influence/test/test_test_test_test/test\")\n",
    "    assert torch.allclose(slurm, s.float())\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    tensor = (s / slurm).float()\n",
    "\n",
    "\n",
    "    array = tensor.numpy()\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.imshow(array, cmap='viridis', aspect='auto', interpolation=None)\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run process_gradients.py test test 0 --mode=mean --dataset_test_split=test --dataset_train_split=test --test=True --test_dataset_size=53457 --gradients_per_file=10000 --batch_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_train_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run process_gradients.py test test 0 --mode=mean --dataset_test_split=test --dataset_train_split=test --test=True --test_dataset_size=53457 --gradients_per_file=10000 --batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_train_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run process_gradients.py test test 0 --mode=mean --dataset_test_split=test --dataset_train_split=test --test=True --test_dataset_size=53457 --gradients_per_file=10000 --batch_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_train_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
